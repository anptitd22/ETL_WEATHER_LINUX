{"timestamp":"2025-09-01T04:18:25.805983","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:18:29.320589Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:29.783999Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:31.844129Z","level":"error","event":"25/09/01 04:18:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:32.271903Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:32.272124Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:32.272212Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.426358Z","level":"error","event":"25/09/01 04:18:36 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.426814Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.427020Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.427114Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.427191Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.427465Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.427594Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.427671Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.427813Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.427913Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.427987Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428058Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428133Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428209Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428280Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428374Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428454Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428531Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428609Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428691Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428770Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428849Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.428939Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.429015Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.429088Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.429159Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.429242Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.429321Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.429395Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.429466Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.429533Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.523594Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.523723Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.523770Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.523808Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.523845Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.523900Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.523958Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524007Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524043Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524079Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524114Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524148Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524183Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524216Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524254Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524287Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524321Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524354Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524388Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.524422Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.522583","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T04:19:10.342609","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:19:10.710083Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:11.361279Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:12.131539Z","level":"error","event":"25/09/01 04:19:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:12.265162Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:12.269183Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:12.269346Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:13.084139Z","level":"error","event":"25/09/01 04:19:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:13.084336Z","level":"error","event":"25/09/01 04:19:13 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688124Z","level":"error","event":"25/09/01 04:19:14 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688475Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688540Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688579Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688614Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688651Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688687Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688720Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688761Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688796Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688830Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688874Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688909Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688942Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.688975Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689006Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689040Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689074Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689105Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689138Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689170Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689202Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689232Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689264Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689303Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689337Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689368Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689399Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689429Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689463Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.689499Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.294932Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295090Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295142Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295182Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295218Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295272Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295309Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295345Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295403Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295444Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295479Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295513Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295545Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295579Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295621Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295655Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295689Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295723Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295757Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295792Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.295069","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T04:25:01.338452","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:25:04.744948Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:04.745058Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:25:04.764355Z","level":"error","event":"25/09/01 04:25:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:04.983419Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:05.005820Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:05.006055Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:10.926005Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:25:41.483041","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:25:41.813368Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:42.334968Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:25:43.095821Z","level":"error","event":"25/09/01 04:25:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:43.244452Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:43.248748Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:43.248879Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:47.095364Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:26:18.460963","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:26:18.838094Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:19.566782Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:26:20.338119Z","level":"error","event":"25/09/01 04:26:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:20.477069Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:20.482149Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:20.482304Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:24.786963Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:26:55.960767","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:26:56.261380Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:56.815548Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:26:57.478967Z","level":"error","event":"25/09/01 04:26:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:57.625795Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:57.630681Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:57.630808Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:58.397467Z","level":"error","event":"25/09/01 04:26:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:01.504572Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:27:32.292304","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:27:32.633172Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:33.335960Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:27:34.025241Z","level":"error","event":"25/09/01 04:27:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:34.160029Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:34.165390Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:34.165589Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:38.499631Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:28:09.680582","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:28:10.186711Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:10.819199Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:28:11.450267Z","level":"error","event":"25/09/01 04:28:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:11.587416Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:11.593669Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:11.593863Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:12.354780Z","level":"error","event":"25/09/01 04:28:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:15.425327Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:28:45.962845","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:28:46.465807Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:47.084546Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:28:47.691980Z","level":"error","event":"25/09/01 04:28:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:47.821621Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:47.831885Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:47.832106Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:48.612890Z","level":"error","event":"25/09/01 04:28:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:51.664531Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:29:22.803061","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:29:23.276630Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:29:23.822520Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:29:24.396992Z","level":"error","event":"25/09/01 04:29:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:29:24.559468Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:29:24.559809Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:29:24.559924Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:29:28.075763Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:29:59.504935","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:29:59.980908Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:00.641447Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:30:01.453670Z","level":"error","event":"25/09/01 04:30:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:01.660723Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:01.677153Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:01.677467Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:09.408493Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:30:40.974469","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:30:41.298134Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:41.992366Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:30:42.664984Z","level":"error","event":"25/09/01 04:30:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:42.841751Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:42.847118Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:42.847278Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:43.717250Z","level":"error","event":"25/09/01 04:30:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:46.696676Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:31:17.936528","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:31:18.264221Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:18.921465Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:31:19.486773Z","level":"error","event":"25/09/01 04:31:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:19.588272Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:19.593064Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:19.593186Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:23.329519Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:31:54.695261","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:31:54.971876Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:55.546784Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:31:56.166183Z","level":"error","event":"25/09/01 04:31:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:56.305597Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:56.305988Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:56.306093Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:57.320271Z","level":"error","event":"25/09/01 04:31:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:01.777305Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:32:33.067651","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:32:33.399129Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:34.000699Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:32:34.695832Z","level":"error","event":"25/09/01 04:32:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:34.833605Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:34.840243Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:34.840414Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:35.479333Z","level":"error","event":"25/09/01 04:32:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:38.316080Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:33:09.279260","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:33:09.603700Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:10.180509Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:33:10.786194Z","level":"error","event":"25/09/01 04:33:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:10.931633Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:10.937445Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:10.937658Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:14.642837Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:33:45.735688","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:33:46.028572Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:46.594257Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:33:47.358838Z","level":"error","event":"25/09/01 04:33:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:47.496460Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:47.503151Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:47.503353Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:02:53.046898","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:02:55.269663Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:02:55.628525Z","level":"error","event":"25/09/01 05:02:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:02:55.864039Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:02:55.864121Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:02:57.060068Z","level":"error","event":"25/09/01 05:02:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:02:59.571452Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:03:31.035409","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:03:31.639412Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:03:32.266032Z","level":"error","event":"25/09/01 05:03:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:03:32.427586Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:03:32.427884Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:03:33.082660Z","level":"error","event":"25/09/01 05:03:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:03:34.361320Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:04:05.555291","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:04:06.112207Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:04:06.743555Z","level":"error","event":"25/09/01 05:04:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:06.879359Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:06.879513Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:07.532478Z","level":"error","event":"25/09/01 05:04:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:08.734587Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:04:39.861486","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:04:40.364468Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:04:41.011008Z","level":"error","event":"25/09/01 05:04:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:41.143104Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:41.143268Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:43.001370Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:05:14.018104","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:05:14.794610Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:05:15.828585Z","level":"error","event":"25/09/01 05:05:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:16.065801Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:16.066177Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:19.603139Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:05:50.655727","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:05:51.274717Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:05:52.007104Z","level":"error","event":"25/09/01 05:05:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:52.153751Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:52.154003Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:52.876113Z","level":"error","event":"25/09/01 05:05:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:54.397434Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:06:25.755229","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:06:26.386593Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:06:27.084490Z","level":"error","event":"25/09/01 05:06:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:06:27.252813Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:06:27.257570Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:06:27.979081Z","level":"error","event":"25/09/01 05:06:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:06:29.354373Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:07:00.703441","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:07:01.412956Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:07:02.045807Z","level":"error","event":"25/09/01 05:07:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:02.196659Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:02.196929Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:03.995803Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:07:35.242304","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:07:35.964761Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:07:36.660958Z","level":"error","event":"25/09/01 05:07:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:36.811235Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:36.811466Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:37.502066Z","level":"error","event":"25/09/01 05:07:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:38.781004Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:08:09.690966","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:08:10.310963Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:08:11.036447Z","level":"error","event":"25/09/01 05:08:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:08:11.172753Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:08:11.172891Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:08:13.283370Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:11:48.648268","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:11:50.953630Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:11:50.953989Z","level":"error","event":"25/09/01 05:11:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:11:51.377428Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:11:51.377673Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:11:55.087214Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:12:25.683565","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:12:26.202472Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:12:26.886388Z","level":"error","event":"25/09/01 05:12:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:12:27.033283Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:12:27.033507Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:12:29.275644Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:13:00.603871","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:13:01.176774Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:13:01.852007Z","level":"error","event":"25/09/01 05:13:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:02.018178Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:02.018360Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:04.145237Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:13:35.284415","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:13:35.899664Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:13:36.564964Z","level":"error","event":"25/09/01 05:13:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:36.718163Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:36.718313Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:38.573500Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:14:09.731522","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:14:10.256476Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:14:10.901496Z","level":"error","event":"25/09/01 05:14:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:11.059367Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:11.062212Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:12.789996Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:14:44.008396","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:14:44.523609Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:14:45.142289Z","level":"error","event":"25/09/01 05:14:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:45.283039Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:45.283192Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:45.956839Z","level":"error","event":"25/09/01 05:14:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:47.210378Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:15:18.314995","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:15:18.844101Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:15:19.500503Z","level":"error","event":"25/09/01 05:15:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:19.625681Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:19.625880Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:21.544714Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:15:52.694217","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:15:53.211723Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:15:53.852401Z","level":"error","event":"25/09/01 05:15:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:53.995300Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:53.995522Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:54.779341Z","level":"error","event":"25/09/01 05:15:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:56.068385Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:16:26.573564","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:16:27.661447Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:16:29.013745Z","level":"error","event":"25/09/01 05:16:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:16:29.330660Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:16:29.336155Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:16:31.086438Z","level":"error","event":"25/09/01 05:16:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:16:33.580008Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:17:04.696985","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:17:05.379398Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:17:06.235876Z","level":"error","event":"25/09/01 05:17:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:06.389764Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:06.390030Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:07.342487Z","level":"error","event":"25/09/01 05:17:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:08.670560Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:17:39.637339","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:17:40.296684Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:17:41.007582Z","level":"error","event":"25/09/01 05:17:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:41.128552Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:41.128772Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:41.898731Z","level":"error","event":"25/09/01 05:17:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:43.057644Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:18:13.580268","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:18:14.119933Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:18:14.845031Z","level":"error","event":"25/09/01 05:18:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:14.999760Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:15.000012Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:15.624512Z","level":"error","event":"25/09/01 05:18:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:16.704638Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:18:47.414371","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:18:48.002026Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:18:48.618807Z","level":"error","event":"25/09/01 05:18:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:48.757448Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:48.757712Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:49.365491Z","level":"error","event":"25/09/01 05:18:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:50.712725Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:19:21.973297","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:19:22.537427Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:19:23.165874Z","level":"error","event":"25/09/01 05:19:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:23.306666Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:23.306889Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:25.258112Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:19:55.769726","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:19:56.361793Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.018847Z","level":"error","event":"25/09/01 05:19:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.148343Z","level":"error","event":"25/09/01 05:19:57 WARN DependencyUtils: Local jar /opt/spark/jars/hadoop-aws-3.3.4.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.303304Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Running Spark version 3.5.6","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.307549Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.307716Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.328862Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.333591Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.333759Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.333839Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.348938Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.352239Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.355813Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.386348Z","level":"error","event":"25/09/01 05:19:57 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.389567Z","level":"error","event":"25/09/01 05:19:57 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.389727Z","level":"error","event":"25/09/01 05:19:57 INFO SecurityManager: Changing view acls groups to:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.389802Z","level":"error","event":"25/09/01 05:19:57 INFO SecurityManager: Changing modify acls groups to:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.389866Z","level":"error","event":"25/09/01 05:19:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.527839Z","level":"error","event":"25/09/01 05:19:57 INFO Utils: Successfully started service 'sparkDriver' on port 43489.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.545860Z","level":"error","event":"25/09/01 05:19:57 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.570660Z","level":"error","event":"25/09/01 05:19:57 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.587214Z","level":"error","event":"25/09/01 05:19:57 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.587424Z","level":"error","event":"25/09/01 05:19:57 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.591900Z","level":"error","event":"25/09/01 05:19:57 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.603550Z","level":"error","event":"25/09/01 05:19:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-86f784d9-2425-4cc6-a637-8b71b6936d7e","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.620600Z","level":"error","event":"25/09/01 05:19:57 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.638332Z","level":"error","event":"25/09/01 05:19:57 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.751571Z","level":"error","event":"25/09/01 05:19:57 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.804664Z","level":"error","event":"25/09/01 05:19:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.841129Z","level":"error","event":"25/09/01 05:19:57 ERROR SparkContext: Failed to add /opt/spark/jars/hadoop-aws-3.3.4.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.841426Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/hadoop-aws-3.3.4.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.841517Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.841577Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.841630Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.841680Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.841760Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.841827Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.841923Z","level":"error","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.841990Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842053Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842123Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842188Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842252Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842309Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842362Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842423Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842487Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842544Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842609Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842676Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842734Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842788Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.842845Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.849512Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://16de1778b869:43489/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756703997298","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.849768Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://16de1778b869:43489/jars/ojdbc11.jar with timestamp 1756703997298","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.849929Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Added JAR /opt/spark/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar at spark://16de1778b869:43489/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar with timestamp 1756703997298","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.850031Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Added JAR /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar at spark://16de1778b869:43489/jars/iceberg-aws-bundle-1.9.2.jar with timestamp 1756703997298","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.904849Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: Starting executor ID driver on host 16de1778b869","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.905043Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.910425Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.914692Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/*,file:/opt/airflow/*'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.914878Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@8c89914 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.921720Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: Fetching spark://16de1778b869:43489/jars/ojdbc11.jar with timestamp 1756703997298","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.972868Z","level":"error","event":"25/09/01 05:19:57 INFO TransportClientFactory: Successfully created connection to 16de1778b869/172.18.0.7:43489 after 25 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.977867Z","level":"error","event":"25/09/01 05:19:57 INFO Utils: Fetching spark://16de1778b869:43489/jars/ojdbc11.jar to /tmp/spark-9003cf4f-8072-442a-8575-20d9943318da/userFiles-f7580881-832b-4f89-ae1a-2b26858c3793/fetchFileTemp13521714624933575069.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.007117Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Adding file:/tmp/spark-9003cf4f-8072-442a-8575-20d9943318da/userFiles-f7580881-832b-4f89-ae1a-2b26858c3793/ojdbc11.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.012496Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Fetching spark://16de1778b869:43489/jars/iceberg-aws-bundle-1.9.2.jar with timestamp 1756703997298","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.012677Z","level":"error","event":"25/09/01 05:19:58 INFO Utils: Fetching spark://16de1778b869:43489/jars/iceberg-aws-bundle-1.9.2.jar to /tmp/spark-9003cf4f-8072-442a-8575-20d9943318da/userFiles-f7580881-832b-4f89-ae1a-2b26858c3793/fetchFileTemp1039059408297492555.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.104539Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Adding file:/tmp/spark-9003cf4f-8072-442a-8575-20d9943318da/userFiles-f7580881-832b-4f89-ae1a-2b26858c3793/iceberg-aws-bundle-1.9.2.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.114099Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Fetching spark://16de1778b869:43489/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar with timestamp 1756703997298","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.118436Z","level":"error","event":"25/09/01 05:19:58 INFO Utils: Fetching spark://16de1778b869:43489/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar to /tmp/spark-9003cf4f-8072-442a-8575-20d9943318da/userFiles-f7580881-832b-4f89-ae1a-2b26858c3793/fetchFileTemp3945911950632847563.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.227123Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Adding file:/tmp/spark-9003cf4f-8072-442a-8575-20d9943318da/userFiles-f7580881-832b-4f89-ae1a-2b26858c3793/iceberg-spark-runtime-3.5_2.13-1.9.2.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.234169Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Fetching spark://16de1778b869:43489/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756703997298","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.234426Z","level":"error","event":"25/09/01 05:19:58 INFO Utils: Fetching spark://16de1778b869:43489/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-9003cf4f-8072-442a-8575-20d9943318da/userFiles-f7580881-832b-4f89-ae1a-2b26858c3793/fetchFileTemp13937271470155778677.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.981303Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Adding file:/tmp/spark-9003cf4f-8072-442a-8575-20d9943318da/userFiles-f7580881-832b-4f89-ae1a-2b26858c3793/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.988890Z","level":"error","event":"25/09/01 05:19:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32841.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.991892Z","level":"error","event":"25/09/01 05:19:58 INFO NettyBlockTransferService: Server created on 16de1778b869:32841","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.992043Z","level":"error","event":"25/09/01 05:19:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.995217Z","level":"error","event":"25/09/01 05:19:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 16de1778b869, 32841, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.997560Z","level":"error","event":"25/09/01 05:19:58 INFO BlockManagerMasterEndpoint: Registering block manager 16de1778b869:32841 with 434.4 MiB RAM, BlockManagerId(driver, 16de1778b869, 32841, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.000339Z","level":"error","event":"25/09/01 05:19:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 16de1778b869, 32841, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.000491Z","level":"error","event":"25/09/01 05:19:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 16de1778b869, 32841, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.261607Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.275345Z","level":"error","event":"25/09/01 05:19:59 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.275475Z","level":"error","event":"25/09/01 05:19:59 INFO SparkContext: SparkContext is stopping with exitCode 0.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.282538Z","level":"error","event":"25/09/01 05:19:59 INFO SparkUI: Stopped Spark web UI at http://16de1778b869:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.289308Z","level":"error","event":"25/09/01 05:19:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.297118Z","level":"error","event":"25/09/01 05:19:59 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.300063Z","level":"error","event":"25/09/01 05:19:59 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.302369Z","level":"error","event":"25/09/01 05:19:59 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.306717Z","level":"error","event":"25/09/01 05:19:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.360990Z","level":"error","event":"25/09/01 05:19:59 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.365567Z","level":"error","event":"25/09/01 05:19:59 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.365726Z","level":"error","event":"25/09/01 05:19:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-9003cf4f-8072-442a-8575-20d9943318da/pyspark-f4f0a68a-73f1-4ab1-b956-e35a7a2b20a6","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.365795Z","level":"error","event":"25/09/01 05:19:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-3e4f5305-f18b-4352-b2b4-e9113bcc22b5","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.369746Z","level":"error","event":"25/09/01 05:19:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-9003cf4f-8072-442a-8575-20d9943318da","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:29:32.951789","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:29:35.468732Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:29:35.468906Z","level":"error","event":"25/09/01 05:29:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:29:35.654291Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:29:35.654573Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:29:36.828820Z","level":"error","event":"25/09/01 05:29:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:29:39.433055Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:30:10.864493","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:30:12.236811Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:30:13.229978Z","level":"error","event":"25/09/01 05:30:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:13.487746Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:13.488600Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:14.667763Z","level":"error","event":"25/09/01 05:30:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:16.820019Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:30:48.274537","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:30:49.086952Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:30:49.913802Z","level":"error","event":"25/09/01 05:30:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:50.104494Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:50.104704Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:52.998430Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:31:23.547757","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:31:24.088643Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:31:24.801209Z","level":"error","event":"25/09/01 05:31:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:31:24.962032Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:31:24.962203Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:31:26.984240Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:31:57.832443","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:31:58.445353Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:31:59.295748Z","level":"error","event":"25/09/01 05:31:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:31:59.459222Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:31:59.459388Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:02.065818Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:32:33.153223","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:32:33.731193Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:32:34.524304Z","level":"error","event":"25/09/01 05:32:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:34.687401Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:34.687566Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:36.739040Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:33:07.402347","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:33:08.213882Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:33:08.881844Z","level":"error","event":"25/09/01 05:33:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:09.042381Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:09.042557Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:10.981908Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:33:42.438248","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:33:43.137490Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:33:43.742085Z","level":"error","event":"25/09/01 05:33:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:43.859418Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:43.859605Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:45.693925Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:34:16.831647","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:34:17.577054Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:34:18.193011Z","level":"error","event":"25/09/01 05:34:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:18.313899Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:18.314144Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:18.981266Z","level":"error","event":"25/09/01 05:34:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:20.371699Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:34:51.254562","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:34:51.829198Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:34:52.420718Z","level":"error","event":"25/09/01 05:34:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:52.564683Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:52.564881Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:53.212718Z","level":"error","event":"25/09/01 05:34:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:54.651814Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:35:26.032548","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:35:26.643290Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:35:27.443268Z","level":"error","event":"25/09/01 05:35:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:35:27.689932Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:35:27.690344Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:35:30.796671Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:36:01.445863","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:36:02.020570Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:36:02.617747Z","level":"error","event":"25/09/01 05:36:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:02.763224Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:02.763407Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:03.327809Z","level":"error","event":"25/09/01 05:36:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:04.611694Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:36:35.739762","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:36:36.344068Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:36:37.049435Z","level":"error","event":"25/09/01 05:36:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:37.197917Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:37.198082Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:37.750657Z","level":"error","event":"25/09/01 05:36:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:39.133628Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:37:10.332293","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:37:10.908764Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:37:11.558097Z","level":"error","event":"25/09/01 05:37:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:37:11.828267Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:37:11.828464Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:37:12.592648Z","level":"error","event":"25/09/01 05:37:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:37:13.995107Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:01.596440","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:40:04.284303Z","level":"error","event":"25/09/01 05:40:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:04.555790Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:04.555978Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:05.905739Z","level":"error","event":"25/09/01 05:40:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.371341Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.371662Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.371769Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.371828Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.371896Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.371954Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372005Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372079Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372130Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372188Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372240Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372295Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372344Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372394Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372447Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372496Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372545Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372596Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372646Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.372700Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.371468","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:40:39.451770","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:40:41.144458Z","level":"error","event":"25/09/01 05:40:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:41.385307Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:41.385622Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.098366Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.098589Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.098668Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.098731Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.098788Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.098846Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.098913Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.098976Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099041Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099103Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099163Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099221Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099281Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099339Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099415Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099475Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099534Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099597Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099652Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.099705Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.098509","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:41:15.359317","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:41:16.763546Z","level":"error","event":"25/09/01 05:41:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:16.954973Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:16.959082Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130021Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130216Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130292Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130354Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130413Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130471Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130526Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130587Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130644Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130705Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130769Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130829Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130914Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.130979Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.131039Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.131095Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.131155Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.131212Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.131261Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.131312Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.129961","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:41:50.422120","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:41:51.806913Z","level":"error","event":"25/09/01 05:41:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:51.987489Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:51.990598Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:52.876432Z","level":"error","event":"25/09/01 05:41:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.268781Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.268950Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.268993Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269037Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269068Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269109Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269140Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269171Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269199Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269227Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269256Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269284Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269312Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269340Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269368Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269394Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269421Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269449Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269476Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.269515Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.268881","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:42:25.559143","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:42:26.863290Z","level":"error","event":"25/09/01 05:42:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:42:27.028467Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:42:27.032866Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:42:27.773425Z","level":"error","event":"25/09/01 05:42:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009074Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009213Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009254Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009287Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009318Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009347Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009376Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009405Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009435Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009464Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009492Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009521Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009559Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009588Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009617Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009644Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009671Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009698Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009725Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009753Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:29.009192","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:43:00.175147","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:43:01.510590Z","level":"error","event":"25/09/01 05:43:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:01.680778Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:01.680962Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:02.366778Z","level":"error","event":"25/09/01 05:43:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.694754Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.694949Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695023Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695070Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695102Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695131Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695158Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695202Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695250Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695302Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695354Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695401Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695447Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695496Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695550Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695600Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695650Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695698Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695758Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.695809Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.694926","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:43:34.737008","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:43:36.266135Z","level":"error","event":"25/09/01 05:43:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:36.445033Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:36.445076Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:37.104522Z","level":"error","event":"25/09/01 05:43:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.605492Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.605667Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.605719Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.605754Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.605785Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.605823Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.605893Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.605955Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606012Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606047Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606079Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606111Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606141Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606174Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606211Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606249Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606280Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606311Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606346Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.606380Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.605681","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:44:09.274111","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:44:10.466404Z","level":"error","event":"25/09/01 05:44:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:10.631460Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:10.631643Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660020Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660231Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660307Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660353Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660387Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660419Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660451Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660483Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660512Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660557Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660590Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660620Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660649Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660680Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660708Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660737Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660766Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660795Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660823Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660866Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.660116","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:44:43.864219","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:44:45.062993Z","level":"error","event":"25/09/01 05:44:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:45.229014Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:45.229242Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.349563Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.349710Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.349755Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.349791Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.349824Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.349895Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.349931Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.349961Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.349992Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.350021Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.350050Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.350080Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.350110Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.350139Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.350168Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.350197Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.350226Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.350266Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.350296Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.350327Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.349662","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:46:32.703242","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:46:35.144372Z","level":"error","event":"25/09/01 05:46:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:46:35.395227Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:46:35.395495Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.138913Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139186Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139306Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139386Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139452Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139515Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139574Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139635Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139697Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139762Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139825Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139901Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139966Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.140029Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.140094Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.140157Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.140219Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.140285Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.140346Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.140409Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.139121","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:47:10.037418","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:47:11.494015Z","level":"error","event":"25/09/01 05:47:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:11.745887Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:11.746096Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:12.767015Z","level":"error","event":"25/09/01 05:47:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.298760Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.298996Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299054Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299116Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299151Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299186Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299219Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299250Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299297Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299330Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299360Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299389Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299417Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299446Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299475Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299502Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299531Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299564Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299611Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.299647Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.298878","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:47:45.395439","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:47:47.700420Z","level":"error","event":"25/09/01 05:47:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:47.916722Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:47.916999Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:49.085475Z","level":"error","event":"25/09/01 05:47:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604051Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604191Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604235Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604272Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604309Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604343Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604374Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604403Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604434Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604464Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604494Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604523Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604553Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604583Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604625Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604669Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604700Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604729Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604758Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604787Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.604157","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:49:20.284047","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:49:22.670376Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:49:22.711999Z","level":"error","event":"25/09/01 05:49:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:23.107918Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:23.109570Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:24.263946Z","level":"error","event":"25/09/01 05:49:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:26.567377Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:49:57.313947","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:49:57.895065Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:49:58.628952Z","level":"error","event":"25/09/01 05:49:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:58.757826Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:58.758019Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:50:00.915178Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:50:32.045571","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:50:32.643199Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:50:33.352997Z","level":"error","event":"25/09/01 05:50:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:50:33.521384Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:50:33.521586Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:50:34.390278Z","level":"error","event":"25/09/01 05:50:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:50:35.683911Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:51:06.213269","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:51:07.001327Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:51:07.926967Z","level":"error","event":"25/09/01 05:51:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:08.188474Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:08.188660Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:09.044243Z","level":"error","event":"25/09/01 05:51:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:10.478973Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:51:41.005520","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:51:41.543575Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:51:42.190509Z","level":"error","event":"25/09/01 05:51:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:42.431115Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:42.431483Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:44.481713Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:52:15.874172","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:52:16.407548Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:52:17.044237Z","level":"error","event":"25/09/01 05:52:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:17.177831Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:17.178055Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:19.077935Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:52:50.275880","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:52:51.005071Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:52:51.696054Z","level":"error","event":"25/09/01 05:52:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:51.881797Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:51.882122Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:53.738695Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:53:25.048072","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:53:25.757567Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:53:26.371479Z","level":"error","event":"25/09/01 05:53:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:53:26.479267Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:53:26.479423Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:53:28.549814Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:53:59.784888","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:54:00.310157Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:54:00.909174Z","level":"error","event":"25/09/01 05:54:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:01.100255Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:01.100730Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:03.326074Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:54:33.858817","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:54:34.410127Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:54:35.034218Z","level":"error","event":"25/09/01 05:54:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:35.154926Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:35.155065Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:35.848372Z","level":"error","event":"25/09/01 05:54:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:37.153254Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:55:07.660566","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:55:08.205330Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:55:08.854601Z","level":"error","event":"25/09/01 05:55:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:08.998972Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:08.999200Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:11.133887Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:55:42.563039","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:55:43.217340Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:55:43.949523Z","level":"error","event":"25/09/01 05:55:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:44.079930Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:44.080139Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:46.157700Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:56:17.487125","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:56:18.057247Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:56:18.736999Z","level":"error","event":"25/09/01 05:56:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:18.918623Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:18.918899Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:19.570579Z","level":"error","event":"25/09/01 05:56:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:21.036085Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:56:52.079642","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:56:52.632869Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:56:53.340498Z","level":"error","event":"25/09/01 05:56:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:53.534837Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:53.535063Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:55.657851Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:57:27.052382","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:57:27.560100Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:57:28.130275Z","level":"error","event":"25/09/01 05:57:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:57:28.249465Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:57:28.249693Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:57:30.037549Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:58:01.211553","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:58:01.825991Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:58:02.653087Z","level":"error","event":"25/09/01 05:58:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:02.824216Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:02.824446Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:03.526289Z","level":"error","event":"25/09/01 05:58:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:04.898186Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:58:36.186003","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:58:36.703233Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:58:37.325470Z","level":"error","event":"25/09/01 05:58:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:37.498347Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:37.498530Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:39.553114Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:59:10.740457","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:59:11.324152Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:59:12.012264Z","level":"error","event":"25/09/01 05:59:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:12.211460Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:12.211623Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:14.321913Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:59:44.905254","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:59:45.459592Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:59:46.077282Z","level":"error","event":"25/09/01 05:59:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:46.207784Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:46.208077Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:48.021292Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:00:19.325953","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:00:19.869447Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:00:20.524604Z","level":"error","event":"25/09/01 06:00:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:20.686573Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:20.686718Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:21.477619Z","level":"error","event":"25/09/01 06:00:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:22.936085Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:00:53.568171","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:00:54.092630Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:00:54.797613Z","level":"error","event":"25/09/01 06:00:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:54.942217Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:54.942384Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:55.639202Z","level":"error","event":"25/09/01 06:00:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:57.125998Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:01:27.798806","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:01:28.336847Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:01:28.956137Z","level":"error","event":"25/09/01 06:01:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:01:29.116978Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:01:29.117172Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:01:31.378175Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:05:52.320072","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:05:54.676488Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:05:54.729063Z","level":"error","event":"25/09/01 06:05:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:05:55.141067Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:05:55.141348Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:05:56.324269Z","level":"error","event":"25/09/01 06:05:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:05:58.595132Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:06:29.773813","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:06:30.501343Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:06:31.318016Z","level":"error","event":"25/09/01 06:06:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:06:31.524282Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:06:31.524440Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:06:32.468613Z","level":"error","event":"25/09/01 06:06:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:06:34.550360Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:07:05.211605","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:07:05.848708Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:07:06.607564Z","level":"error","event":"25/09/01 06:07:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:06.817075Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:06.817261Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:08.758427Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:07:39.852644","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:07:40.539278Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:07:41.190412Z","level":"error","event":"25/09/01 06:07:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:41.327671Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:41.330404Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:43.242070Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:08:14.365491","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:08:14.938778Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:08:15.639266Z","level":"error","event":"25/09/01 06:08:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:15.799517Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:15.799679Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:16.553545Z","level":"error","event":"25/09/01 06:08:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:17.890331Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:08:49.290408","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:08:49.820266Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:08:50.486919Z","level":"error","event":"25/09/01 06:08:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:50.633027Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:50.633176Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:51.230579Z","level":"error","event":"25/09/01 06:08:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:52.527488Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:09:23.812931","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:09:24.580932Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.203841Z","level":"error","event":"25/09/01 06:09:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.343590Z","level":"error","event":"25/09/01 06:09:25 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.427937Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Running Spark version 3.5.6","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.431322Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.431438Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.447898Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.450685Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.450791Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.450829Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.462802Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.468664Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.468759Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.499590Z","level":"error","event":"25/09/01 06:09:25 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.503595Z","level":"error","event":"25/09/01 06:09:25 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.503708Z","level":"error","event":"25/09/01 06:09:25 INFO SecurityManager: Changing view acls groups to:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.503754Z","level":"error","event":"25/09/01 06:09:25 INFO SecurityManager: Changing modify acls groups to:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.503787Z","level":"error","event":"25/09/01 06:09:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.675010Z","level":"error","event":"25/09/01 06:09:25 INFO Utils: Successfully started service 'sparkDriver' on port 33063.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.693865Z","level":"error","event":"25/09/01 06:09:25 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.731107Z","level":"error","event":"25/09/01 06:09:25 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.758149Z","level":"error","event":"25/09/01 06:09:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.758210Z","level":"error","event":"25/09/01 06:09:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.762472Z","level":"error","event":"25/09/01 06:09:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.779235Z","level":"error","event":"25/09/01 06:09:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-40f7266b-b486-40ae-859f-baa02352c773","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.794152Z","level":"error","event":"25/09/01 06:09:25 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.810503Z","level":"error","event":"25/09/01 06:09:25 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.901198Z","level":"error","event":"25/09/01 06:09:25 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.940909Z","level":"error","event":"25/09/01 06:09:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.943967Z","level":"error","event":"25/09/01 06:09:25 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.980133Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.4.jar at spark://af5d5ce08564:33063/jars/hadoop-aws-3.3.4.jar with timestamp 1756706965422","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985109Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://af5d5ce08564:33063/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756706965422","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985288Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://af5d5ce08564:33063/jars/ojdbc11.jar with timestamp 1756706965422","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985374Z","level":"error","event":"25/09/01 06:09:25 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985428Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985483Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985537Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985586Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985638Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985702Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985750Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985793Z","level":"error","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985836Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985894Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985943Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.985996Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986041Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986084Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986131Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986179Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986227Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986272Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986322Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986370Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986414Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986460Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986506Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.986554Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Added JAR /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar at spark://af5d5ce08564:33063/jars/iceberg-aws-bundle-1.9.2.jar with timestamp 1756706965422","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.025377Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Starting executor ID driver on host af5d5ce08564","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.025484Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.025533Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.028048Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/*,file:/opt/airflow/*'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.030131Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@ddcde0b for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.035699Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Fetching spark://af5d5ce08564:33063/jars/iceberg-aws-bundle-1.9.2.jar with timestamp 1756706965422","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.066380Z","level":"error","event":"25/09/01 06:09:26 INFO TransportClientFactory: Successfully created connection to af5d5ce08564/172.18.0.11:33063 after 15 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.071428Z","level":"error","event":"25/09/01 06:09:26 INFO Utils: Fetching spark://af5d5ce08564:33063/jars/iceberg-aws-bundle-1.9.2.jar to /tmp/spark-38fa4481-93e4-406c-bbac-ad1e4222fb6c/userFiles-06b42975-bfcc-4469-92af-44af1740dde9/fetchFileTemp8003254655022610961.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.182567Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Adding file:/tmp/spark-38fa4481-93e4-406c-bbac-ad1e4222fb6c/userFiles-06b42975-bfcc-4469-92af-44af1740dde9/iceberg-aws-bundle-1.9.2.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.188557Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Fetching spark://af5d5ce08564:33063/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756706965422","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.188766Z","level":"error","event":"25/09/01 06:09:26 INFO Utils: Fetching spark://af5d5ce08564:33063/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-38fa4481-93e4-406c-bbac-ad1e4222fb6c/userFiles-06b42975-bfcc-4469-92af-44af1740dde9/fetchFileTemp8486732158631138786.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.817779Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Adding file:/tmp/spark-38fa4481-93e4-406c-bbac-ad1e4222fb6c/userFiles-06b42975-bfcc-4469-92af-44af1740dde9/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.821562Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Fetching spark://af5d5ce08564:33063/jars/hadoop-aws-3.3.4.jar with timestamp 1756706965422","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.821708Z","level":"error","event":"25/09/01 06:09:26 INFO Utils: Fetching spark://af5d5ce08564:33063/jars/hadoop-aws-3.3.4.jar to /tmp/spark-38fa4481-93e4-406c-bbac-ad1e4222fb6c/userFiles-06b42975-bfcc-4469-92af-44af1740dde9/fetchFileTemp11681388828787907290.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.825246Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Adding file:/tmp/spark-38fa4481-93e4-406c-bbac-ad1e4222fb6c/userFiles-06b42975-bfcc-4469-92af-44af1740dde9/hadoop-aws-3.3.4.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.828376Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Fetching spark://af5d5ce08564:33063/jars/ojdbc11.jar with timestamp 1756706965422","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.828485Z","level":"error","event":"25/09/01 06:09:26 INFO Utils: Fetching spark://af5d5ce08564:33063/jars/ojdbc11.jar to /tmp/spark-38fa4481-93e4-406c-bbac-ad1e4222fb6c/userFiles-06b42975-bfcc-4469-92af-44af1740dde9/fetchFileTemp3751812558585566855.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.840278Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Adding file:/tmp/spark-38fa4481-93e4-406c-bbac-ad1e4222fb6c/userFiles-06b42975-bfcc-4469-92af-44af1740dde9/ojdbc11.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.849036Z","level":"error","event":"25/09/01 06:09:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36993.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.851936Z","level":"error","event":"25/09/01 06:09:26 INFO NettyBlockTransferService: Server created on af5d5ce08564:36993","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.852032Z","level":"error","event":"25/09/01 06:09:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.856969Z","level":"error","event":"25/09/01 06:09:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, af5d5ce08564, 36993, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.859624Z","level":"error","event":"25/09/01 06:09:26 INFO BlockManagerMasterEndpoint: Registering block manager af5d5ce08564:36993 with 434.4 MiB RAM, BlockManagerId(driver, af5d5ce08564, 36993, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.862282Z","level":"error","event":"25/09/01 06:09:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, af5d5ce08564, 36993, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.864929Z","level":"error","event":"25/09/01 06:09:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, af5d5ce08564, 36993, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.089972Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.104535Z","level":"error","event":"25/09/01 06:09:27 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.106780Z","level":"error","event":"25/09/01 06:09:27 INFO SparkContext: SparkContext is stopping with exitCode 0.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.111246Z","level":"error","event":"25/09/01 06:09:27 INFO SparkUI: Stopped Spark web UI at http://af5d5ce08564:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.116047Z","level":"error","event":"25/09/01 06:09:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.125443Z","level":"error","event":"25/09/01 06:09:27 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.125563Z","level":"error","event":"25/09/01 06:09:27 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.130401Z","level":"error","event":"25/09/01 06:09:27 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.133776Z","level":"error","event":"25/09/01 06:09:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.180488Z","level":"error","event":"25/09/01 06:09:27 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.184069Z","level":"error","event":"25/09/01 06:09:27 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.184165Z","level":"error","event":"25/09/01 06:09:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-1c4288f9-9e49-4a8b-9999-3cd259e1421c","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.186075Z","level":"error","event":"25/09/01 06:09:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-38fa4481-93e4-406c-bbac-ad1e4222fb6c","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.187740Z","level":"error","event":"25/09/01 06:09:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-38fa4481-93e4-406c-bbac-ad1e4222fb6c/pyspark-e698f53d-3a54-48b7-80c6-337ead9c266e","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:25:48.987240","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:25:48.989006","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'cx_Oracle'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":2,"name":"<module>"}]}]}
{"timestamp":"2025-09-01T06:26:21.347433","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:26:21.348722","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'cx_Oracle'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":2,"name":"<module>"}]}]}
{"timestamp":"2025-09-01T06:36:02.479329","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:36:04.688956Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:36:04.708028Z","level":"error","event":"25/09/01 06:36:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:04.970972Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:04.971176Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:06.127992Z","level":"error","event":"25/09/01 06:36:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:08.546495Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:36:39.348239","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:36:39.925576Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:36:40.850244Z","level":"error","event":"25/09/01 06:36:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:41.069477Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:41.069753Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:43.735417Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:37:15.229234","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:37:15.851318Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:37:16.668939Z","level":"error","event":"25/09/01 06:37:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:16.940870Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:16.945251Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:17.764012Z","level":"error","event":"25/09/01 06:37:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:19.127614Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:37:50.267112","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:37:50.862482Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:37:51.569410Z","level":"error","event":"25/09/01 06:37:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:51.713256Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:51.716496Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:53.815113Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:38:24.926372","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:38:25.500020Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:38:26.107021Z","level":"error","event":"25/09/01 06:38:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:38:26.250951Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:38:26.251102Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:38:26.894977Z","level":"error","event":"25/09/01 06:38:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:38:28.157422Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:38:59.090367","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:38:59.747293Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:39:00.535358Z","level":"error","event":"25/09/01 06:39:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:00.760586Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:00.760819Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:03.191695Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:39:34.052677","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:39:34.602784Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:39:35.306518Z","level":"error","event":"25/09/01 06:39:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:35.494078Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:35.494333Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:36.194884Z","level":"error","event":"25/09/01 06:39:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:37.770613Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:40:08.245385","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:40:08.749051Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:40:09.354885Z","level":"error","event":"25/09/01 06:40:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:09.505181Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:09.505369Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:11.392648Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:40:42.013973","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:40:42.651654Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:40:43.257471Z","level":"error","event":"25/09/01 06:40:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:43.389833Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:43.390089Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:45.121867Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:41:15.623124","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:41:16.101459Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:41:16.666018Z","level":"error","event":"25/09/01 06:41:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:16.771121Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:16.771273Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:18.392708Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:41:49.296114","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:41:49.854198Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:41:50.442664Z","level":"error","event":"25/09/01 06:41:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:50.563018Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:50.563172Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:52.180606Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:42:22.664322","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:42:23.153828Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:42:23.780246Z","level":"error","event":"25/09/01 06:42:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:42:23.921339Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:42:23.921664Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:42:25.840866Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:42:56.404778","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:42:56.894746Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:42:57.487541Z","level":"error","event":"25/09/01 06:42:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:42:57.602427Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:42:57.602569Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:42:59.314813Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:43:30.585696","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:43:31.127185Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:43:31.748231Z","level":"error","event":"25/09/01 06:43:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:43:31.872451Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:43:31.872604Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:43:33.982473Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:44:05.400325","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:44:05.881464Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:44:06.468185Z","level":"error","event":"25/09/01 06:44:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:06.612184Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:06.612351Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:08.332681Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:44:39.388681","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:44:39.849206Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:44:40.501300Z","level":"error","event":"25/09/01 06:44:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:40.624331Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:40.624535Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:42.343764Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:45:12.955653","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:45:13.427055Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:45:13.996954Z","level":"error","event":"25/09/01 06:45:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:14.134082Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:14.134304Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:15.959622Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:45:46.666153","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:45:47.178193Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:45:47.833646Z","level":"error","event":"25/09/01 06:45:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:47.972181Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:47.972412Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:50.127707Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:46:21.418332","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:46:21.946669Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:46:22.559933Z","level":"error","event":"25/09/01 06:46:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:22.732768Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:22.733038Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:24.780367Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:46:55.292775","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:46:55.800282Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:46:56.401433Z","level":"error","event":"25/09/01 06:46:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:56.531606Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:56.536206Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:58.290034Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:47:29.539998","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:47:30.050795Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:47:30.672696Z","level":"error","event":"25/09/01 06:47:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:47:30.798696Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:47:30.798838Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:47:31.530143Z","level":"error","event":"25/09/01 06:47:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:47:32.772283Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:48:03.750686","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:48:04.524942Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:48:05.376155Z","level":"error","event":"25/09/01 06:48:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:05.599820Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:05.600149Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:09.181532Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:48:40.042712","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:48:40.645696Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:48:41.441498Z","level":"error","event":"25/09/01 06:48:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:41.658459Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:41.658635Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:42.488336Z","level":"error","event":"25/09/01 06:48:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:44.173320Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:49:15.588991","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:49:16.230374Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:49:16.918979Z","level":"error","event":"25/09/01 06:49:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:17.099552Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:17.103727Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:19.205355Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:49:49.902620","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:49:50.401595Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:49:51.021152Z","level":"error","event":"25/09/01 06:49:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:51.197479Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:51.197673Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:53.089526Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:50:23.656644","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:50:24.297081Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:50:25.020445Z","level":"error","event":"25/09/01 06:50:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:50:25.174604Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:50:25.174833Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:50:27.308265Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:50:57.792806","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:50:58.445643Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:50:59.122697Z","level":"error","event":"25/09/01 06:50:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:50:59.301259Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:50:59.301511Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:51:02.222500Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:51:32.810124","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:51:33.436853Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:51:34.120325Z","level":"error","event":"25/09/01 06:51:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:51:34.304183Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:51:34.304392Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:51:36.479525Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:52:07.012754","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:52:07.676169Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:52:08.368724Z","level":"error","event":"25/09/01 06:52:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:08.546107Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:08.546340Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:10.683702Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:52:42.132218","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:52:42.712849Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:52:43.443225Z","level":"error","event":"25/09/01 06:52:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:43.614254Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:43.617959Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:44.389232Z","level":"error","event":"25/09/01 06:52:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:45.788936Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:53:16.949232","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:53:17.727487Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:53:18.730732Z","level":"error","event":"25/09/01 06:53:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:19.050941Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:19.051202Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:21.587451Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:53:52.777521","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:53:53.552693Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:53:54.187320Z","level":"error","event":"25/09/01 06:53:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:54.344336Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:54.344500Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:56.165075Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:54:27.367103","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:54:28.214574Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:54:28.811712Z","level":"error","event":"25/09/01 06:54:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:54:28.947513Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:54:28.947706Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:54:31.109426Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:55:02.203106","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:55:03.020346Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:55:03.654240Z","level":"error","event":"25/09/01 06:55:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:03.797781Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:03.797994Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:05.734846Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:55:37.112268","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:55:37.953136Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:55:38.681463Z","level":"error","event":"25/09/01 06:55:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:38.793136Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:38.793283Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:39.480548Z","level":"error","event":"25/09/01 06:55:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:40.881720Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:56:12.035379","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:56:12.814991Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:56:13.520637Z","level":"error","event":"25/09/01 06:56:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:13.661902Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:13.664795Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:14.946371Z","level":"error","event":"25/09/01 06:56:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:16.680191Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:56:47.405642","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:56:48.487634Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:56:50.173615Z","level":"error","event":"25/09/01 06:56:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:51.031824Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:51.032252Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:55.517006Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:57:26.706353","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:57:27.296641Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:57:27.920691Z","level":"error","event":"25/09/01 06:57:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:57:28.051430Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:57:28.051616Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:57:30.171969Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:58:01.320382","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:58:02.104159Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:58:02.928577Z","level":"error","event":"25/09/01 06:58:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:03.094946Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:03.095124Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:05.629550Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:58:36.262847","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:58:36.854647Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:58:37.543273Z","level":"error","event":"25/09/01 06:58:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:37.735141Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:37.735315Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:38.437239Z","level":"error","event":"25/09/01 06:58:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:39.806869Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:59:10.371063","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:59:10.946193Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:59:11.574306Z","level":"error","event":"25/09/01 06:59:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:11.699999Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:11.700148Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:12.265288Z","level":"error","event":"25/09/01 06:59:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:13.584568Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:59:44.648802","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:59:45.210877Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:59:45.918205Z","level":"error","event":"25/09/01 06:59:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:46.071361Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:46.071604Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:46.816283Z","level":"error","event":"25/09/01 06:59:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:48.094049Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:00:19.234389","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:00:19.814091Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:00:20.446533Z","level":"error","event":"25/09/01 07:00:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:20.563406Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:20.563596Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:22.727103Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:00:53.897004","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:00:54.462292Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:00:55.132397Z","level":"error","event":"25/09/01 07:00:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:55.265677Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:55.265905Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:56.085951Z","level":"error","event":"25/09/01 07:00:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:57.523843Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:01:28.085820","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:01:28.728623Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:01:29.470070Z","level":"error","event":"25/09/01 07:01:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:01:29.660934Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:01:29.661250Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:01:30.587326Z","level":"error","event":"25/09/01 07:01:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:01:32.036024Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:02:03.159034","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:02:03.717455Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:02:04.339257Z","level":"error","event":"25/09/01 07:02:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:04.538316Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:04.538623Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:05.439957Z","level":"error","event":"25/09/01 07:02:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:07.169947Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:02:37.687575","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:02:38.227365Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:02:38.886223Z","level":"error","event":"25/09/01 07:02:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:39.026441Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:39.026563Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:41.253616Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:03:11.797739","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:03:12.287241Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:03:12.879511Z","level":"error","event":"25/09/01 07:03:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:13.016631Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:13.016790Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:14.906436Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:03:45.718784","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:03:46.296427Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:03:46.948979Z","level":"error","event":"25/09/01 07:03:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:47.105503Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:47.110816Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:49.626366Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:04:20.382647","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:04:20.908456Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:04:21.635946Z","level":"error","event":"25/09/01 07:04:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:21.803383Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:21.803585Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:23.772237Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:04:54.518377","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:04:55.080505Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:04:55.835612Z","level":"error","event":"25/09/01 07:04:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:56.002960Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:56.007791Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:58.210426Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:05:29.161349","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:05:29.785110Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:05:30.616817Z","level":"error","event":"25/09/01 07:05:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:05:30.830226Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:05:30.830508Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:05:33.681938Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:06:04.313898","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:06:04.831894Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:06:05.544176Z","level":"error","event":"25/09/01 07:06:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:05.703310Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:05.703500Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:08.188701Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:06:38.912689","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:06:39.600046Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:06:40.295225Z","level":"error","event":"25/09/01 07:06:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:40.465086Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:40.465353Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:42.522558Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:07:13.189806","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:07:13.746913Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:07:14.586080Z","level":"error","event":"25/09/01 07:07:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:14.710609Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:14.710820Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:16.614991Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:07:47.160826","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:07:47.698364Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:07:48.296061Z","level":"error","event":"25/09/01 07:07:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:48.435180Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:48.435409Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:50.377208Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:08:21.122341","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:08:21.629438Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:08:22.189203Z","level":"error","event":"25/09/01 07:08:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:22.408215Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:22.408627Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:24.351289Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:08:55.461563","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:08:56.012541Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:08:56.621823Z","level":"error","event":"25/09/01 07:08:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:56.794258Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:56.798192Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:58.704562Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:09:29.768281","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:09:30.374176Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:09:31.071332Z","level":"error","event":"25/09/01 07:09:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:09:31.228347Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:09:31.233468Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:09:33.513407Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:10:04.387434","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:10:04.939819Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:10:05.604413Z","level":"error","event":"25/09/01 07:10:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:05.725780Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:05.726054Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:07.736618Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:10:38.455483","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:10:39.169294Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:10:39.777741Z","level":"error","event":"25/09/01 07:10:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:39.940593Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:39.940774Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:42.209849Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:11:12.918259","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:11:13.662030Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:11:14.338946Z","level":"error","event":"25/09/01 07:11:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:14.490558Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:14.490799Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:16.483013Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:11:47.759326","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:11:48.270849Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:11:48.934114Z","level":"error","event":"25/09/01 07:11:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:49.132682Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:49.132892Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:51.087776Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:12:22.424451","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:12:22.980908Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:12:23.669127Z","level":"error","event":"25/09/01 07:12:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:23.835194Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:23.839304Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:24.524147Z","level":"error","event":"25/09/01 07:12:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:25.878225Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:12:56.440957","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:12:57.065428Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:12:57.679117Z","level":"error","event":"25/09/01 07:12:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:57.818587Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:57.818730Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:59.775343Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:13:30.392324","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:13:31.007749Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:13:31.621400Z","level":"error","event":"25/09/01 07:13:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:13:31.756864Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:13:31.757085Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:13:33.677457Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:14:05.058353","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:14:05.661965Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:14:06.307505Z","level":"error","event":"25/09/01 07:14:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:06.510636Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:06.510911Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:07.282557Z","level":"error","event":"25/09/01 07:14:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:08.620016Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:14:39.844747","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:14:40.425247Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:14:41.038125Z","level":"error","event":"25/09/01 07:14:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:41.213461Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:41.213645Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:43.328417Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:15:14.601000","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:15:15.137095Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:15:15.798192Z","level":"error","event":"25/09/01 07:15:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:15.929849Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:15.930023Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:16.628442Z","level":"error","event":"25/09/01 07:15:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:17.848395Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:15:48.463138","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:15:49.101035Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:15:49.869026Z","level":"error","event":"25/09/01 07:15:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:50.076242Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:50.081755Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:50.860823Z","level":"error","event":"25/09/01 07:15:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:52.459971Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:16:23.735912","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:16:24.365203Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:16:25.031467Z","level":"error","event":"25/09/01 07:16:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:16:25.185721Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:16:25.190143Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:16:27.326919Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:16:57.865286","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:16:58.855354Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:17:00.034085Z","level":"error","event":"25/09/01 07:17:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:00.270175Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:00.275306Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:01.510178Z","level":"error","event":"25/09/01 07:17:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:03.933359Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:17:34.754076","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:17:35.842809Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:17:37.127290Z","level":"error","event":"25/09/01 07:17:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:37.440245Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:37.440527Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:38.637530Z","level":"error","event":"25/09/01 07:17:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:41.059200Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:18:12.300750","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:18:13.370643Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:18:14.716156Z","level":"error","event":"25/09/01 07:18:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:14.993488Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:14.999731Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:18.469098Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:18:49.901315","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:18:50.855238Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:18:51.995997Z","level":"error","event":"25/09/01 07:18:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:52.299639Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:52.307323Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:53.491638Z","level":"error","event":"25/09/01 07:18:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:55.434960Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:19:26.329771","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:19:27.266037Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:19:28.510948Z","level":"error","event":"25/09/01 07:19:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:19:28.791096Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:19:28.799060Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:19:31.622015Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:20:02.578555","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:20:03.796372Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:20:05.051965Z","level":"error","event":"25/09/01 07:20:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:05.276388Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:05.276608Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:06.359816Z","level":"error","event":"25/09/01 07:20:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:08.238169Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:20:39.059540","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:20:39.977771Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:20:41.279771Z","level":"error","event":"25/09/01 07:20:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:41.506363Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:41.513577Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:44.660765Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:21:15.747806","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:21:16.730257Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:21:18.054140Z","level":"error","event":"25/09/01 07:21:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:18.426259Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:18.433381Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:21.733002Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:21:53.094717","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:21:54.080509Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:21:55.189556Z","level":"error","event":"25/09/01 07:21:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:55.404229Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:55.411414Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:57.904355Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:22:28.900082","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:22:30.193330Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:22:31.320777Z","level":"error","event":"25/09/01 07:22:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:22:31.564788Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:22:31.564985Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:22:34.290758Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:23:05.568659","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:23:06.556441Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:23:07.516771Z","level":"error","event":"25/09/01 07:23:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:07.724911Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:07.730843Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:10.762596Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:23:41.572906","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:23:42.630156Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:23:43.826619Z","level":"error","event":"25/09/01 07:23:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:44.057871Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:44.058119Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:47.596152Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:24:18.743713","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:24:19.713026Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:24:20.714850Z","level":"error","event":"25/09/01 07:24:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:20.908400Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:20.912603Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:23.426989Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:24:54.697594","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:24:55.500048Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:24:56.445489Z","level":"error","event":"25/09/01 07:24:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:56.655726Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:56.656021Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:59.318989Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:25:30.667095","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:25:31.472330Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:25:32.495355Z","level":"error","event":"25/09/01 07:25:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:25:32.732216Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:25:32.732458Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:25:35.508641Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:26:07.020238","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:26:07.917123Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:26:09.052256Z","level":"error","event":"25/09/01 07:26:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:09.313383Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:09.313762Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:12.134257Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:26:42.717226","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:26:43.531895Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:26:44.624766Z","level":"error","event":"25/09/01 07:26:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:44.805075Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:44.805365Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:47.698525Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:27:18.302294","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:27:19.290916Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:27:20.263914Z","level":"error","event":"25/09/01 07:27:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:27:20.454818Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:27:20.455049Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:27:23.633268Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:27:54.874580","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:27:55.887165Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:27:56.768587Z","level":"error","event":"25/09/01 07:27:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:27:57.027569Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:27:57.028120Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:27:59.822045Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:28:30.965037","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:28:31.777300Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:28:32.577449Z","level":"error","event":"25/09/01 07:28:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:28:32.775957Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:28:32.776419Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:28:35.117996Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:29:06.208466","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:29:07.030045Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:29:07.901988Z","level":"error","event":"25/09/01 07:29:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:08.060742Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:08.061249Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:10.453715Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:29:41.154445","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:29:41.858285Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:29:42.617183Z","level":"error","event":"25/09/01 07:29:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:42.764777Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:42.765002Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:44.944391Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:30:16.032718","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:30:16.851908Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:30:17.662645Z","level":"error","event":"25/09/01 07:30:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:30:17.868140Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:30:17.887201Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:30:20.083183Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:30:51.231962","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:30:52.081794Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:30:53.391829Z","level":"error","event":"25/09/01 07:30:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:30:53.621696Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:30:53.631960Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:30:56.609790Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:31:27.824279","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:31:28.678444Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:31:29.868246Z","level":"error","event":"25/09/01 07:31:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:31:30.238393Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:31:30.238868Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:31:32.782112Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:32:03.475795","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:32:04.186541Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:32:05.173740Z","level":"error","event":"25/09/01 07:32:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:05.360298Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:05.360631Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:07.364792Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:32:38.604612","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:32:39.579607Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:32:40.644887Z","level":"error","event":"25/09/01 07:32:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:40.828218Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:40.828619Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:43.143318Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:33:13.778505","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:33:14.564494Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:33:15.462514Z","level":"error","event":"25/09/01 07:33:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:15.693052Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:15.693609Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:18.011220Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:33:48.887750","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:33:49.596896Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:33:50.344774Z","level":"error","event":"25/09/01 07:33:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:50.495618Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:50.495883Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:52.524041Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:34:23.624421","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:34:24.355451Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:34:25.391180Z","level":"error","event":"25/09/01 07:34:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:34:25.567068Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:34:25.567520Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:34:27.816703Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:34:59.103941","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:34:59.801921Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:35:00.616124Z","level":"error","event":"25/09/01 07:35:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:00.819347Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:00.819651Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:03.278202Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:35:34.109741","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:35:34.858090Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:35:35.757907Z","level":"error","event":"25/09/01 07:35:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:35.954247Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:35.962608Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:38.394617Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:36:09.634882","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:36:10.795056Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:36:12.430198Z","level":"error","event":"25/09/01 07:36:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:12.671703Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:12.672214Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:15.960399Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:36:47.563266","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:36:48.579847Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:36:49.629603Z","level":"error","event":"25/09/01 07:36:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:49.831906Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:49.832077Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:52.424758Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:37:23.397412","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:37:24.228692Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:37:25.209199Z","level":"error","event":"25/09/01 07:37:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:37:25.375401Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:37:25.383110Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:37:28.166640Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:37:59.567625","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:38:00.527460Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:38:01.391467Z","level":"error","event":"25/09/01 07:38:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:01.564504Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:01.564766Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:04.342071Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:38:34.953555","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:38:35.783454Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:38:36.899213Z","level":"error","event":"25/09/01 07:38:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:37.125325Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:37.132190Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:39.883067Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:39:10.611228","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:39:11.499988Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:39:12.703782Z","level":"error","event":"25/09/01 07:39:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:13.050423Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:13.050818Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:15.790824Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:39:46.762668","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:39:47.698636Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:39:48.689481Z","level":"error","event":"25/09/01 07:39:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:48.844364Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:48.844559Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:51.481464Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:40:22.989813","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:40:23.749131Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:40:24.594850Z","level":"error","event":"25/09/01 07:40:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:40:24.725538Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:40:24.726029Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:40:27.004447Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:40:57.821355","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:40:58.500357Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:40:59.246493Z","level":"error","event":"25/09/01 07:40:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:40:59.418361Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:40:59.418839Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:41:01.490253Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:41:32.044773","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:41:32.932479Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:41:33.861587Z","level":"error","event":"25/09/01 07:41:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:41:34.026735Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:41:34.026896Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:41:36.158825Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:42:07.003955","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:42:07.979345Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:42:08.830408Z","level":"error","event":"25/09/01 07:42:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:09.007821Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:09.008136Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:11.591827Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:42:42.975812","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:42:43.691548Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:42:44.506511Z","level":"error","event":"25/09/01 07:42:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:44.662895Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:44.663142Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:47.135181Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:43:18.387507","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:43:19.106165Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:43:19.941079Z","level":"error","event":"25/09/01 07:43:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:43:20.088174Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:43:20.088422Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:43:22.284819Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:43:53.095176","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:43:53.843190Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:43:54.733919Z","level":"error","event":"25/09/01 07:43:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:43:54.921290Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:43:54.921450Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:43:57.393429Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:44:28.757925","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:44:29.626217Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:44:30.598414Z","level":"error","event":"25/09/01 07:44:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:44:30.864733Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:44:30.865248Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:44:33.615614Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:45:04.293950","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:45:05.411207Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:45:06.434156Z","level":"error","event":"25/09/01 07:45:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:06.641646Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:06.649489Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:09.333495Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:45:40.169593","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:45:40.891468Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:45:41.652037Z","level":"error","event":"25/09/01 07:45:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:41.816877Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:41.817144Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:43.912930Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:46:15.193972","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:46:16.198727Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:46:17.365884Z","level":"error","event":"25/09/01 07:46:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:17.597952Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:17.598514Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:20.450057Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:46:51.620128","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:46:52.555939Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:46:53.795707Z","level":"error","event":"25/09/01 07:46:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:54.008789Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:54.009103Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:56.159944Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:47:26.976236","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:47:27.702573Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:47:28.485580Z","level":"error","event":"25/09/01 07:47:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:47:28.643470Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:47:28.643696Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:47:30.859037Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:48:02.163828","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:48:03.101255Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:48:04.063426Z","level":"error","event":"25/09/01 07:48:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:04.261465Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:04.261725Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:06.540042Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:48:37.650985","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:48:38.401472Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:48:39.250646Z","level":"error","event":"25/09/01 07:48:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:39.416283Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:39.416427Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:41.943374Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:49:12.866101","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:49:13.764655Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:49:14.638395Z","level":"error","event":"25/09/01 07:49:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:14.784890Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:14.785138Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:17.106794Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:49:48.493391","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:49:49.635239Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:49:50.774132Z","level":"error","event":"25/09/01 07:49:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:51.010711Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:51.014928Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:53.804945Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:50:24.736590","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:50:25.489697Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:50:26.354978Z","level":"error","event":"25/09/01 07:50:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:50:26.566635Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:50:26.567896Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:50:29.136072Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:51:00.016957","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:51:00.789019Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:51:01.601286Z","level":"error","event":"25/09/01 07:51:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:01.767667Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:01.767940Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:04.250123Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:51:35.100864","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:51:35.985130Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:51:37.052417Z","level":"error","event":"25/09/01 07:51:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:37.213021Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:37.222143Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:39.702467Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:52:10.537513","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:52:11.246144Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:52:12.111207Z","level":"error","event":"25/09/01 07:52:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:12.257726Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:12.257910Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:14.369695Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:52:45.557734","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:52:46.485661Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:52:47.541535Z","level":"error","event":"25/09/01 07:52:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:47.729512Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:47.729812Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:50.038820Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:53:20.682386","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:53:21.603250Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:53:22.800540Z","level":"error","event":"25/09/01 07:53:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:53:23.013963Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:53:23.014156Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:53:25.728711Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:53:56.691984","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:53:57.495997Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:53:58.568471Z","level":"error","event":"25/09/01 07:53:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:53:58.778428Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:53:58.778777Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:54:01.234205Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:54:31.877735","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:54:32.817110Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:54:34.014689Z","level":"error","event":"25/09/01 07:54:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:54:34.327265Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:54:34.327484Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:54:36.544980Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:55:07.774822","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:55:08.561052Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:55:09.475563Z","level":"error","event":"25/09/01 07:55:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:09.643867Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:09.644109Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:11.903410Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:55:42.945000","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:55:43.643019Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:55:44.405966Z","level":"error","event":"25/09/01 07:55:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:44.563737Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:44.563995Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:46.856460Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:56:17.522175","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:56:18.408601Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:56:19.251927Z","level":"error","event":"25/09/01 07:56:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:56:19.404303Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:56:19.404561Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:56:21.695622Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:56:52.511576","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:56:53.619867Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:56:54.462047Z","level":"error","event":"25/09/01 07:56:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:56:54.641300Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:56:54.641469Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:56:56.846976Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:57:27.483444","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:57:28.779448Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:57:29.897262Z","level":"error","event":"25/09/01 07:57:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:57:30.199502Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:57:30.200151Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:57:32.741722Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:58:03.810744","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:58:04.570846Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:58:05.592571Z","level":"error","event":"25/09/01 07:58:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:05.808602Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:05.808939Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:08.595632Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:58:39.282628","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:58:40.268651Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:58:41.487045Z","level":"error","event":"25/09/01 07:58:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:41.743868Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:41.744579Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:44.838238Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:59:16.331779","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:59:17.236644Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:59:18.101512Z","level":"error","event":"25/09/01 07:59:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:59:18.283006Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:59:18.283264Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:59:20.792509Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:59:51.373492","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:59:52.161299Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:59:52.962948Z","level":"error","event":"25/09/01 07:59:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:59:53.150055Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:59:53.150281Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:59:55.742686Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:00:27.164778","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:00:27.916372Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:00:28.722102Z","level":"error","event":"25/09/01 08:00:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:00:28.904864Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:00:28.905104Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:00:31.196329Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:01:02.651004","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:01:03.505535Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:01:04.546005Z","level":"error","event":"25/09/01 08:01:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:04.752873Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:04.753235Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:07.525775Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:01:38.174912","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:01:39.159055Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:01:40.206726Z","level":"error","event":"25/09/01 08:01:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:40.397528Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:40.421416Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:43.595281Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:02:14.620321","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:02:15.402897Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:02:16.358297Z","level":"error","event":"25/09/01 08:02:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:02:16.586665Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:02:16.587270Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:02:19.608580Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:02:50.187219","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:02:51.338639Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:02:52.436736Z","level":"error","event":"25/09/01 08:02:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:02:52.661817Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:02:52.662202Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:02:55.449426Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:03:26.786360","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:03:27.701055Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:03:28.659186Z","level":"error","event":"25/09/01 08:03:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:03:28.877823Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:03:28.878327Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:03:31.503671Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:04:02.689516","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:04:03.786293Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:04:05.100412Z","level":"error","event":"25/09/01 08:04:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:05.334518Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:05.343540Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:08.211540Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:04:39.364333","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:04:40.185591Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:04:41.525240Z","level":"error","event":"25/09/01 08:04:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:41.772275Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:41.772729Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:44.777359Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:05:15.777874","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:05:16.841199Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:05:17.854227Z","level":"error","event":"25/09/01 08:05:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:05:18.111019Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:05:18.111611Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:05:20.887410Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:05:52.265655","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:05:53.082618Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:05:54.130901Z","level":"error","event":"25/09/01 08:05:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:05:54.355768Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:05:54.355945Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:05:56.997009Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:06:27.582231","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:06:28.351843Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:06:29.294259Z","level":"error","event":"25/09/01 08:06:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:06:29.465057Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:06:29.465391Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:06:31.926709Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:07:03.215512","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:07:04.042738Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:07:04.995070Z","level":"error","event":"25/09/01 08:07:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:05.185923Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:05.192902Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:07.594335Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:07:38.178976","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:07:39.031846Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:07:40.377478Z","level":"error","event":"25/09/01 08:07:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:40.556006Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:40.556568Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:42.997225Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:08:13.554688","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:08:14.367237Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:08:15.392969Z","level":"error","event":"25/09/01 08:08:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:08:15.572754Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:08:15.573062Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:08:17.753206Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:08:48.622036","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:08:49.409727Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:08:50.278317Z","level":"error","event":"25/09/01 08:08:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:08:50.456973Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:08:50.457194Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:08:52.608278Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:09:23.804958","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:09:24.510906Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:09:25.418250Z","level":"error","event":"25/09/01 08:09:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:09:25.618315Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:09:25.618640Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:09:27.709121Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:09:59.056146","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:10:00.069874Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:10:01.207400Z","level":"error","event":"25/09/01 08:10:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:01.434969Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:01.435240Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:03.977152Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:10:35.264738","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:10:36.061023Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:10:36.908438Z","level":"error","event":"25/09/01 08:10:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:37.160569Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:37.160866Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:39.696045Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:11:10.717561","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:11:11.637561Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:11:12.738333Z","level":"error","event":"25/09/01 08:11:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:13.033453Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:13.033662Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:15.692354Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:11:46.473187","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:11:47.616065Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:11:48.591631Z","level":"error","event":"25/09/01 08:11:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:48.781227Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:48.790629Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:51.327755Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:12:21.949961","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:12:23.022848Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:12:24.102554Z","level":"error","event":"25/09/01 08:12:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:12:24.278012Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:12:24.278173Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:12:26.559886Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:12:57.149909","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:12:57.875669Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:12:58.662212Z","level":"error","event":"25/09/01 08:12:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:12:58.880020Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:12:58.880149Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:13:00.904997Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:13:31.863015","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:13:32.689319Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:13:33.602981Z","level":"error","event":"25/09/01 08:13:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:13:33.778662Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:13:33.779090Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:13:35.826245Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:14:07.202235","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:14:07.917225Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:14:08.685678Z","level":"error","event":"25/09/01 08:14:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:08.882681Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:08.883155Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:10.965015Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:14:41.791287","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:14:42.646986Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:14:43.625983Z","level":"error","event":"25/09/01 08:14:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:43.827744Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:43.828176Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:46.311314Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:15:17.787323","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:15:18.591732Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:15:19.562220Z","level":"error","event":"25/09/01 08:15:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:15:19.753849Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:15:19.754281Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:15:22.466186Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:15:53.680581","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:15:54.532014Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:15:55.481386Z","level":"error","event":"25/09/01 08:15:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:15:55.694174Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:15:55.701370Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:15:57.996494Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:14:36.982837","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:14:39.932052Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:14:40.717796Z","level":"error","event":"25/09/01 11:14:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:14:41.062560Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:14:41.062828Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:14:44.860989Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:15:15.964781","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:15:16.555453Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:15:17.241185Z","level":"error","event":"25/09/01 11:15:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:17.373209Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:17.373342Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:19.600467Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:15:50.846999","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:15:51.661753Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:15:52.596369Z","level":"error","event":"25/09/01 11:15:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:52.782958Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:52.783214Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:57.407031Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:16:28.517387","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:16:29.182263Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:16:29.919852Z","level":"error","event":"25/09/01 11:16:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:16:30.093741Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:16:30.093960Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:16:32.568505Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:17:03.336624","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:17:04.140182Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:17:05.220992Z","level":"error","event":"25/09/01 11:17:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:05.456925Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:05.466041Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:06.626545Z","level":"error","event":"25/09/01 11:17:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:09.983195Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:17:41.318920","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:17:42.014922Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:17:42.872337Z","level":"error","event":"25/09/01 11:17:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:43.078222Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:43.078450Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:44.283918Z","level":"error","event":"25/09/01 11:17:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:46.306344Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:18:16.944846","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:18:17.918826Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:18:18.594897Z","level":"error","event":"25/09/01 11:18:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:18.773315Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:18.773516Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:20.988088Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:18:51.593074","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:18:52.450610Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:18:53.385086Z","level":"error","event":"25/09/01 11:18:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:53.560085Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:53.560324Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:55.965152Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:19:26.524480","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:19:27.679153Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:19:28.432196Z","level":"error","event":"25/09/01 11:19:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:19:28.627124Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:19:28.628102Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:19:29.613506Z","level":"error","event":"25/09/01 11:19:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:19:31.078788Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:20:02.476393","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:20:03.124248Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:20:03.925194Z","level":"error","event":"25/09/01 11:20:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:04.184495Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:04.184863Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:06.542289Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:20:37.216717","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:20:38.055556Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:20:38.855670Z","level":"error","event":"25/09/01 11:20:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:39.023794Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:39.023973Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:39.803069Z","level":"error","event":"25/09/01 11:20:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:41.327292Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:21:11.989269","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:21:12.584235Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:21:13.284887Z","level":"error","event":"25/09/01 11:21:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:13.460646Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:13.460934Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:15.777469Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:21:46.320199","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:21:46.878332Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:21:47.581044Z","level":"error","event":"25/09/01 11:21:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:47.707753Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:47.707998Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:50.253558Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:22:21.198854","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:22:21.803339Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:22:22.549382Z","level":"error","event":"25/09/01 11:22:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:22.697941Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:22.698176Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:24.743943Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:22:55.958622","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:22:56.610605Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:22:57.309727Z","level":"error","event":"25/09/01 11:22:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:57.502883Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:57.503124Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:59.589858Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:23:30.583813","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:23:31.250985Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:23:31.992343Z","level":"error","event":"25/09/01 11:23:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:23:32.180347Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:23:32.180599Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:23:33.015292Z","level":"error","event":"25/09/01 11:23:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:23:34.488225Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:24:05.330882","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:24:05.941716Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:24:06.793826Z","level":"error","event":"25/09/01 11:24:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:06.963906Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:06.964111Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:07.711923Z","level":"error","event":"25/09/01 11:24:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:09.669082Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:24:40.306061","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:24:40.954291Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:24:41.862329Z","level":"error","event":"25/09/01 11:24:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:41.962999Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:41.968870Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:42.893204Z","level":"error","event":"25/09/01 11:24:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:44.405501Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:25:14.928325","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:25:15.579384Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:25:16.392805Z","level":"error","event":"25/09/01 11:25:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:16.594893Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:16.595067Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:17.773210Z","level":"error","event":"25/09/01 11:25:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:19.457770Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:25:50.379136","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:25:51.040989Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:25:51.840958Z","level":"error","event":"25/09/01 11:25:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:52.058800Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:52.059037Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:54.888433Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:26:25.662872","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:26:26.402851Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:26:27.335797Z","level":"error","event":"25/09/01 11:26:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:26:27.610597Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:26:27.610848Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:26:28.540998Z","level":"error","event":"25/09/01 11:26:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:26:30.370129Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:27:01.186922","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:27:01.778171Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:27:02.513271Z","level":"error","event":"25/09/01 11:27:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:02.696506Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:02.704322Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:03.435992Z","level":"error","event":"25/09/01 11:27:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:04.825229Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:27:35.984734","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:27:36.664558Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:27:37.443451Z","level":"error","event":"25/09/01 11:27:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:37.612136Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:37.617060Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:38.503585Z","level":"error","event":"25/09/01 11:27:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:39.903215Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:28:11.123539","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:28:11.803580Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:28:12.414637Z","level":"error","event":"25/09/01 11:28:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:12.566200Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:12.566499Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:14.578985Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:28:45.608826","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:28:46.340013Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:28:47.134856Z","level":"error","event":"25/09/01 11:28:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:47.310906Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:47.311098Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:48.097785Z","level":"error","event":"25/09/01 11:28:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:49.639406Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:29:20.519202","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:29:21.217811Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:29:21.980470Z","level":"error","event":"25/09/01 11:29:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:22.194651Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:22.194950Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:22.939048Z","level":"error","event":"25/09/01 11:29:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:24.390939Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:29:55.144753","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:29:55.702857Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:29:56.435348Z","level":"error","event":"25/09/01 11:29:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:56.625296Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:56.625483Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:57.456366Z","level":"error","event":"25/09/01 11:29:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:58.699700Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:30:29.243039","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:30:29.979024Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:30:30.677170Z","level":"error","event":"25/09/01 11:30:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:30:30.819918Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:30:30.820097Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:30:31.510447Z","level":"error","event":"25/09/01 11:30:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:30:33.335193Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:31:04.362153","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:31:04.943396Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:31:05.572431Z","level":"error","event":"25/09/01 11:31:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:05.710647Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:05.710808Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:07.630651Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:31:38.787093","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:31:39.500760Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:31:40.272380Z","level":"error","event":"25/09/01 11:31:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:40.425804Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:40.425843Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:41.133569Z","level":"error","event":"25/09/01 11:31:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:42.953927Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:32:13.558218","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:32:14.118435Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:32:14.794997Z","level":"error","event":"25/09/01 11:32:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:14.916616Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:14.916855Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:15.542237Z","level":"error","event":"25/09/01 11:32:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:17.175294Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:32:48.072389","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:32:48.681158Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:32:49.375525Z","level":"error","event":"25/09/01 11:32:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:49.518289Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:49.522437Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:51.418869Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:33:22.577872","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:33:23.157675Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:33:23.779849Z","level":"error","event":"25/09/01 11:33:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:23.967002Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:23.967277Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:25.938094Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:33:57.052636","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:33:57.874706Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:33:58.508263Z","level":"error","event":"25/09/01 11:33:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:58.662930Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:58.666809Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:34:00.597519Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:34:31.761278","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:34:32.551424Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:34:33.200921Z","level":"error","event":"25/09/01 11:34:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:34:33.312076Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:34:33.312357Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:34:35.204844Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:35:05.699832","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:35:06.392384Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:35:06.967640Z","level":"error","event":"25/09/01 11:35:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:07.111073Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:07.111291Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:08.770260Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:35:39.585734","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:35:40.114605Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:35:40.616440Z","level":"error","event":"25/09/01 11:35:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:40.724102Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:40.724322Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:42.550109Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:36:13.454738","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:36:13.991352Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:36:14.634060Z","level":"error","event":"25/09/01 11:36:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:14.780496Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:14.783953Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:16.540789Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:36:47.467590","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:36:48.076386Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:36:48.727108Z","level":"error","event":"25/09/01 11:36:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:48.837639Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:48.837798Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:50.685814Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:37:21.794316","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:37:22.469404Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:37:23.033509Z","level":"error","event":"25/09/01 11:37:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:23.137696Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:23.137891Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:25.010699Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:37:56.012746","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:37:56.537775Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:37:57.147855Z","level":"error","event":"25/09/01 11:37:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:57.268031Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:57.268261Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:59.224974Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:38:29.858441","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:38:30.427038Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:38:31.062162Z","level":"error","event":"25/09/01 11:38:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:38:31.201481Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:38:31.201708Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:38:33.045882Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:39:04.255876","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:39:05.070444Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:39:05.886610Z","level":"error","event":"25/09/01 11:39:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:06.052536Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:06.052665Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:08.510930Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:39:39.856721","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:39:40.461698Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:39:41.164595Z","level":"error","event":"25/09/01 11:39:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:41.347001Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:41.347191Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:43.571464Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:40:14.174265","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:40:14.808503Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:40:15.501084Z","level":"error","event":"25/09/01 11:40:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:15.657675Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:15.657865Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:16.393219Z","level":"error","event":"25/09/01 11:40:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:17.692213Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:40:48.852870","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:40:49.481097Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:40:50.131211Z","level":"error","event":"25/09/01 11:40:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:50.275916Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:50.276132Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:52.130296Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:41:23.374408","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:41:23.945699Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:41:24.579436Z","level":"error","event":"25/09/01 11:41:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:41:24.734060Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:41:24.734286Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:41:26.862575Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:41:58.127855","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:41:58.741388Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:41:59.367330Z","level":"error","event":"25/09/01 11:41:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:41:59.557788Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:41:59.561754Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:42:01.524865Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:42:32.766598","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:42:33.385738Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:42:34.012317Z","level":"error","event":"25/09/01 11:42:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:42:34.134203Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:42:34.134406Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:42:34.783334Z","level":"error","event":"25/09/01 11:42:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:42:36.046818Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:43:07.258085","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:43:07.856697Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:43:08.607866Z","level":"error","event":"25/09/01 11:43:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:08.760410Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:08.760705Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:09.546430Z","level":"error","event":"25/09/01 11:43:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:10.972137Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:43:42.215255","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:43:42.740705Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:43:43.340099Z","level":"error","event":"25/09/01 11:43:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:43.463666Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:43.463851Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:45.307671Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:44:16.495893","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:44:17.030514Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:44:17.690653Z","level":"error","event":"25/09/01 11:44:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:17.865676Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:17.870341Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:18.672935Z","level":"error","event":"25/09/01 11:44:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:20.230523Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:44:50.904662","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:44:51.544133Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:44:52.362434Z","level":"error","event":"25/09/01 11:44:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:52.492916Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:52.493151Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:53.177703Z","level":"error","event":"25/09/01 11:44:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:54.522738Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:45:25.733702","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:45:26.278018Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:45:26.913538Z","level":"error","event":"25/09/01 11:45:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:45:27.048244Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:45:27.048452Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:45:27.684952Z","level":"error","event":"25/09/01 11:45:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:45:28.941542Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:46:00.034342","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:46:00.621912Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:46:01.255638Z","level":"error","event":"25/09/01 11:46:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:01.411843Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:01.412125Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:02.123577Z","level":"error","event":"25/09/01 11:46:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:03.308769Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:46:34.450239","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:46:35.142148Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:46:35.875051Z","level":"error","event":"25/09/01 11:46:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:36.049696Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:36.049904Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:36.888366Z","level":"error","event":"25/09/01 11:46:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:38.397564Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:47:09.685712","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:47:10.283189Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:47:10.997897Z","level":"error","event":"25/09/01 11:47:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:11.171883Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:11.172112Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:11.948901Z","level":"error","event":"25/09/01 11:47:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:13.203558Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:47:44.282725","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:47:44.906206Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:47:45.644835Z","level":"error","event":"25/09/01 11:47:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:45.833436Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:45.833861Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:48.019065Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:48:19.196880","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:48:19.770267Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:48:20.427508Z","level":"error","event":"25/09/01 11:48:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:20.585862Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:20.586029Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:22.500006Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:48:53.867446","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:48:54.613584Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:48:55.215518Z","level":"error","event":"25/09/01 11:48:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:55.346259Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:55.346401Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:57.690063Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:49:28.465640","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:49:29.311774Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:49:29.989657Z","level":"error","event":"25/09/01 11:49:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:49:30.201255Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:49:30.205310Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:49:30.937724Z","level":"error","event":"25/09/01 11:49:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:49:32.308788Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:50:02.854772","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:50:03.691368Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:50:04.326814Z","level":"error","event":"25/09/01 11:50:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:04.492117Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:04.498003Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:07.058470Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:50:38.173132","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:50:38.741476Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:50:39.455169Z","level":"error","event":"25/09/01 11:50:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:39.618092Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:39.618248Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:41.635463Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:51:12.896382","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:51:13.515769Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:51:14.315598Z","level":"error","event":"25/09/01 11:51:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:14.491105Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:14.491323Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:16.930168Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:51:48.213412","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:51:48.892772Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:51:49.679152Z","level":"error","event":"25/09/01 11:51:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:49.870938Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:49.871108Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:50.588604Z","level":"error","event":"25/09/01 11:51:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:52.420313Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:52:23.006749","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:52:23.676105Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:52:24.460579Z","level":"error","event":"25/09/01 11:52:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:52:24.656987Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:52:24.657234Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:52:25.392490Z","level":"error","event":"25/09/01 11:52:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:52:26.906170Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:52:57.855628","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:52:58.515026Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:52:59.281295Z","level":"error","event":"25/09/01 11:52:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:52:59.425770Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:52:59.426037Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:53:00.156600Z","level":"error","event":"25/09/01 11:53:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:53:01.268059Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:53:31.881978","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:53:32.442470Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:53:33.082444Z","level":"error","event":"25/09/01 11:53:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:53:33.191192Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:53:33.191348Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:53:33.855491Z","level":"error","event":"25/09/01 11:53:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:53:34.930107Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:54:05.777408","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:54:06.497308Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:54:07.412215Z","level":"error","event":"25/09/01 11:54:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:07.627179Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:07.627671Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:09.426924Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:54:39.966855","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:54:40.550127Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:54:41.192522Z","level":"error","event":"25/09/01 11:54:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:41.342367Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:41.342578Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:42.130936Z","level":"error","event":"25/09/01 11:54:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:43.272796Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:55:13.857544","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:55:14.474993Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:55:15.269415Z","level":"error","event":"25/09/01 11:55:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:15.509861Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:15.510265Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:16.290349Z","level":"error","event":"25/09/01 11:55:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:17.399272Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:55:47.968340","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:55:48.527916Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:55:49.167768Z","level":"error","event":"25/09/01 11:55:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:49.294518Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:49.294735Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:49.998829Z","level":"error","event":"25/09/01 11:55:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:50.990052Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:56:21.581108","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:56:22.167906Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:56:22.857202Z","level":"error","event":"25/09/01 11:56:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:22.997224Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:22.997394Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:23.767809Z","level":"error","event":"25/09/01 11:56:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:24.771344Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:56:55.314063","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:56:55.867101Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:56:56.512005Z","level":"error","event":"25/09/01 11:56:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:56.705105Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:56.705399Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:57.421203Z","level":"error","event":"25/09/01 11:56:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:58.543270Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:57:29.158350","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:57:29.787918Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:57:30.497539Z","level":"error","event":"25/09/01 11:57:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:57:30.625650Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:57:30.625893Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:57:31.327262Z","level":"error","event":"25/09/01 11:57:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:57:32.326831Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:58:02.847933","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:58:03.443139Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:58:04.128137Z","level":"error","event":"25/09/01 11:58:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:04.283533Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:04.283783Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:04.997483Z","level":"error","event":"25/09/01 11:58:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:06.144009Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:58:36.656775","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:58:37.242429Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:58:37.952369Z","level":"error","event":"25/09/01 11:58:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:38.082383Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:38.082635Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:38.861235Z","level":"error","event":"25/09/01 11:58:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:40.050234Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:59:10.757939","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:59:11.295219Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:59:11.917589Z","level":"error","event":"25/09/01 11:59:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:12.038725Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:12.038891Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:12.722832Z","level":"error","event":"25/09/01 11:59:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:13.830791Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:59:44.379448","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:59:44.939656Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:59:45.599393Z","level":"error","event":"25/09/01 11:59:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:45.736347Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:45.739915Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:46.373695Z","level":"error","event":"25/09/01 11:59:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:47.390290Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:00:18.597721","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:00:19.324352Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:00:20.336509Z","level":"error","event":"25/09/01 12:00:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:20.554325Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:20.559502Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:21.998890Z","level":"error","event":"25/09/01 12:00:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:23.866835Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:00:54.459825","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:00:55.150590Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:00:55.900370Z","level":"error","event":"25/09/01 12:00:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:56.064828Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:56.065030Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:56.862586Z","level":"error","event":"25/09/01 12:00:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:58.231122Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:01:28.840397","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:01:29.469493Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:01:30.153322Z","level":"error","event":"25/09/01 12:01:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:01:30.319720Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:01:30.333443Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:01:31.048399Z","level":"error","event":"25/09/01 12:01:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:01:32.255381Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:02:02.922262","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:02:03.474928Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:02:04.154112Z","level":"error","event":"25/09/01 12:02:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:04.277204Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:04.277443Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:04.926930Z","level":"error","event":"25/09/01 12:02:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:05.956530Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:02:36.715004","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:02:37.277704Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:02:37.953908Z","level":"error","event":"25/09/01 12:02:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:38.115187Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:38.115368Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:38.777178Z","level":"error","event":"25/09/01 12:02:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:39.797700Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:03:10.371879","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:03:10.930414Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:03:11.606893Z","level":"error","event":"25/09/01 12:03:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:11.713470Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:11.713630Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:12.636077Z","level":"error","event":"25/09/01 12:03:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:14.041667Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:03:44.750604","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:03:45.412027Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:03:46.236081Z","level":"error","event":"25/09/01 12:03:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:46.382238Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:46.382495Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:47.156121Z","level":"error","event":"25/09/01 12:03:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:48.199714Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:04:18.861140","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:04:19.423390Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:04:20.189243Z","level":"error","event":"25/09/01 12:04:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:20.369102Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:20.372668Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:21.302697Z","level":"error","event":"25/09/01 12:04:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:22.626843Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:04:53.248312","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:04:54.004303Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:04:54.707354Z","level":"error","event":"25/09/01 12:04:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:54.854333Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:54.854537Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:55.892504Z","level":"error","event":"25/09/01 12:04:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:57.407894Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:05:28.134320","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:05:28.703730Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:05:29.416469Z","level":"error","event":"25/09/01 12:05:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:05:29.614982Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:05:29.615200Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:05:30.344373Z","level":"error","event":"25/09/01 12:05:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:05:31.650100Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:06:02.422957","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:06:03.046790Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:06:03.739354Z","level":"error","event":"25/09/01 12:06:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:03.927411Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:03.927663Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:04.608785Z","level":"error","event":"25/09/01 12:06:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:05.892823Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:06:37.319833","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:06:37.946862Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:06:38.596406Z","level":"error","event":"25/09/01 12:06:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:38.740530Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:38.740829Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:39.457312Z","level":"error","event":"25/09/01 12:06:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:40.637156Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:07:11.165112","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:07:11.769804Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:07:12.688258Z","level":"error","event":"25/09/01 12:07:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:12.901017Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:12.901253Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:13.764062Z","level":"error","event":"25/09/01 12:07:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:15.230211Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:07:45.892588","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:07:46.427306Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:07:47.152291Z","level":"error","event":"25/09/01 12:07:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:47.365929Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:47.373268Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:49.392400Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:08:20.075874","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:08:20.654714Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:08:21.436974Z","level":"error","event":"25/09/01 12:08:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:21.606060Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:21.611851Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:22.365593Z","level":"error","event":"25/09/01 12:08:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:23.743856Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:08:54.868383","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:08:55.467104Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:08:56.044324Z","level":"error","event":"25/09/01 12:08:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:56.176713Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:56.176954Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:56.945494Z","level":"error","event":"25/09/01 12:08:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:58.560930Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:09:29.935420","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:09:30.446930Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:09:31.106806Z","level":"error","event":"25/09/01 12:09:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:09:31.219005Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:09:31.219160Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:09:31.938212Z","level":"error","event":"25/09/01 12:09:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:09:33.149137Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:10:04.331182","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:10:04.871116Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:10:05.498301Z","level":"error","event":"25/09/01 12:10:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:05.640773Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:05.641014Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:06.346692Z","level":"error","event":"25/09/01 12:10:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:07.525692Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:10:38.809382","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:10:39.321910Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:10:39.931806Z","level":"error","event":"25/09/01 12:10:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:40.063249Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:40.063406Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:42.011695Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:11:13.203074","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:11:13.862644Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:11:14.616934Z","level":"error","event":"25/09/01 12:11:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:14.793097Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:14.793419Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:15.664825Z","level":"error","event":"25/09/01 12:11:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:17.136570Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:11:47.855339","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:11:48.488101Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:11:49.304571Z","level":"error","event":"25/09/01 12:11:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:49.574305Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:49.574616Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:51.755587Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:12:22.448893","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:12:23.058833Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:12:23.798351Z","level":"error","event":"25/09/01 12:12:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:23.952064Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:23.952415Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:26.213169Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:12:57.497428","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:12:58.033727Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:12:58.640760Z","level":"error","event":"25/09/01 12:12:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:58.768035Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:58.768225Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:59.448200Z","level":"error","event":"25/09/01 12:12:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:13:00.650572Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:13:31.803187","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:13:32.365861Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:13:32.987274Z","level":"error","event":"25/09/01 12:13:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:13:33.107238Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:13:33.107380Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:13:33.784027Z","level":"error","event":"25/09/01 12:13:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:13:35.201585Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:14:06.409097","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:14:06.946633Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:14:07.589852Z","level":"error","event":"25/09/01 12:14:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:07.706286Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:07.706440Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:08.371357Z","level":"error","event":"25/09/01 12:14:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:09.573984Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:14:40.786856","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:14:41.319096Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:14:41.951206Z","level":"error","event":"25/09/01 12:14:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:42.102860Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:42.103036Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:42.777091Z","level":"error","event":"25/09/01 12:14:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:43.997840Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:15:15.235088","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:15:15.762655Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:15:16.368316Z","level":"error","event":"25/09/01 12:15:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:16.503278Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:16.503438Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:17.108016Z","level":"error","event":"25/09/01 12:15:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:18.303275Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:15:49.659082","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:15:50.535488Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:15:51.745123Z","level":"error","event":"25/09/01 12:15:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:52.025815Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:52.031224Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:55.078227Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:16:26.510032","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:16:27.499266Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:16:28.522972Z","level":"error","event":"25/09/01 12:16:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:16:28.760821Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:16:28.761096Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:16:29.667902Z","level":"error","event":"25/09/01 12:16:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:16:31.508512Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:17:02.361049","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:17:03.275889Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:17:04.338258Z","level":"error","event":"25/09/01 12:17:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:04.596334Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:04.596587Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:08.008640Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:17:39.204329","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:17:40.228299Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:17:41.286226Z","level":"error","event":"25/09/01 12:17:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:41.526623Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:41.532954Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:42.627169Z","level":"error","event":"25/09/01 12:17:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:44.661457Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:18:15.637285","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:18:16.529209Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:18:17.642507Z","level":"error","event":"25/09/01 12:18:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:17.940113Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:17.940376Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:21.600063Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:18:52.457590","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:18:53.330808Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:18:54.585596Z","level":"error","event":"25/09/01 12:18:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:54.803988Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:54.809048Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:58.279569Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:19:29.099537","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:19:30.397603Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:19:31.669008Z","level":"error","event":"25/09/01 12:19:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:19:31.965353Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:19:31.973676Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:19:33.130701Z","level":"error","event":"25/09/01 12:19:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:19:35.688066Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:20:06.662417","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:20:08.026883Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:20:09.527947Z","level":"error","event":"25/09/01 12:20:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:20:09.921286Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:20:09.921755Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:20:11.182697Z","level":"error","event":"25/09/01 12:20:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:20:13.392580Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
