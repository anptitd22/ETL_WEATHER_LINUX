{"timestamp":"2025-09-01T04:18:25.805312","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:18:29.320339Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:29.797828Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:31.843869Z","level":"error","event":"25/09/01 04:18:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:32.257892Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:32.258254Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:32.258341Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:33.962794Z","level":"error","event":"25/09/01 04:18:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.437021Z","level":"error","event":"25/09/01 04:18:36 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.437345Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.437463Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.437538Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.437613Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.437683Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.437753Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.437822Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.437914Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.437991Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.438067Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.438139Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.438216Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.438462Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.438668Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.438796Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.438894Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.438970Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439042Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439113Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439178Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439241Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439306Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439368Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439429Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439488Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439554Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439616Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439691Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439772Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:36.439838Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504130Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504329Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504379Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504418Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504454Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504502Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504537Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504581Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504635Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504673Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504709Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504744Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504780Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504815Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504850Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504898Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.504943Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.505103Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.505149Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.505216Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:18:39.505719","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T04:19:10.349324","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:19:10.715245Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:11.374412Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:12.125789Z","level":"error","event":"25/09/01 04:19:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:12.269414Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:12.269465Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:12.269503Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:13.078639Z","level":"error","event":"25/09/01 04:19:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.796324Z","level":"error","event":"25/09/01 04:19:14 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.796728Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.796852Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.796937Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797001Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797060Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797118Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797178Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797252Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797318Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797381Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797457Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797524Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797590Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797654Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797716Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797777Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797836Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797907Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.797966Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.798027Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.798087Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.798146Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.798208Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.798265Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.798330Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.798401Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.798472Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.798541Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.798617Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:14.798682Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299435Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299503Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299547Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299586Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299622Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299658Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299695Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299730Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299766Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299800Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299834Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299878Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299915Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299952Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.299988Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.300024Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.300059Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.300092Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.300125Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.300159Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:19:16.296660","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T04:25:01.350609","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:25:04.744778Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:04.745142Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:25:04.837003Z","level":"error","event":"25/09/01 04:25:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:05.054648Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:05.060952Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:05.061134Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:06.602251Z","level":"error","event":"25/09/01 04:25:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:10.929404Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:25:41.855141","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:25:42.319757Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:42.808240Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:25:43.420291Z","level":"error","event":"25/09/01 04:25:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:43.539838Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:43.544891Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:43.545017Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:44.276498Z","level":"error","event":"25/09/01 04:25:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:25:47.196376Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:26:18.467163","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:26:18.816940Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:19.545529Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:26:20.305133Z","level":"error","event":"25/09/01 04:26:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:20.482363Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:20.482408Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:20.482447Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:21.283950Z","level":"error","event":"25/09/01 04:26:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:24.705571Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:26:55.966588","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:26:56.272092Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:56.879179Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:26:57.528940Z","level":"error","event":"25/09/01 04:26:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:57.662728Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:57.666327Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:26:57.666457Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:01.441047Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:27:32.298612","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:27:32.628119Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:33.361411Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:27:34.024976Z","level":"error","event":"25/09/01 04:27:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:34.177533Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:34.183740Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:34.183960Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:35.227846Z","level":"error","event":"25/09/01 04:27:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:27:38.478493Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:28:09.689711","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:28:10.216179Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:10.805901Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:28:11.456804Z","level":"error","event":"25/09/01 04:28:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:11.575807Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:11.581442Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:11.581618Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:15.435427Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:28:45.969523","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:28:46.470073Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:47.088261Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:28:47.678437Z","level":"error","event":"25/09/01 04:28:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:47.804496Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:47.810196Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:47.810363Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:28:51.535018Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:29:22.811032","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:29:23.286431Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:29:23.853283Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:29:24.464162Z","level":"error","event":"25/09/01 04:29:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:29:24.631335Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:29:24.636613Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:29:24.636898Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:29:25.359655Z","level":"error","event":"25/09/01 04:29:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:29:28.208555Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:29:59.511408","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:30:00.012667Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:00.697276Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:30:01.495025Z","level":"error","event":"25/09/01 04:30:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:01.686653Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:01.686898Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:01.686982Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:02.992036Z","level":"error","event":"25/09/01 04:30:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:09.461592Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:30:40.981861","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:30:41.315215Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:42.016062Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:30:42.718957Z","level":"error","event":"25/09/01 04:30:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:42.874479Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:42.879170Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:42.879322Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:30:46.771693Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:31:17.940573","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:31:18.279401Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:18.915357Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:31:19.457358Z","level":"error","event":"25/09/01 04:31:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:19.595905Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:19.596015Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:19.596052Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:20.262960Z","level":"error","event":"25/09/01 04:31:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:23.439081Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:31:54.700737","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:31:54.994176Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:55.493467Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:31:56.118669Z","level":"error","event":"25/09/01 04:31:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:56.265104Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:56.268996Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:31:56.269133Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:01.765572Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:32:33.078046","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:32:33.379238Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:33.893957Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:32:34.575851Z","level":"error","event":"25/09/01 04:32:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:34.727633Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:34.733373Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:34.733516Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:32:38.133814Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:33:09.287232","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:33:09.628851Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:10.176577Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:33:10.828631Z","level":"error","event":"25/09/01 04:33:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:10.961091Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:10.966939Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:10.967118Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:11.795478Z","level":"error","event":"25/09/01 04:33:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:14.728470Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:33:45.745151","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T04:33:46.089430Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:46.713665Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T04:33:47.445178Z","level":"error","event":"25/09/01 04:33:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:47.622011Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:47.629662Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:47.629915Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T04:33:48.414060Z","level":"error","event":"25/09/01 04:33:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:02:53.046893","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:02:55.269887Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:02:55.617558Z","level":"error","event":"25/09/01 05:02:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:02:55.863363Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:02:55.863792Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:02:59.582025Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:03:31.043134","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:03:31.651398Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:03:32.325584Z","level":"error","event":"25/09/01 05:03:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:03:32.442870Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:03:32.443087Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:03:34.365200Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:04:05.566313","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:04:06.134779Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:04:06.763790Z","level":"error","event":"25/09/01 05:04:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:06.889681Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:06.889838Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:08.820454Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:04:39.867202","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:04:40.420750Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:04:41.019587Z","level":"error","event":"25/09/01 05:04:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:41.159600Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:41.159753Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:41.858449Z","level":"error","event":"25/09/01 05:04:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:04:43.043355Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:05:14.028457","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:05:14.815791Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:05:15.855329Z","level":"error","event":"25/09/01 05:05:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:16.107648Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:16.107915Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:17.315563Z","level":"error","event":"25/09/01 05:05:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:19.822388Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:05:50.660481","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:05:51.250202Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:05:51.980069Z","level":"error","event":"25/09/01 05:05:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:52.139505Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:52.139738Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:05:54.307755Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:06:25.764471","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:06:26.423493Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:06:27.118640Z","level":"error","event":"25/09/01 05:06:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:06:27.289444Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:06:27.289676Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:06:29.309208Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:07:00.709433","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:07:01.493373Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:07:02.133847Z","level":"error","event":"25/09/01 05:07:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:02.264798Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:02.267691Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:02.922434Z","level":"error","event":"25/09/01 05:07:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:04.149232Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:07:35.248957","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:07:36.023759Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:07:36.741871Z","level":"error","event":"25/09/01 05:07:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:36.868045Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:36.868194Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:07:38.694632Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:08:09.697742","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:08:10.305795Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:08:11.032502Z","level":"error","event":"25/09/01 05:08:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:08:11.167156Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:08:11.167497Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:08:12.005365Z","level":"error","event":"25/09/01 05:08:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:08:13.461966Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:11:48.648315","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:11:50.953880Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:11:51.030230Z","level":"error","event":"25/09/01 05:11:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:11:51.404999Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:11:51.411502Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:11:52.811406Z","level":"error","event":"25/09/01 05:11:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:11:55.156628Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:12:26.247539","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:12:26.841203Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:12:27.569773Z","level":"error","event":"25/09/01 05:12:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:12:27.698013Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:12:27.698198Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:12:28.480178Z","level":"error","event":"25/09/01 05:12:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:12:29.790095Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:13:00.611645","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:13:01.193754Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:13:01.879590Z","level":"error","event":"25/09/01 05:13:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:02.029710Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:02.029887Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:02.811904Z","level":"error","event":"25/09/01 05:13:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:04.156333Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:13:35.292924","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:13:35.905837Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:13:36.511259Z","level":"error","event":"25/09/01 05:13:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:36.656551Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:36.656783Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:37.321701Z","level":"error","event":"25/09/01 05:13:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:13:38.590309Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:14:09.738387","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:14:10.332600Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:14:10.974714Z","level":"error","event":"25/09/01 05:14:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:11.105163Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:11.108812Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:11.748732Z","level":"error","event":"25/09/01 05:14:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:13.006405Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:14:44.016002","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:14:44.529337Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:14:45.115735Z","level":"error","event":"25/09/01 05:14:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:45.268556Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:45.268776Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:14:47.207903Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:15:18.321922","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:15:18.849269Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:15:19.487471Z","level":"error","event":"25/09/01 05:15:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:19.633580Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:19.637246Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:20.290452Z","level":"error","event":"25/09/01 05:15:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:21.625782Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:15:52.700829","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:15:53.470027Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:15:54.052970Z","level":"error","event":"25/09/01 05:15:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:54.171425Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:54.171616Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:15:55.979941Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:16:26.508371","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:16:27.631098Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:16:28.890906Z","level":"error","event":"25/09/01 05:16:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:16:29.130021Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:16:29.130279Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:16:33.407220Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:17:04.055396","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:17:04.637539Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:17:05.417107Z","level":"error","event":"25/09/01 05:17:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:05.598455Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:05.598761Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:07.760764Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:17:39.040115","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:17:39.633549Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:17:40.321415Z","level":"error","event":"25/09/01 05:17:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:40.436698Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:40.436921Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:17:42.362300Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:18:13.027288","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:18:13.535788Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:18:14.132458Z","level":"error","event":"25/09/01 05:18:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:14.237722Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:14.237883Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:15.943868Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:18:47.424852","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:18:48.004824Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:18:48.613476Z","level":"error","event":"25/09/01 05:18:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:48.768348Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:48.768479Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:18:50.695187Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:19:21.982006","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:19:22.518841Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:19:23.174352Z","level":"error","event":"25/09/01 05:19:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:23.310229Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:23.310380Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:23.922063Z","level":"error","event":"25/09/01 05:19:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:25.263150Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:19:55.814490","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:19:56.388179Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.037950Z","level":"error","event":"25/09/01 05:19:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.179282Z","level":"error","event":"25/09/01 05:19:57 WARN DependencyUtils: Local jar /opt/spark/jars/hadoop-aws-3.3.4.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.340337Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Running Spark version 3.5.6","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.344816Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.344986Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.365935Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.369441Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.369554Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.369595Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.380982Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.389945Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.390013Z","level":"error","event":"25/09/01 05:19:57 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.424885Z","level":"error","event":"25/09/01 05:19:57 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.429544Z","level":"error","event":"25/09/01 05:19:57 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.429719Z","level":"error","event":"25/09/01 05:19:57 INFO SecurityManager: Changing view acls groups to:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.429784Z","level":"error","event":"25/09/01 05:19:57 INFO SecurityManager: Changing modify acls groups to:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.429840Z","level":"error","event":"25/09/01 05:19:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.563225Z","level":"error","event":"25/09/01 05:19:57 INFO Utils: Successfully started service 'sparkDriver' on port 38641.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.582704Z","level":"error","event":"25/09/01 05:19:57 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.614640Z","level":"error","event":"25/09/01 05:19:57 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.632024Z","level":"error","event":"25/09/01 05:19:57 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.638050Z","level":"error","event":"25/09/01 05:19:57 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.638258Z","level":"error","event":"25/09/01 05:19:57 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.652990Z","level":"error","event":"25/09/01 05:19:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0b7d61f0-699d-42d1-9c9c-563fa878d6ad","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.666235Z","level":"error","event":"25/09/01 05:19:57 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.680187Z","level":"error","event":"25/09/01 05:19:57 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.773652Z","level":"error","event":"25/09/01 05:19:57 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.825210Z","level":"error","event":"25/09/01 05:19:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.833341Z","level":"error","event":"25/09/01 05:19:57 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871131Z","level":"error","event":"25/09/01 05:19:57 ERROR SparkContext: Failed to add /opt/spark/jars/hadoop-aws-3.3.4.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871335Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/hadoop-aws-3.3.4.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871381Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871418Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871451Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871481Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871533Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871565Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871594Z","level":"error","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871623Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871652Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871681Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871709Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871739Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871768Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871797Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871825Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871862Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871896Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871926Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871955Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.871984Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.872012Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.872041Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.876578Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://16de1778b869:38641/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756703997334","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.876705Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://16de1778b869:38641/jars/ojdbc11.jar with timestamp 1756703997334","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.876745Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Added JAR /opt/spark/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar at spark://16de1778b869:38641/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar with timestamp 1756703997334","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.876789Z","level":"error","event":"25/09/01 05:19:57 INFO SparkContext: Added JAR /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar at spark://16de1778b869:38641/jars/iceberg-aws-bundle-1.9.2.jar with timestamp 1756703997334","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.942245Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: Starting executor ID driver on host 16de1778b869","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.947265Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.947425Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.952635Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/*,file:/opt/airflow/*'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.958476Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@254f6df8 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:57.966912Z","level":"error","event":"25/09/01 05:19:57 INFO Executor: Fetching spark://16de1778b869:38641/jars/ojdbc11.jar with timestamp 1756703997334","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.012769Z","level":"error","event":"25/09/01 05:19:58 INFO TransportClientFactory: Successfully created connection to 16de1778b869/172.18.0.7:38641 after 17 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.012842Z","level":"error","event":"25/09/01 05:19:58 INFO Utils: Fetching spark://16de1778b869:38641/jars/ojdbc11.jar to /tmp/spark-b6b903fd-d357-4d26-ac7e-eecc04e48089/userFiles-ef9bbcdd-b1fc-47d5-b69f-1634cb31e36e/fetchFileTemp14478066759906610063.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.049192Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Adding file:/tmp/spark-b6b903fd-d357-4d26-ac7e-eecc04e48089/userFiles-ef9bbcdd-b1fc-47d5-b69f-1634cb31e36e/ojdbc11.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.055763Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Fetching spark://16de1778b869:38641/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar with timestamp 1756703997334","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.056010Z","level":"error","event":"25/09/01 05:19:58 INFO Utils: Fetching spark://16de1778b869:38641/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar to /tmp/spark-b6b903fd-d357-4d26-ac7e-eecc04e48089/userFiles-ef9bbcdd-b1fc-47d5-b69f-1634cb31e36e/fetchFileTemp18254867277748865578.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.167694Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Adding file:/tmp/spark-b6b903fd-d357-4d26-ac7e-eecc04e48089/userFiles-ef9bbcdd-b1fc-47d5-b69f-1634cb31e36e/iceberg-spark-runtime-3.5_2.13-1.9.2.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.176933Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Fetching spark://16de1778b869:38641/jars/iceberg-aws-bundle-1.9.2.jar with timestamp 1756703997334","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.177201Z","level":"error","event":"25/09/01 05:19:58 INFO Utils: Fetching spark://16de1778b869:38641/jars/iceberg-aws-bundle-1.9.2.jar to /tmp/spark-b6b903fd-d357-4d26-ac7e-eecc04e48089/userFiles-ef9bbcdd-b1fc-47d5-b69f-1634cb31e36e/fetchFileTemp12252861438430243803.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.293162Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Adding file:/tmp/spark-b6b903fd-d357-4d26-ac7e-eecc04e48089/userFiles-ef9bbcdd-b1fc-47d5-b69f-1634cb31e36e/iceberg-aws-bundle-1.9.2.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.302004Z","level":"error","event":"25/09/01 05:19:58 INFO Executor: Fetching spark://16de1778b869:38641/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756703997334","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:58.302282Z","level":"error","event":"25/09/01 05:19:58 INFO Utils: Fetching spark://16de1778b869:38641/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-b6b903fd-d357-4d26-ac7e-eecc04e48089/userFiles-ef9bbcdd-b1fc-47d5-b69f-1634cb31e36e/fetchFileTemp3946769145648713390.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.085662Z","level":"error","event":"25/09/01 05:19:59 INFO Executor: Adding file:/tmp/spark-b6b903fd-d357-4d26-ac7e-eecc04e48089/userFiles-ef9bbcdd-b1fc-47d5-b69f-1634cb31e36e/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.095916Z","level":"error","event":"25/09/01 05:19:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36373.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.101387Z","level":"error","event":"25/09/01 05:19:59 INFO NettyBlockTransferService: Server created on 16de1778b869:36373","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.101520Z","level":"error","event":"25/09/01 05:19:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.106179Z","level":"error","event":"25/09/01 05:19:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 16de1778b869, 36373, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.110756Z","level":"error","event":"25/09/01 05:19:59 INFO BlockManagerMasterEndpoint: Registering block manager 16de1778b869:36373 with 434.4 MiB RAM, BlockManagerId(driver, 16de1778b869, 36373, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.110966Z","level":"error","event":"25/09/01 05:19:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 16de1778b869, 36373, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.111072Z","level":"error","event":"25/09/01 05:19:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 16de1778b869, 36373, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.374794Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.397361Z","level":"error","event":"25/09/01 05:19:59 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.399627Z","level":"error","event":"25/09/01 05:19:59 INFO SparkContext: SparkContext is stopping with exitCode 0.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.403640Z","level":"error","event":"25/09/01 05:19:59 INFO SparkUI: Stopped Spark web UI at http://16de1778b869:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.411003Z","level":"error","event":"25/09/01 05:19:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.418538Z","level":"error","event":"25/09/01 05:19:59 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.421878Z","level":"error","event":"25/09/01 05:19:59 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.424332Z","level":"error","event":"25/09/01 05:19:59 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.427179Z","level":"error","event":"25/09/01 05:19:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.479771Z","level":"error","event":"25/09/01 05:19:59 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.482327Z","level":"error","event":"25/09/01 05:19:59 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.482418Z","level":"error","event":"25/09/01 05:19:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-8deb5f58-a13b-477e-8499-ff88ae674f05","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.484028Z","level":"error","event":"25/09/01 05:19:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-b6b903fd-d357-4d26-ac7e-eecc04e48089","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:19:59.485598Z","level":"error","event":"25/09/01 05:19:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-b6b903fd-d357-4d26-ac7e-eecc04e48089/pyspark-16f01adc-96f0-4fd9-9843-035e7d2dc21f","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:29:32.958456","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:29:35.468601Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:29:35.468821Z","level":"error","event":"25/09/01 05:29:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:29:35.503194Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:29:35.503512Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:29:39.415059Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:30:10.881781","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:30:12.263994Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:30:13.228945Z","level":"error","event":"25/09/01 05:30:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:13.488787Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:13.488877Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:17.037035Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:30:48.282974","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:30:49.100883Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:30:49.896490Z","level":"error","event":"25/09/01 05:30:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:50.095630Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:50.095806Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:50.882729Z","level":"error","event":"25/09/01 05:30:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:30:53.102945Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:31:24.137141","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:31:24.755450Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:31:25.608573Z","level":"error","event":"25/09/01 05:31:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:31:25.764890Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:31:25.765071Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:31:26.639807Z","level":"error","event":"25/09/01 05:31:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:31:27.831128Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:31:58.463185","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:31:59.117102Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:32:00.005801Z","level":"error","event":"25/09/01 05:32:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:00.180364Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:00.180672Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:01.159987Z","level":"error","event":"25/09/01 05:32:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:02.699609Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:32:33.623287","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:32:34.289833Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:32:35.067823Z","level":"error","event":"25/09/01 05:32:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:35.237912Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:35.238118Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:36.048196Z","level":"error","event":"25/09/01 05:32:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:32:37.333449Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:33:07.899478","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:33:08.485803Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:33:09.189618Z","level":"error","event":"25/09/01 05:33:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:09.328011Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:09.328228Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:09.963215Z","level":"error","event":"25/09/01 05:33:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:11.176048Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:33:42.444445","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:33:43.130844Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:33:43.762754Z","level":"error","event":"25/09/01 05:33:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:43.908576Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:43.911662Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:44.505983Z","level":"error","event":"25/09/01 05:33:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:33:45.805208Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:34:16.841681","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:34:17.559272Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:34:18.178903Z","level":"error","event":"25/09/01 05:34:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:18.314238Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:18.314306Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:20.194890Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:34:51.261354","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:34:51.838568Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:34:52.435632Z","level":"error","event":"25/09/01 05:34:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:52.582069Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:52.582238Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:34:54.555890Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:35:26.039604","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:35:26.671121Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:35:27.535555Z","level":"error","event":"25/09/01 05:35:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:35:27.781656Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:35:27.781937Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:35:28.854214Z","level":"error","event":"25/09/01 05:35:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:35:30.806195Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:36:01.451651","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:36:01.974904Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:36:02.588137Z","level":"error","event":"25/09/01 05:36:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:02.710852Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:02.711049Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:04.666651Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:36:35.747831","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:36:36.316411Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:36:36.980064Z","level":"error","event":"25/09/01 05:36:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:37.129962Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:37.130133Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:36:39.071056Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:37:10.344293","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:37:10.939398Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:37:11.547126Z","level":"error","event":"25/09/01 05:37:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:37:11.809781Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:37:11.810057Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:37:13.980223Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:01.596440","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:40:04.284041Z","level":"error","event":"25/09/01 05:40:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:04.470525Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:04.470800Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.099577Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.099842Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.099949Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100011Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100067Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100123Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100178Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100273Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100329Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100400Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100457Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100505Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100545Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100577Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100609Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100648Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100702Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100757Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100816Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.100866Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:08.099341","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:40:39.464098","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:40:41.187473Z","level":"error","event":"25/09/01 05:40:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:41.429282Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:41.432933Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:42.532702Z","level":"error","event":"25/09/01 05:40:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.241889Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242098Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242163Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242217Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242260Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242290Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242320Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242354Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242402Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242453Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242503Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242555Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242604Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242656Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242709Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242775Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242841Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242901Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242960Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.243005Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:40:44.242115","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:41:15.372508","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:41:16.910771Z","level":"error","event":"25/09/01 05:41:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:17.043478Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:17.043654Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:17.856376Z","level":"error","event":"25/09/01 05:41:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.274959Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275132Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275192Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275246Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275296Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275344Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275391Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275429Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275458Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275488Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275518Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275547Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275576Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275605Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275635Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275663Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275692Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275720Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275748Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275777Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:19.275156","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:41:50.428959","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:41:51.907132Z","level":"error","event":"25/09/01 05:41:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:52.051952Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:52.056491Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147040Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147198Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147249Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147288Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147330Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147365Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147409Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147442Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147474Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147521Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147557Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147588Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147620Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147649Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147695Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147754Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147811Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147884Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147940Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147994Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:41:54.147266","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:42:25.565414","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:42:26.804548Z","level":"error","event":"25/09/01 05:42:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:42:26.983603Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:42:26.983815Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.846535Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.846686Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.846732Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.846769Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.846819Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.846889Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.846960Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847019Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847052Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847084Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847115Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847146Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847176Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847218Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847251Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847281Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847311Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847339Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847368Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.847398Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:42:28.846682","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:43:00.181600","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:43:01.525592Z","level":"error","event":"25/09/01 05:43:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:01.649600Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:01.649810Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.600799Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.600998Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601062Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601100Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601130Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601165Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601194Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601223Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601252Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601282Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601311Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601342Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601374Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601405Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601435Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601462Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601491Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601518Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601546Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.601576Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:03.600952","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:43:34.743413","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:43:36.272288Z","level":"error","event":"25/09/01 05:43:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:36.441877Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:36.444915Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.591767Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.591973Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592074Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592143Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592203Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592280Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592336Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592391Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592446Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592501Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592555Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592609Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592661Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592716Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592775Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592833Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592888Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592939Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.592990Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.593036Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:43:38.591919","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:44:09.282380","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:44:10.517982Z","level":"error","event":"25/09/01 05:44:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:10.679781Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:10.683384Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:11.377429Z","level":"error","event":"25/09/01 05:44:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695364Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695579Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695644Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695695Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695741Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695780Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695811Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695841Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695884Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695914Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695961Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.696027Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.696081Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.696135Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.696186Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.696233Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.696282Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.696334Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.696384Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.696434Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:12.695582","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:44:43.871193","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:44:45.127024Z","level":"error","event":"25/09/01 05:44:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:45.266628Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:45.266779Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:45.990599Z","level":"error","event":"25/09/01 05:44:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.231647Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.231841Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.231921Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.231980Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232024Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232056Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232088Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232137Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232190Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232246Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232302Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232357Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232410Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232462Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232519Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232572Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232625Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232693Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232742Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.232790Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:44:47.231852","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:46:32.711701","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:46:35.302067Z","level":"error","event":"25/09/01 05:46:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:46:35.575161Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:46:35.585956Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:46:36.886499Z","level":"error","event":"25/09/01 05:46:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.027171Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.027408Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.027492Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.027561Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.027628Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.027693Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.027756Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.027817Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.027902Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.027967Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.028031Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.028095Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.028158Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.028224Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.028338Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.028406Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.028473Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.028530Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.028586Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.028645Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:46:39.026824","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:47:10.048589","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:47:11.433181Z","level":"error","event":"25/09/01 05:47:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:11.688996Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:11.689945Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313305Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313412Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313452Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313489Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313522Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313554Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313586Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313616Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313660Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313696Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313741Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313782Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313812Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313841Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313879Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313909Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313939Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313969Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.313998Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.314030Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:14.312093","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:47:45.416320","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:47:47.755846Z","level":"error","event":"25/09/01 05:47:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:47.974061Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:47.974261Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.565994Z","level":"info","event":"Không tìm thấy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566179Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566244Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566299Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566349Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566384Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566415Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566449Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566497Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566549Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566606Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566660Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566714Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566764Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566817Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566898Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566950Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566999Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.567049Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.567099Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:47:50.566178","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":69,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}]}]}
{"timestamp":"2025-09-01T05:49:20.278932","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:49:22.670505Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:49:22.757801Z","level":"error","event":"25/09/01 05:49:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:23.145589Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:23.145823Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:26.457123Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:49:57.509122","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:49:58.141694Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:49:58.823539Z","level":"error","event":"25/09/01 05:49:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:58.951983Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:58.956056Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:49:59.609712Z","level":"error","event":"25/09/01 05:49:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:50:01.061390Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:50:32.054021","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:50:32.639775Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:50:33.298652Z","level":"error","event":"25/09/01 05:50:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:50:33.502370Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:50:33.502630Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:50:35.776174Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:51:06.265073","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:51:07.087069Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:51:07.999139Z","level":"error","event":"25/09/01 05:51:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:08.219444Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:08.219638Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:10.331798Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:51:41.014203","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:51:41.557229Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:51:42.294260Z","level":"error","event":"25/09/01 05:51:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:42.504028Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:42.508433Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:43.216027Z","level":"error","event":"25/09/01 05:51:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:51:44.640496Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:52:15.886318","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:52:16.442115Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:52:17.083508Z","level":"error","event":"25/09/01 05:52:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:17.220800Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:17.221018Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:17.806117Z","level":"error","event":"25/09/01 05:52:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:19.016081Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:52:50.283168","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:52:51.060491Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:52:51.745021Z","level":"error","event":"25/09/01 05:52:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:51.888195Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:51.888408Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:52.472744Z","level":"error","event":"25/09/01 05:52:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:52:53.833096Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:53:25.054561","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:53:25.761618Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:53:26.363424Z","level":"error","event":"25/09/01 05:53:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:53:26.512771Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:53:26.512929Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:53:27.186380Z","level":"error","event":"25/09/01 05:53:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:53:28.585172Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:53:59.791676","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:54:00.354246Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:54:01.011021Z","level":"error","event":"25/09/01 05:54:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:01.259457Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:01.259821Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:01.975491Z","level":"error","event":"25/09/01 05:54:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:03.416366Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:54:33.901837","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:54:34.428248Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:54:35.004440Z","level":"error","event":"25/09/01 05:54:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:35.128593Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:35.128763Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:54:37.020972Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:55:07.669100","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:55:08.233360Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:55:08.870840Z","level":"error","event":"25/09/01 05:55:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:09.003646Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:09.003836Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:09.691873Z","level":"error","event":"25/09/01 05:55:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:11.183184Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:55:42.572319","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:55:43.165036Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:55:43.887684Z","level":"error","event":"25/09/01 05:55:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:44.040783Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:44.040957Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:44.747309Z","level":"error","event":"25/09/01 05:55:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:55:46.168977Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:56:17.497341","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:56:18.081722Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:56:18.760450Z","level":"error","event":"25/09/01 05:56:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:18.940672Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:18.940905Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:20.922542Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:56:52.087349","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:56:52.669244Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:56:53.400642Z","level":"error","event":"25/09/01 05:56:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:53.584262Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:53.584538Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:54.276630Z","level":"error","event":"25/09/01 05:56:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:56:55.717657Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:57:27.060426","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:57:27.600624Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:57:28.242450Z","level":"error","event":"25/09/01 05:57:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:57:28.360959Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:57:28.361178Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:57:29.004267Z","level":"error","event":"25/09/01 05:57:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:57:30.231467Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:58:01.222013","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:58:01.795660Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:58:02.615909Z","level":"error","event":"25/09/01 05:58:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:02.831905Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:02.832126Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:04.821159Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:58:36.192217","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:58:36.694814Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:58:37.304344Z","level":"error","event":"25/09/01 05:58:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:37.485467Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:37.485647Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:38.229263Z","level":"error","event":"25/09/01 05:58:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:58:39.625500Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:59:10.749498","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:59:11.328322Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:59:12.011602Z","level":"error","event":"25/09/01 05:59:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:12.205496Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:12.205736Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:12.900360Z","level":"error","event":"25/09/01 05:59:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:14.370379Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:59:44.915899","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:59:45.493657Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T05:59:46.088195Z","level":"error","event":"25/09/01 05:59:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:46.231838Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:46.232003Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:46.846280Z","level":"error","event":"25/09/01 05:59:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T05:59:48.131307Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:00:19.333810","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:00:19.859362Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:00:20.514961Z","level":"error","event":"25/09/01 06:00:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:20.666763Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:20.667014Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:22.788915Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:00:53.575639","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:00:54.160698Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:00:54.847678Z","level":"error","event":"25/09/01 06:00:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:54.994011Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:54.994228Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:00:57.015249Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:01:27.806259","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:01:28.333266Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:01:28.943876Z","level":"error","event":"25/09/01 06:01:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:01:29.105298Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:01:29.105561Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:01:29.836163Z","level":"error","event":"25/09/01 06:01:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:01:31.467736Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:05:52.308348","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:05:54.676330Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:05:54.676573Z","level":"error","event":"25/09/01 06:05:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:05:55.047001Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:05:55.047294Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:05:58.322345Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:06:29.783762","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:06:30.478642Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:06:31.338306Z","level":"error","event":"25/09/01 06:06:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:06:31.537917Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:06:31.538132Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:06:34.547134Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:07:05.219139","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:07:05.853956Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:07:06.629027Z","level":"error","event":"25/09/01 06:07:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:06.846631Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:06.846778Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:07.464426Z","level":"error","event":"25/09/01 06:07:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:08.782947Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:07:39.865249","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:07:40.517610Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:07:41.181249Z","level":"error","event":"25/09/01 06:07:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:41.313321Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:41.313495Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:41.940106Z","level":"error","event":"25/09/01 06:07:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:07:43.344417Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:08:14.373266","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:08:14.950327Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:08:15.613779Z","level":"error","event":"25/09/01 06:08:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:15.791169Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:15.791417Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:17.824530Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:08:49.295875","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:08:49.835194Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:08:50.443523Z","level":"error","event":"25/09/01 06:08:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:50.604763Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:50.604986Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:08:52.562663Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:09:23.819581","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:09:24.533870Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.175977Z","level":"error","event":"25/09/01 06:09:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.315889Z","level":"error","event":"25/09/01 06:09:25 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.433641Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Running Spark version 3.5.6","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.433742Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.433779Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.452609Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.452709Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.452747Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.452779Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.466492Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.472386Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.474956Z","level":"error","event":"25/09/01 06:09:25 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.506538Z","level":"error","event":"25/09/01 06:09:25 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.506656Z","level":"error","event":"25/09/01 06:09:25 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.506694Z","level":"error","event":"25/09/01 06:09:25 INFO SecurityManager: Changing view acls groups to:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.506725Z","level":"error","event":"25/09/01 06:09:25 INFO SecurityManager: Changing modify acls groups to:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.506756Z","level":"error","event":"25/09/01 06:09:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.679737Z","level":"error","event":"25/09/01 06:09:25 INFO Utils: Successfully started service 'sparkDriver' on port 41711.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.701192Z","level":"error","event":"25/09/01 06:09:25 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.736419Z","level":"error","event":"25/09/01 06:09:25 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.752117Z","level":"error","event":"25/09/01 06:09:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.757901Z","level":"error","event":"25/09/01 06:09:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.758074Z","level":"error","event":"25/09/01 06:09:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.772725Z","level":"error","event":"25/09/01 06:09:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-103dc1a9-5cea-4f02-92f7-b583c20c0d31","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.785196Z","level":"error","event":"25/09/01 06:09:25 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.800733Z","level":"error","event":"25/09/01 06:09:25 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.896272Z","level":"error","event":"25/09/01 06:09:25 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.936791Z","level":"error","event":"25/09/01 06:09:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.970599Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.4.jar at spark://af5d5ce08564:41711/jars/hadoop-aws-3.3.4.jar with timestamp 1756706965426","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973537Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://af5d5ce08564:41711/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756706965426","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973641Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://af5d5ce08564:41711/jars/ojdbc11.jar with timestamp 1756706965426","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973680Z","level":"error","event":"25/09/01 06:09:25 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973712Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973743Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2095)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973773Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2151)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973803Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973842Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973879Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973915Z","level":"error","event":"\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973952Z","level":"error","event":"\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.973980Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:521)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974009Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974036Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974063Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974093Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974120Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974147Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974174Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974201Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974228Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974255Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974283Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974309Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974334Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974359Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:25.974387Z","level":"error","event":"25/09/01 06:09:25 INFO SparkContext: Added JAR /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar at spark://af5d5ce08564:41711/jars/iceberg-aws-bundle-1.9.2.jar with timestamp 1756706965426","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.010246Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Starting executor ID driver on host af5d5ce08564","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.013250Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.013354Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.015313Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/*,file:/opt/airflow/*'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.015406Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@33dd2469 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.022579Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Fetching spark://af5d5ce08564:41711/jars/hadoop-aws-3.3.4.jar with timestamp 1756706965426","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.052775Z","level":"error","event":"25/09/01 06:09:26 INFO TransportClientFactory: Successfully created connection to af5d5ce08564/172.18.0.11:41711 after 15 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.057875Z","level":"error","event":"25/09/01 06:09:26 INFO Utils: Fetching spark://af5d5ce08564:41711/jars/hadoop-aws-3.3.4.jar to /tmp/spark-4295ea6f-a12e-4489-bc03-d5e30db7daa8/userFiles-29ecc4ac-18db-4371-be82-5dc0c9ae7f3b/fetchFileTemp2708944459806030302.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.078530Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Adding file:/tmp/spark-4295ea6f-a12e-4489-bc03-d5e30db7daa8/userFiles-29ecc4ac-18db-4371-be82-5dc0c9ae7f3b/hadoop-aws-3.3.4.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.081565Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Fetching spark://af5d5ce08564:41711/jars/ojdbc11.jar with timestamp 1756706965426","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.081665Z","level":"error","event":"25/09/01 06:09:26 INFO Utils: Fetching spark://af5d5ce08564:41711/jars/ojdbc11.jar to /tmp/spark-4295ea6f-a12e-4489-bc03-d5e30db7daa8/userFiles-29ecc4ac-18db-4371-be82-5dc0c9ae7f3b/fetchFileTemp11064046465499532275.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.092629Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Adding file:/tmp/spark-4295ea6f-a12e-4489-bc03-d5e30db7daa8/userFiles-29ecc4ac-18db-4371-be82-5dc0c9ae7f3b/ojdbc11.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.096983Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Fetching spark://af5d5ce08564:41711/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756706965426","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.097152Z","level":"error","event":"25/09/01 06:09:26 INFO Utils: Fetching spark://af5d5ce08564:41711/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-4295ea6f-a12e-4489-bc03-d5e30db7daa8/userFiles-29ecc4ac-18db-4371-be82-5dc0c9ae7f3b/fetchFileTemp12824312451101622799.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.776258Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Adding file:/tmp/spark-4295ea6f-a12e-4489-bc03-d5e30db7daa8/userFiles-29ecc4ac-18db-4371-be82-5dc0c9ae7f3b/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.781092Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Fetching spark://af5d5ce08564:41711/jars/iceberg-aws-bundle-1.9.2.jar with timestamp 1756706965426","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.781209Z","level":"error","event":"25/09/01 06:09:26 INFO Utils: Fetching spark://af5d5ce08564:41711/jars/iceberg-aws-bundle-1.9.2.jar to /tmp/spark-4295ea6f-a12e-4489-bc03-d5e30db7daa8/userFiles-29ecc4ac-18db-4371-be82-5dc0c9ae7f3b/fetchFileTemp12333890457473239351.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.854586Z","level":"error","event":"25/09/01 06:09:26 INFO Executor: Adding file:/tmp/spark-4295ea6f-a12e-4489-bc03-d5e30db7daa8/userFiles-29ecc4ac-18db-4371-be82-5dc0c9ae7f3b/iceberg-aws-bundle-1.9.2.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.862429Z","level":"error","event":"25/09/01 06:09:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36201.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.862474Z","level":"error","event":"25/09/01 06:09:26 INFO NettyBlockTransferService: Server created on af5d5ce08564:36201","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.865048Z","level":"error","event":"25/09/01 06:09:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.867616Z","level":"error","event":"25/09/01 06:09:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, af5d5ce08564, 36201, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.870095Z","level":"error","event":"25/09/01 06:09:26 INFO BlockManagerMasterEndpoint: Registering block manager af5d5ce08564:36201 with 434.4 MiB RAM, BlockManagerId(driver, af5d5ce08564, 36201, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.872322Z","level":"error","event":"25/09/01 06:09:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, af5d5ce08564, 36201, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:26.872417Z","level":"error","event":"25/09/01 06:09:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, af5d5ce08564, 36201, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.096024Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.128095Z","level":"error","event":"25/09/01 06:09:27 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.128206Z","level":"error","event":"25/09/01 06:09:27 INFO SparkContext: SparkContext is stopping with exitCode 0.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.133910Z","level":"error","event":"25/09/01 06:09:27 INFO SparkUI: Stopped Spark web UI at http://af5d5ce08564:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.139064Z","level":"error","event":"25/09/01 06:09:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.145945Z","level":"error","event":"25/09/01 06:09:27 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.148595Z","level":"error","event":"25/09/01 06:09:27 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.150399Z","level":"error","event":"25/09/01 06:09:27 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.152398Z","level":"error","event":"25/09/01 06:09:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.197658Z","level":"error","event":"25/09/01 06:09:27 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.200084Z","level":"error","event":"25/09/01 06:09:27 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.200177Z","level":"error","event":"25/09/01 06:09:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-6e67fe94-eb2a-4e5c-85c2-a40477bad128","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.201725Z","level":"error","event":"25/09/01 06:09:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-4295ea6f-a12e-4489-bc03-d5e30db7daa8/pyspark-74002c66-a581-4d81-a470-bc96ed48abac","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:09:27.203287Z","level":"error","event":"25/09/01 06:09:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-4295ea6f-a12e-4489-bc03-d5e30db7daa8","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:25:48.987240","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:25:48.991785","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'cx_Oracle'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":2,"name":"<module>"}]}]}
{"timestamp":"2025-09-01T06:26:21.354836","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:26:21.356542","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'cx_Oracle'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":2,"name":"<module>"}]}]}
{"timestamp":"2025-09-01T06:36:02.479922","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:36:04.688716Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:36:04.698124Z","level":"error","event":"25/09/01 06:36:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:04.977125Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:04.977290Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:08.546301Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:36:39.999778","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:36:40.700055Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:36:41.754649Z","level":"error","event":"25/09/01 06:36:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:41.945605Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:41.945803Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:42.887715Z","level":"error","event":"25/09/01 06:36:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:36:44.496829Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:37:15.239123","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:37:15.859046Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:37:16.634926Z","level":"error","event":"25/09/01 06:37:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:16.925492Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:16.925711Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:19.055158Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:37:50.276177","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:37:50.917665Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:37:51.640956Z","level":"error","event":"25/09/01 06:37:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:51.799668Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:51.799880Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:52.637090Z","level":"error","event":"25/09/01 06:37:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:37:53.909250Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:38:24.933775","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:38:25.485809Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:38:26.118354Z","level":"error","event":"25/09/01 06:38:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:38:26.242385Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:38:26.242531Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:38:28.070568Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:38:59.098646","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:38:59.789681Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:39:00.622154Z","level":"error","event":"25/09/01 06:39:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:00.831861Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:00.832046Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:01.634635Z","level":"error","event":"25/09/01 06:39:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:03.296137Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:39:34.059733","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:39:34.596548Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:39:35.284042Z","level":"error","event":"25/09/01 06:39:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:35.472931Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:35.473327Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:39:37.814895Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:40:08.802845","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:40:09.428298Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:40:10.111596Z","level":"error","event":"25/09/01 06:40:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:10.231170Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:10.231331Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:11.000351Z","level":"error","event":"25/09/01 06:40:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:12.150996Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:40:42.695433","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:40:43.491691Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:40:44.192574Z","level":"error","event":"25/09/01 06:40:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:44.358625Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:44.358998Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:44.990040Z","level":"error","event":"25/09/01 06:40:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:40:46.045182Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:41:16.657992","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:41:17.267388Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:41:17.940990Z","level":"error","event":"25/09/01 06:41:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:18.056744Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:18.056961Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:19.766575Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:41:50.703482","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:41:51.260385Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:41:51.925063Z","level":"error","event":"25/09/01 06:41:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:52.054129Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:52.061676Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:41:53.815033Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:42:24.554133","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:42:25.269155Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:42:25.948300Z","level":"error","event":"25/09/01 06:42:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:42:26.083783Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:42:26.084028Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:42:27.790872Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:42:58.418836","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:42:58.988123Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:42:59.593443Z","level":"error","event":"25/09/01 06:42:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:42:59.692718Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:42:59.692900Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:43:01.079642Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:43:31.785223","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:43:32.462945Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:43:33.320494Z","level":"error","event":"25/09/01 06:43:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:43:33.506430Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:43:33.506599Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:43:35.245803Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:44:05.925108","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:44:06.476213Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:44:07.198835Z","level":"error","event":"25/09/01 06:44:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:07.311087Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:07.311268Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:08.049335Z","level":"error","event":"25/09/01 06:44:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:09.047254Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:44:39.896569","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:44:40.547100Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:44:41.213606Z","level":"error","event":"25/09/01 06:44:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:41.340897Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:41.341051Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:41.964313Z","level":"error","event":"25/09/01 06:44:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:44:42.957246Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:45:13.468460","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:45:14.052233Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:45:14.695811Z","level":"error","event":"25/09/01 06:45:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:14.835078Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:14.835311Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:15.603799Z","level":"error","event":"25/09/01 06:45:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:16.724673Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:45:47.224470","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:45:47.811945Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:45:48.523752Z","level":"error","event":"25/09/01 06:45:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:48.723573Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:48.723717Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:49.608114Z","level":"error","event":"25/09/01 06:45:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:45:50.674466Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:46:21.423501","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:46:21.965282Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:46:22.565537Z","level":"error","event":"25/09/01 06:46:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:22.738905Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:22.739050Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:23.479164Z","level":"error","event":"25/09/01 06:46:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:24.833332Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:46:55.404520","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:46:55.947568Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:46:56.573788Z","level":"error","event":"25/09/01 06:46:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:56.697341Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:56.697492Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:57.322601Z","level":"error","event":"25/09/01 06:46:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:46:58.498901Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:47:29.545925","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:47:30.060767Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:47:30.687722Z","level":"error","event":"25/09/01 06:47:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:47:30.833765Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:47:30.833914Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:47:32.605352Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:48:03.761364","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:48:04.604235Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:48:05.472263Z","level":"error","event":"25/09/01 06:48:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:05.681613Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:05.681832Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:06.961446Z","level":"error","event":"25/09/01 06:48:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:09.174817Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:48:40.050288","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:48:40.651001Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:48:41.430992Z","level":"error","event":"25/09/01 06:48:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:41.651470Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:41.651718Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:48:44.163523Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:49:15.597222","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:49:16.260805Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:49:16.939690Z","level":"error","event":"25/09/01 06:49:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:17.127252Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:17.127399Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:17.822941Z","level":"error","event":"25/09/01 06:49:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:19.245760Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:49:49.908748","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:49:50.439166Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:49:51.100845Z","level":"error","event":"25/09/01 06:49:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:51.237962Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:51.238166Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:51.911272Z","level":"error","event":"25/09/01 06:49:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:49:53.093095Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:50:23.662898","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:50:24.315036Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:50:25.032987Z","level":"error","event":"25/09/01 06:50:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:50:25.201609Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:50:25.201806Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:50:25.878203Z","level":"error","event":"25/09/01 06:50:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:50:27.340390Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:50:57.844989","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:50:58.506072Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:50:59.192906Z","level":"error","event":"25/09/01 06:50:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:50:59.359089Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:50:59.359258Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:51:00.211997Z","level":"error","event":"25/09/01 06:51:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:51:02.226274Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:51:32.817163","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:51:33.427416Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:51:34.099009Z","level":"error","event":"25/09/01 06:51:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:51:34.279087Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:51:34.279464Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:51:35.113175Z","level":"error","event":"25/09/01 06:51:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:51:36.571718Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:52:07.131751","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:52:07.822674Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:52:08.493433Z","level":"error","event":"25/09/01 06:52:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:08.651596Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:08.651803Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:09.459962Z","level":"error","event":"25/09/01 06:52:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:10.797311Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:52:42.139906","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:52:42.774428Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:52:43.484897Z","level":"error","event":"25/09/01 06:52:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:43.618074Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:43.618116Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:52:45.794409Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:53:16.973307","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:53:17.774098Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:53:18.879781Z","level":"error","event":"25/09/01 06:53:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:19.154290Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:19.154534Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:20.172049Z","level":"error","event":"25/09/01 06:53:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:21.537795Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:53:52.784535","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:53:53.567116Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:53:54.181889Z","level":"error","event":"25/09/01 06:53:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:54.360639Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:54.360799Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:54.960426Z","level":"error","event":"25/09/01 06:53:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:53:56.262404Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:54:27.374910","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:54:28.184833Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:54:28.833507Z","level":"error","event":"25/09/01 06:54:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:54:28.952378Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:54:28.952530Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:54:29.630127Z","level":"error","event":"25/09/01 06:54:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:54:31.174243Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:55:02.216761","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:55:03.027007Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:55:03.637603Z","level":"error","event":"25/09/01 06:55:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:03.784147Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:03.789564Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:04.394226Z","level":"error","event":"25/09/01 06:55:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:05.744477Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:55:37.118838","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:55:37.922557Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:55:38.603330Z","level":"error","event":"25/09/01 06:55:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:38.732299Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:38.732521Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:55:40.788656Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:56:12.045090","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:56:12.805387Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:56:13.499651Z","level":"error","event":"25/09/01 06:56:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:13.638447Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:13.642684Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:16.553833Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:56:47.432983","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:56:48.449021Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:56:50.383958Z","level":"error","event":"25/09/01 06:56:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:50.973018Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:50.973318Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:52.755669Z","level":"error","event":"25/09/01 06:56:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:56:55.720387Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:57:26.713506","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:57:27.289698Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:57:27.924801Z","level":"error","event":"25/09/01 06:57:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:57:28.079835Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:57:28.080015Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:57:28.764578Z","level":"error","event":"25/09/01 06:57:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:57:30.243387Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:58:01.333908","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:58:02.071279Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:58:02.915195Z","level":"error","event":"25/09/01 06:58:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:03.115929Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:03.116142Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:04.066970Z","level":"error","event":"25/09/01 06:58:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:05.656507Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:58:36.275116","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:58:36.843028Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:58:37.535942Z","level":"error","event":"25/09/01 06:58:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:37.693900Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:37.694121Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:58:39.769516Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:59:10.376950","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:59:10.869203Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:59:11.459110Z","level":"error","event":"25/09/01 06:59:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:11.581227Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:11.586536Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:13.411051Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:59:44.655421","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T06:59:45.219440Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T06:59:45.946034Z","level":"error","event":"25/09/01 06:59:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:46.087329Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:46.087504Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T06:59:48.058837Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:00:19.241201","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:00:19.754761Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:00:20.373653Z","level":"error","event":"25/09/01 07:00:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:20.514078Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:20.518457Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:21.197939Z","level":"error","event":"25/09/01 07:00:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:22.851730Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:00:53.904419","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:00:54.538817Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:00:55.245815Z","level":"error","event":"25/09/01 07:00:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:55.357963Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:55.358105Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:00:57.584215Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:01:28.096406","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:01:28.716650Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:01:29.416501Z","level":"error","event":"25/09/01 07:01:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:01:29.634075Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:01:29.634404Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:01:31.756330Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:02:03.167217","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:02:03.699713Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:02:04.372297Z","level":"error","event":"25/09/01 07:02:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:04.581062Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:04.584497Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:07.174888Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:02:37.736333","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:02:38.291304Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:02:39.022495Z","level":"error","event":"25/09/01 07:02:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:39.156051Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:39.156251Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:39.947646Z","level":"error","event":"25/09/01 07:02:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:02:41.591546Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:03:12.331796","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:03:12.867172Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:03:13.624277Z","level":"error","event":"25/09/01 07:03:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:13.766747Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:13.766969Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:14.513766Z","level":"error","event":"25/09/01 07:03:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:15.657145Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:03:46.407682","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:03:47.001040Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:03:47.919771Z","level":"error","event":"25/09/01 07:03:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:48.098967Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:48.103742Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:48.938712Z","level":"error","event":"25/09/01 07:03:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:03:50.398687Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:04:20.899067","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:04:21.580896Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:04:22.353181Z","level":"error","event":"25/09/01 07:04:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:22.510494Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:22.510652Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:23.245245Z","level":"error","event":"25/09/01 07:04:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:24.637342Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:04:55.279580","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:04:55.982464Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:04:56.833551Z","level":"error","event":"25/09/01 07:04:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:57.000187Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:57.003676Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:57.724274Z","level":"error","event":"25/09/01 07:04:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:04:58.954948Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:05:29.559723","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:05:30.261208Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:05:31.227971Z","level":"error","event":"25/09/01 07:05:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:05:31.483063Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:05:31.484348Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:05:32.419112Z","level":"error","event":"25/09/01 07:05:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:05:34.111189Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:06:04.709879","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:06:05.296587Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:06:06.096962Z","level":"error","event":"25/09/01 07:06:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:06.361204Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:06.361511Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:07.299380Z","level":"error","event":"25/09/01 07:06:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:08.703106Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:06:39.381915","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:06:40.109177Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:06:40.857289Z","level":"error","event":"25/09/01 07:06:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:41.107942Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:41.108162Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:41.882788Z","level":"error","event":"25/09/01 07:06:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:06:43.098465Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:07:13.690782","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:07:14.406399Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:07:15.083117Z","level":"error","event":"25/09/01 07:07:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:15.235014Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:15.235242Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:16.061528Z","level":"error","event":"25/09/01 07:07:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:17.156038Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:07:47.730994","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:07:48.334959Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:07:49.190397Z","level":"error","event":"25/09/01 07:07:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:49.341447Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:49.344982Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:50.039795Z","level":"error","event":"25/09/01 07:07:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:07:51.209843Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:08:21.883741","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:08:22.588050Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:08:23.302098Z","level":"error","event":"25/09/01 07:08:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:23.420662Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:23.420820Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:24.171325Z","level":"error","event":"25/09/01 07:08:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:25.392981Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:08:56.295892","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:08:56.900843Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:08:57.596028Z","level":"error","event":"25/09/01 07:08:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:57.765065Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:57.765277Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:58.524996Z","level":"error","event":"25/09/01 07:08:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:08:59.624299Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:09:30.411810","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:09:31.009960Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:09:31.755320Z","level":"error","event":"25/09/01 07:09:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:09:31.957343Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:09:31.957553Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:09:32.698049Z","level":"error","event":"25/09/01 07:09:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:09:33.883338Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:10:04.739669","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:10:05.531220Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:10:06.288222Z","level":"error","event":"25/09/01 07:10:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:06.458481Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:06.458885Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:07.373619Z","level":"error","event":"25/09/01 07:10:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:08.439868Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:10:39.003411","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:10:39.790438Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:10:40.553279Z","level":"error","event":"25/09/01 07:10:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:40.725833Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:40.730115Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:41.533040Z","level":"error","event":"25/09/01 07:10:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:10:42.757706Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:11:13.426326","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:11:14.216760Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:11:14.938215Z","level":"error","event":"25/09/01 07:11:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:15.094397Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:15.094558Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:15.923474Z","level":"error","event":"25/09/01 07:11:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:17.098072Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:11:47.764966","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:11:48.336588Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:11:49.041283Z","level":"error","event":"25/09/01 07:11:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:49.202881Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:49.203091Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:49.814913Z","level":"error","event":"25/09/01 07:11:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:11:51.094196Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:12:22.429767","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:12:23.015657Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:12:23.694395Z","level":"error","event":"25/09/01 07:12:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:23.839485Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:23.839559Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:25.800153Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:12:56.364585","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:12:57.085893Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:12:57.735470Z","level":"error","event":"25/09/01 07:12:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:57.861444Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:57.861603Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:58.497156Z","level":"error","event":"25/09/01 07:12:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:12:59.944784Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:13:30.484154","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:13:31.023998Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:13:31.633345Z","level":"error","event":"25/09/01 07:13:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:13:31.764378Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:13:31.764568Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:13:32.462962Z","level":"error","event":"25/09/01 07:13:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:13:33.749927Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:14:05.064461","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:14:05.687067Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:14:06.340313Z","level":"error","event":"25/09/01 07:14:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:06.523595Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:06.523787Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:08.389747Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:14:39.850736","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:14:40.401621Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:14:41.031730Z","level":"error","event":"25/09/01 07:14:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:41.191659Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:41.192045Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:42.004989Z","level":"error","event":"25/09/01 07:14:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:14:43.272146Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:15:14.608008","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:15:15.185020Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:15:15.776880Z","level":"error","event":"25/09/01 07:15:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:15.912618Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:15.912820Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:17.859844Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:15:48.471078","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:15:49.088706Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:15:49.816032Z","level":"error","event":"25/09/01 07:15:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:49.988697Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:49.988987Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:15:52.321416Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:16:23.736063","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:16:24.385218Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:16:25.126506Z","level":"error","event":"25/09/01 07:16:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:16:25.287431Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:16:25.287592Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:16:25.998305Z","level":"error","event":"25/09/01 07:16:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:16:27.248779Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:16:57.788185","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:16:58.830209Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:16:59.996812Z","level":"error","event":"25/09/01 07:16:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:00.236345Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:00.243831Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:03.729275Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:17:34.764298","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:17:35.818026Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:17:37.070175Z","level":"error","event":"25/09/01 07:17:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:37.382724Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:37.383090Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:17:41.010414Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:18:12.314964","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:18:13.422292Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:18:14.786983Z","level":"error","event":"25/09/01 07:18:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:15.034023Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:15.041575Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:16.324392Z","level":"error","event":"25/09/01 07:18:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:18.638997Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:18:49.920147","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:18:50.935721Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:18:52.085006Z","level":"error","event":"25/09/01 07:18:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:52.372185Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:52.378700Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:18:55.510822Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:19:26.341639","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:19:27.422627Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:19:28.624042Z","level":"error","event":"25/09/01 07:19:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:19:28.919494Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:19:28.919720Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:19:30.000172Z","level":"error","event":"25/09/01 07:19:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:19:31.936772Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:20:02.591837","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:20:03.809190Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:20:05.002490Z","level":"error","event":"25/09/01 07:20:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:05.288170Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:05.293323Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:08.311600Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:20:39.069517","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:20:40.070976Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:20:41.401228Z","level":"error","event":"25/09/01 07:20:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:41.663598Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:41.663874Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:42.983603Z","level":"error","event":"25/09/01 07:20:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:20:44.883507Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:21:15.765192","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:21:16.816204Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:21:18.083009Z","level":"error","event":"25/09/01 07:21:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:18.379771Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:18.380150Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:19.748921Z","level":"error","event":"25/09/01 07:21:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:21.779989Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:21:53.109676","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:21:54.068039Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:21:55.238254Z","level":"error","event":"25/09/01 07:21:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:55.454579Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:55.454862Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:56.435599Z","level":"error","event":"25/09/01 07:21:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:21:58.095579Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:22:28.909071","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:22:30.156150Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:22:31.336154Z","level":"error","event":"25/09/01 07:22:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:22:31.557910Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:22:31.558143Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:22:32.451434Z","level":"error","event":"25/09/01 07:22:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:22:34.092529Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:23:05.578123","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:23:06.495357Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:23:07.528137Z","level":"error","event":"25/09/01 07:23:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:07.747808Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:07.753011Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:08.775205Z","level":"error","event":"25/09/01 07:23:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:10.767659Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:23:41.607192","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:23:42.664598Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:23:43.835441Z","level":"error","event":"25/09/01 07:23:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:44.048759Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:44.049078Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:45.099730Z","level":"error","event":"25/09/01 07:23:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:23:47.659705Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:24:18.752326","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:24:19.750704Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:24:20.801848Z","level":"error","event":"25/09/01 07:24:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:21.027688Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:21.027994Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:21.878159Z","level":"error","event":"25/09/01 07:24:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:23.491864Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:24:54.706517","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:24:55.574507Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:24:56.532019Z","level":"error","event":"25/09/01 07:24:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:56.736183Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:56.736414Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:57.631910Z","level":"error","event":"25/09/01 07:24:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:24:59.354428Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:25:30.676872","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:25:31.509828Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:25:32.600929Z","level":"error","event":"25/09/01 07:25:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:25:32.829007Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:25:32.835998Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:25:33.797166Z","level":"error","event":"25/09/01 07:25:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:25:35.576702Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:26:07.029718","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:26:07.982085Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:26:09.143719Z","level":"error","event":"25/09/01 07:26:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:09.421715Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:09.421963Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:10.389621Z","level":"error","event":"25/09/01 07:26:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:12.299639Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:26:43.617325","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:26:44.505227Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:26:45.520884Z","level":"error","event":"25/09/01 07:26:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:45.735482Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:45.741933Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:47.017152Z","level":"error","event":"25/09/01 07:26:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:26:48.772845Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:27:20.252526","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:27:21.525211Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:27:23.105312Z","level":"error","event":"25/09/01 07:27:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:27:23.294088Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:27:23.300242Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:27:25.738737Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:27:57.285805","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:27:58.697621Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:27:59.986887Z","level":"error","event":"25/09/01 07:27:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:28:00.219679Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:28:00.225227Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:28:02.836251Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:28:34.071521","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:28:34.970065Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:28:35.856164Z","level":"error","event":"25/09/01 07:28:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:28:36.104813Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:28:36.105022Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:28:38.798225Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:29:09.597612","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:29:10.446625Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:29:11.289342Z","level":"error","event":"25/09/01 07:29:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:11.461118Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:11.461283Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:13.658456Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:29:44.726202","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:29:45.542362Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:29:46.507982Z","level":"error","event":"25/09/01 07:29:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:46.704124Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:46.704399Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:29:49.028918Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:30:19.953033","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:30:20.686784Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:30:21.548107Z","level":"error","event":"25/09/01 07:30:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:30:21.721019Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:30:21.721574Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:30:24.486800Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:30:55.885006","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:30:57.000577Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:30:58.182756Z","level":"error","event":"25/09/01 07:30:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:30:58.472008Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:30:58.472642Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:31:01.682638Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:31:32.969256","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:31:34.038115Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:31:35.394034Z","level":"error","event":"25/09/01 07:31:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:31:35.706239Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:31:35.706446Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:31:38.938542Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:32:09.659785","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:32:10.515585Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:32:11.587121Z","level":"error","event":"25/09/01 07:32:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:11.803675Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:11.804041Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:14.323213Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:32:45.076428","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:32:46.006590Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:32:46.971467Z","level":"error","event":"25/09/01 07:32:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:47.150249Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:47.167977Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:32:49.324363Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:33:20.106457","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:33:20.931486Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:33:21.931388Z","level":"error","event":"25/09/01 07:33:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:22.110725Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:22.111025Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:24.567193Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:33:55.319222","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:33:56.126109Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:33:57.021836Z","level":"error","event":"25/09/01 07:33:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:57.200062Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:57.206040Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:33:59.460938Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:34:31.008315","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:34:31.769030Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:34:32.536208Z","level":"error","event":"25/09/01 07:34:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:34:32.777221Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:34:32.777531Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:34:34.804809Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:35:05.673366","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:35:06.356562Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:35:07.216668Z","level":"error","event":"25/09/01 07:35:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:07.401746Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:07.401998Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:09.398241Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:35:40.065171","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:35:41.018106Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:35:42.113530Z","level":"error","event":"25/09/01 07:35:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:42.275791Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:42.276080Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:35:44.586971Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:36:15.653314","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:36:16.727030Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:36:17.761252Z","level":"error","event":"25/09/01 07:36:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:17.962745Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:17.963041Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:20.794743Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:36:51.985607","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:36:52.836533Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:36:53.752483Z","level":"error","event":"25/09/01 07:36:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:53.931560Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:53.939493Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:36:56.347366Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:37:27.517822","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:37:28.518709Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:37:29.537936Z","level":"error","event":"25/09/01 07:37:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:37:29.686304Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:37:29.686554Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:37:31.915659Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:38:02.660184","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:38:03.854995Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:38:05.123598Z","level":"error","event":"25/09/01 07:38:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:05.342600Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:05.343344Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:08.130484Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:38:39.135212","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:38:40.140036Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:38:41.174174Z","level":"error","event":"25/09/01 07:38:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:41.364222Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:41.364662Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:38:43.971422Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:39:15.264232","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:39:16.144820Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:39:17.262669Z","level":"error","event":"25/09/01 07:39:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:17.443361Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:17.443930Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:20.136127Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:39:50.785548","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:39:51.639354Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:39:52.846938Z","level":"error","event":"25/09/01 07:39:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:53.045357Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:53.045825Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:39:55.663471Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:40:26.736974","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:40:27.789442Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:40:28.716841Z","level":"error","event":"25/09/01 07:40:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:40:28.861644Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:40:28.861821Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:40:31.012151Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:41:02.015522","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:41:02.776359Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:41:04.128567Z","level":"error","event":"25/09/01 07:41:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:41:04.298592Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:41:04.298980Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:41:06.458688Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:41:37.308265","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:41:38.294494Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:41:39.260117Z","level":"error","event":"25/09/01 07:41:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:41:39.411429Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:41:39.432282Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:41:41.762871Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:42:13.236966","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:42:13.968447Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:42:14.834240Z","level":"error","event":"25/09/01 07:42:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:15.016258Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:15.016415Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:16.982195Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:42:47.674337","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:42:48.396265Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:42:49.341949Z","level":"error","event":"25/09/01 07:42:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:49.514906Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:49.515139Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:42:51.633147Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:43:22.351663","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:43:23.248619Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:43:24.108683Z","level":"error","event":"25/09/01 07:43:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:43:24.262054Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:43:24.262392Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:43:26.729132Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:43:57.417756","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:43:58.396224Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:43:59.226536Z","level":"error","event":"25/09/01 07:43:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:43:59.399644Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:43:59.399983Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:44:01.825507Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:44:33.069877","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:44:34.100589Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:44:35.089940Z","level":"error","event":"25/09/01 07:44:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:44:35.310768Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:44:35.319693Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:44:37.912627Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:45:08.849976","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:45:09.765418Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:45:10.562171Z","level":"error","event":"25/09/01 07:45:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:10.711617Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:10.711943Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:13.028306Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:45:43.979495","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:45:44.886796Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:45:45.715692Z","level":"error","event":"25/09/01 07:45:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:45.877798Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:45.883836Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:45:48.198494Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:46:18.998623","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:46:20.120008Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:46:21.370067Z","level":"error","event":"25/09/01 07:46:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:21.573105Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:21.573498Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:24.232749Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:46:55.568073","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:46:56.384127Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:46:57.184594Z","level":"error","event":"25/09/01 07:46:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:57.325897Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:57.326144Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:46:59.369441Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:47:30.360767","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:47:31.464488Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:47:32.437037Z","level":"error","event":"25/09/01 07:47:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:47:32.594208Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:47:32.598080Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:47:34.868663Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:48:05.637639","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:48:06.511124Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:48:07.432326Z","level":"error","event":"25/09/01 07:48:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:07.637532Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:07.643263Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:09.817670Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:48:40.526783","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:48:41.659933Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:48:42.614082Z","level":"error","event":"25/09/01 07:48:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:42.785515Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:42.786027Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:48:44.993581Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:49:15.859295","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:49:16.776086Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:49:17.714631Z","level":"error","event":"25/09/01 07:49:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:17.882835Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:17.883327Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:20.214191Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:49:50.963081","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:49:51.950329Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:49:53.264886Z","level":"error","event":"25/09/01 07:49:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:53.516905Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:53.531203Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:49:56.506454Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:50:27.315140","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:50:28.313441Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:50:29.320874Z","level":"error","event":"25/09/01 07:50:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:50:29.484834Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:50:29.489652Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:50:31.879914Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:51:02.691096","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:51:03.708458Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:51:04.673260Z","level":"error","event":"25/09/01 07:51:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:04.856076Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:04.856236Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:07.431872Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:51:38.297727","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:51:39.130290Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:51:40.325526Z","level":"error","event":"25/09/01 07:51:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:40.582160Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:40.582754Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:51:43.567556Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:52:14.197200","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:52:14.966875Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:52:15.913112Z","level":"error","event":"25/09/01 07:52:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:16.110268Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:16.110701Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:18.624331Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:52:49.652352","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:52:50.580777Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:52:51.570753Z","level":"error","event":"25/09/01 07:52:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:51.791473Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:51.791993Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:52:55.019414Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:53:25.824505","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:53:26.808266Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:53:28.134189Z","level":"error","event":"25/09/01 07:53:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:53:28.348583Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:53:28.368712Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:53:31.497649Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:54:02.795642","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:54:03.691325Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:54:04.723440Z","level":"error","event":"25/09/01 07:54:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:54:04.934294Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:54:04.934558Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:54:08.448988Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:54:39.512242","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:54:40.724144Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:54:42.371217Z","level":"error","event":"25/09/01 07:54:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:54:42.690215Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:54:42.690507Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:54:46.526159Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:55:17.550694","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:55:18.332654Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:55:19.231896Z","level":"error","event":"25/09/01 07:55:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:19.442219Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:19.442763Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:21.901676Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:55:52.930398","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:55:54.095269Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:55:55.174173Z","level":"error","event":"25/09/01 07:55:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:55.325309Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:55.325688Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:55:57.587105Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:56:28.678147","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:56:30.211898Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:56:31.684183Z","level":"error","event":"25/09/01 07:56:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:56:31.908447Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:56:31.908967Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:56:34.696217Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:57:05.528481","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:57:06.665987Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:57:07.600592Z","level":"error","event":"25/09/01 07:57:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:57:07.781144Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:57:07.781454Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:57:10.022208Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:57:41.412067","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:57:42.356322Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:57:43.267384Z","level":"error","event":"25/09/01 07:57:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:57:43.427748Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:57:43.433336Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:57:45.567630Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:58:16.981264","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:58:17.938368Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:58:19.050971Z","level":"error","event":"25/09/01 07:58:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:19.306796Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:19.307354Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:22.127609Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:58:53.241126","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:58:54.445223Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:58:55.656796Z","level":"error","event":"25/09/01 07:58:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:55.859100Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:55.859313Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:58:58.743431Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:59:29.422140","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T07:59:30.534102Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T07:59:31.621286Z","level":"error","event":"25/09/01 07:59:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:59:31.808703Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:59:31.809151Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T07:59:34.595209Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:00:05.433991","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:00:06.312341Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:00:07.243202Z","level":"error","event":"25/09/01 08:00:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:00:07.450511Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:00:07.451096Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:00:10.102168Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:00:41.055693","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:00:41.884995Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:00:42.691499Z","level":"error","event":"25/09/01 08:00:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:00:42.859246Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:00:42.859518Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:00:45.144600Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:01:15.784648","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:01:16.744267Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:01:17.976975Z","level":"error","event":"25/09/01 08:01:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:18.187797Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:18.188306Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:21.297318Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:01:52.218652","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:01:53.129326Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:01:54.152608Z","level":"error","event":"25/09/01 08:01:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:54.344117Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:54.344533Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:01:56.757725Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:02:27.936713","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:02:28.864366Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:02:29.688375Z","level":"error","event":"25/09/01 08:02:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:02:29.897093Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:02:29.897361Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:02:32.663222Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:03:04.172851","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:03:05.201637Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:03:06.434307Z","level":"error","event":"25/09/01 08:03:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:03:06.592685Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:03:06.593138Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:03:09.124297Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:03:40.085103","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:03:40.912431Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:03:41.940771Z","level":"error","event":"25/09/01 08:03:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:03:42.176786Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:03:42.177284Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:03:44.563597Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:04:15.996335","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:04:16.753482Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:04:17.835743Z","level":"error","event":"25/09/01 08:04:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:18.099516Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:18.100090Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:21.187590Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:04:52.231111","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:04:53.115100Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:04:54.028529Z","level":"error","event":"25/09/01 08:04:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:54.265324Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:54.265751Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:04:56.881538Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:05:27.587958","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:05:28.287418Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:05:29.108817Z","level":"error","event":"25/09/01 08:05:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:05:29.305689Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:05:29.312405Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:05:31.514345Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:06:02.869853","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:06:03.854543Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:06:04.701863Z","level":"error","event":"25/09/01 08:06:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:06:04.879123Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:06:04.879771Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:06:07.013682Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:06:37.942948","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:06:38.629665Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:06:39.526373Z","level":"error","event":"25/09/01 08:06:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:06:39.674723Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:06:39.675139Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:06:41.761664Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:07:12.325325","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:07:13.041007Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:07:14.048531Z","level":"error","event":"25/09/01 08:07:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:14.277869Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:14.278301Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:16.697890Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:07:48.271070","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:07:48.992632Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:07:49.792342Z","level":"error","event":"25/09/01 08:07:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:49.976974Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:49.977568Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:07:52.037929Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:08:22.800153","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:08:23.660270Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:08:24.555497Z","level":"error","event":"25/09/01 08:08:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:08:24.774648Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:08:24.775052Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:08:26.985581Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:08:57.854026","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:08:58.548735Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:08:59.518818Z","level":"error","event":"25/09/01 08:08:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:08:59.714078Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:08:59.714269Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:09:02.029498Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:09:32.648545","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:09:33.612234Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:09:34.505871Z","level":"error","event":"25/09/01 08:09:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:09:34.693470Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:09:34.693999Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:09:36.893232Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:10:07.761242","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:10:08.579543Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:10:09.423429Z","level":"error","event":"25/09/01 08:10:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:09.567585Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:09.574652Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:11.873410Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:10:43.225615","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:10:44.112064Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:10:44.995096Z","level":"error","event":"25/09/01 08:10:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:45.165460Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:45.186996Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:10:47.714365Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:11:18.547469","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:11:19.305351Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:11:20.394552Z","level":"error","event":"25/09/01 08:11:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:20.623210Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:20.623781Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:23.092033Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:11:54.961205","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:11:55.884359Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:11:56.649305Z","level":"error","event":"25/09/01 08:11:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:56.829410Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:56.829655Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:11:58.907003Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:12:29.700434","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:12:30.740756Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:12:31.571451Z","level":"error","event":"25/09/01 08:12:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:12:31.732423Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:12:31.732621Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:12:33.904306Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:13:04.528558","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:13:05.239479Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:13:06.109599Z","level":"error","event":"25/09/01 08:13:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:13:06.339721Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:13:06.339928Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:13:08.552084Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:13:39.691009","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:13:40.513736Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:13:41.415397Z","level":"error","event":"25/09/01 08:13:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:13:41.603029Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:13:41.603414Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:13:43.761257Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:14:14.590152","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:14:15.349619Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:14:16.137551Z","level":"error","event":"25/09/01 08:14:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:16.306793Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:16.307050Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:18.682235Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:14:49.428474","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:14:50.189609Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:14:51.078211Z","level":"error","event":"25/09/01 08:14:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:51.238073Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:51.238296Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:14:53.640646Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:15:24.354450","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:15:25.318390Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:15:26.185064Z","level":"error","event":"25/09/01 08:15:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:15:26.390553Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:15:26.391050Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:15:28.850286Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:15:59.513120","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T08:16:00.740023Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T08:16:01.651598Z","level":"error","event":"25/09/01 08:16:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:16:01.860974Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T08:16:01.861221Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:14:36.991983","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:14:39.931836Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:14:40.711529Z","level":"error","event":"25/09/01 11:14:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:14:41.078819Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:14:41.079033Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:14:42.473842Z","level":"error","event":"25/09/01 11:14:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:14:44.858104Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:15:15.970869","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:15:16.639128Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:15:17.369067Z","level":"error","event":"25/09/01 11:15:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:17.483980Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:17.484225Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:18.080103Z","level":"error","event":"25/09/01 11:15:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:19.600248Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:15:50.855516","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:15:51.689255Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:15:52.615066Z","level":"error","event":"25/09/01 11:15:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:52.810073Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:52.810280Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:53.851219Z","level":"error","event":"25/09/01 11:15:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:15:57.441551Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:16:28.522182","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:16:29.179024Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:16:29.957671Z","level":"error","event":"25/09/01 11:16:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:16:30.110634Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:16:30.110850Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:16:30.962353Z","level":"error","event":"25/09/01 11:16:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:16:32.748168Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:17:03.336624","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:17:04.201263Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:17:05.340446Z","level":"error","event":"25/09/01 11:17:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:05.573265Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:05.582619Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:09.962819Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:17:41.324437","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:17:41.986008Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:17:42.903930Z","level":"error","event":"25/09/01 11:17:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:43.117487Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:43.124563Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:17:46.382186Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:18:16.953445","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:18:17.912177Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:18:18.651314Z","level":"error","event":"25/09/01 11:18:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:18.790703Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:18.790946Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:19.516925Z","level":"error","event":"25/09/01 11:18:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:20.948417Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:18:51.603825","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:18:52.454268Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:18:53.337062Z","level":"error","event":"25/09/01 11:18:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:53.518568Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:53.518798Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:54.316181Z","level":"error","event":"25/09/01 11:18:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:18:55.940932Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:19:26.534327","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:19:27.663605Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:19:28.411591Z","level":"error","event":"25/09/01 11:19:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:19:28.592165Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:19:28.592412Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:19:31.085996Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:20:02.483325","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:20:03.174901Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:20:04.084917Z","level":"error","event":"25/09/01 11:20:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:04.265755Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:04.265942Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:05.026069Z","level":"error","event":"25/09/01 11:20:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:06.503595Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:20:37.226250","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:20:38.062457Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:20:38.899529Z","level":"error","event":"25/09/01 11:20:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:39.049690Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:39.049914Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:20:41.323766Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:21:11.997965","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:21:12.680574Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:21:13.471652Z","level":"error","event":"25/09/01 11:21:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:13.606219Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:13.610470Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:14.413090Z","level":"error","event":"25/09/01 11:21:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:15.920725Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:21:46.518198","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:21:47.148148Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:21:47.851103Z","level":"error","event":"25/09/01 11:21:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:48.099526Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:48.107200Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:48.983343Z","level":"error","event":"25/09/01 11:21:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:21:50.470838Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:22:21.205510","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:22:21.803557Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:22:22.512282Z","level":"error","event":"25/09/01 11:22:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:22.662931Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:22.663116Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:23.432643Z","level":"error","event":"25/09/01 11:22:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:24.776497Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:22:55.965535","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:22:56.586624Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:22:57.292512Z","level":"error","event":"25/09/01 11:22:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:57.465981Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:57.466297Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:58.156152Z","level":"error","event":"25/09/01 11:22:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:22:59.667805Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:23:30.591093","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:23:31.255654Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:23:31.958779Z","level":"error","event":"25/09/01 11:23:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:23:32.150603Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:23:32.150947Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:23:34.483484Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:24:05.338797","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:24:05.899251Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:24:06.732307Z","level":"error","event":"25/09/01 11:24:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:06.907259Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:06.911510Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:09.659928Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:24:40.313338","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:24:40.978352Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:24:41.761012Z","level":"error","event":"25/09/01 11:24:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:41.990312Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:41.990515Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:24:44.301758Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:25:14.935827","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:25:15.586751Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:25:16.442690Z","level":"error","event":"25/09/01 11:25:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:16.645593Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:16.651652Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:19.360952Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:25:50.386538","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:25:51.096101Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:25:51.974553Z","level":"error","event":"25/09/01 11:25:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:52.176965Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:52.177363Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:53.050254Z","level":"error","event":"25/09/01 11:25:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:25:54.977401Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:26:25.673353","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:26:26.409933Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:26:27.330150Z","level":"error","event":"25/09/01 11:26:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:26:27.602287Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:26:27.602547Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:26:30.268891Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:27:01.193535","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:27:01.837197Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:27:02.557100Z","level":"error","event":"25/09/01 11:27:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:02.739907Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:02.740137Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:04.711002Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:27:35.992705","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:27:36.649670Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:27:37.475862Z","level":"error","event":"25/09/01 11:27:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:37.642475Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:37.642638Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:27:39.723727Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:28:11.131016","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:28:11.817917Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:28:12.449265Z","level":"error","event":"25/09/01 11:28:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:12.604714Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:12.609081Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:13.335026Z","level":"error","event":"25/09/01 11:28:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:14.650246Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:28:45.616333","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:28:46.303219Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:28:47.098876Z","level":"error","event":"25/09/01 11:28:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:47.316241Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:47.316499Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:28:49.706353Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:29:20.527535","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:29:21.210433Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:29:21.980259Z","level":"error","event":"25/09/01 11:29:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:22.201396Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:22.201592Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:24.399717Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:29:55.153648","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:29:55.707323Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:29:56.410732Z","level":"error","event":"25/09/01 11:29:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:56.601233Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:56.601492Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:29:58.594976Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:30:29.259941","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:30:29.961885Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:30:30.651542Z","level":"error","event":"25/09/01 11:30:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:30:30.784294Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:30:30.784517Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:30:33.166967Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:31:04.367405","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:31:04.929745Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:31:05.583543Z","level":"error","event":"25/09/01 11:31:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:05.754204Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:05.759825Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:06.385639Z","level":"error","event":"25/09/01 11:31:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:07.716742Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:31:38.793143","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:31:39.513401Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:31:40.268142Z","level":"error","event":"25/09/01 11:31:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:40.425505Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:40.425731Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:31:42.779410Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:32:13.366296","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:32:13.912057Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:32:14.509874Z","level":"error","event":"25/09/01 11:32:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:14.650125Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:14.650365Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:16.705204Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:32:48.079192","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:32:48.634231Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:32:49.399750Z","level":"error","event":"25/09/01 11:32:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:49.565233Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:49.565567Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:50.399940Z","level":"error","event":"25/09/01 11:32:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:32:51.599147Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:33:22.585033","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:33:23.169262Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:33:23.798853Z","level":"error","event":"25/09/01 11:33:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:23.973111Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:23.973286Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:24.669281Z","level":"error","event":"25/09/01 11:33:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:25.989386Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:33:57.058530","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:33:57.895264Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:33:58.522308Z","level":"error","event":"25/09/01 11:33:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:58.686266Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:58.686425Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:33:59.347100Z","level":"error","event":"25/09/01 11:33:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:34:00.843071Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:34:31.768394","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:34:32.489577Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:34:33.082748Z","level":"error","event":"25/09/01 11:34:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:34:33.226041Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:34:33.226201Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:34:33.998958Z","level":"error","event":"25/09/01 11:34:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:34:35.294144Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:35:06.441541","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:35:07.205048Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:35:07.839233Z","level":"error","event":"25/09/01 11:35:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:07.982274Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:07.987696Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:08.745177Z","level":"error","event":"25/09/01 11:35:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:09.956507Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:35:40.668398","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:35:41.276540Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:35:42.018892Z","level":"error","event":"25/09/01 11:35:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:42.174703Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:42.174881Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:35:43.873732Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:36:14.662739","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:36:15.330431Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:36:16.077228Z","level":"error","event":"25/09/01 11:36:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:16.201453Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:16.201653Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:17.767338Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:36:48.737142","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:36:49.326270Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:36:50.261836Z","level":"error","event":"25/09/01 11:36:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:50.391162Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:50.391311Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:36:51.949202Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:37:22.893488","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:37:23.526663Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:37:24.234707Z","level":"error","event":"25/09/01 11:37:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:24.408345Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:24.408513Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:26.146794Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:37:56.740345","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:37:57.300113Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:37:57.938217Z","level":"error","event":"25/09/01 11:37:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:58.067979Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:58.068134Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:58.854754Z","level":"error","event":"25/09/01 11:37:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:37:59.945408Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:38:30.486976","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:38:31.044413Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:38:31.736319Z","level":"error","event":"25/09/01 11:38:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:38:31.885597Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:38:31.885757Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:38:32.616740Z","level":"error","event":"25/09/01 11:38:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:38:33.696063Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:39:04.262081","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:39:05.080050Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:39:05.874491Z","level":"error","event":"25/09/01 11:39:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:06.047190Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:06.047374Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:07.087985Z","level":"error","event":"25/09/01 11:39:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:08.544163Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:39:39.863182","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:39:40.399017Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:39:41.133617Z","level":"error","event":"25/09/01 11:39:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:41.313936Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:41.314246Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:42.218562Z","level":"error","event":"25/09/01 11:39:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:39:43.525359Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:40:14.182559","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:40:14.792155Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:40:15.515810Z","level":"error","event":"25/09/01 11:40:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:15.667726Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:15.667873Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:17.611238Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:40:48.863319","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:40:49.419323Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:40:50.074028Z","level":"error","event":"25/09/01 11:40:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:50.232935Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:50.233152Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:50.991324Z","level":"error","event":"25/09/01 11:40:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:40:52.248382Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:41:23.385926","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:41:23.950184Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:41:24.557322Z","level":"error","event":"25/09/01 11:41:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:41:24.699703Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:41:24.699903Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:41:25.350998Z","level":"error","event":"25/09/01 11:41:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:41:26.807728Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:41:58.135563","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:41:58.765694Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:41:59.419275Z","level":"error","event":"25/09/01 11:41:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:41:59.587132Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:41:59.587311Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:42:00.346745Z","level":"error","event":"25/09/01 11:42:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:42:01.564980Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:42:32.774125","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:42:33.378855Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:42:33.953440Z","level":"error","event":"25/09/01 11:42:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:42:34.094677Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:42:34.094847Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:42:36.074301Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:43:07.265045","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:43:07.851997Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:43:08.543009Z","level":"error","event":"25/09/01 11:43:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:08.743605Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:08.743896Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:10.987846Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:43:42.221828","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:43:42.783778Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:43:43.369596Z","level":"error","event":"25/09/01 11:43:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:43.492568Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:43.492736Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:44.168321Z","level":"error","event":"25/09/01 11:43:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:43:45.389253Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:44:16.502565","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:44:17.049598Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:44:17.716052Z","level":"error","event":"25/09/01 11:44:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:17.870562Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:17.870641Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:20.146988Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:44:50.908636","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:44:51.504476Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:44:52.271092Z","level":"error","event":"25/09/01 11:44:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:52.414976Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:52.420038Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:44:54.312895Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:45:25.741464","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:45:26.319194Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:45:26.919340Z","level":"error","event":"25/09/01 11:45:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:45:27.060173Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:45:27.060377Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:45:28.846772Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:46:00.040023","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:46:00.574274Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:46:01.232973Z","level":"error","event":"25/09/01 11:46:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:01.400486Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:01.400762Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:03.446902Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:46:34.463555","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:46:35.149548Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:46:35.846628Z","level":"error","event":"25/09/01 11:46:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:36.028263Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:36.028448Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:46:38.435010Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:47:09.692979","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:47:10.247181Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:47:10.924422Z","level":"error","event":"25/09/01 11:47:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:11.106539Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:11.106752Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:13.117638Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:47:44.289022","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:47:44.886250Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:47:45.629813Z","level":"error","event":"25/09/01 11:47:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:45.821675Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:45.822136Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:46.627159Z","level":"error","event":"25/09/01 11:47:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:47:47.942794Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:48:19.204490","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:48:19.807070Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:48:20.437092Z","level":"error","event":"25/09/01 11:48:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:20.576263Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:20.576515Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:21.264753Z","level":"error","event":"25/09/01 11:48:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:22.507428Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:48:53.874109","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:48:54.583101Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:48:55.204276Z","level":"error","event":"25/09/01 11:48:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:55.328053Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:55.328200Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:56.062297Z","level":"error","event":"25/09/01 11:48:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:48:57.667584Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:49:28.473665","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:49:29.308306Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:49:29.962800Z","level":"error","event":"25/09/01 11:49:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:49:30.177452Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:49:30.177797Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:49:32.304350Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:50:02.860793","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:50:03.706802Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:50:04.388297Z","level":"error","event":"25/09/01 11:50:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:04.550052Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:04.556445Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:05.519620Z","level":"error","event":"25/09/01 11:50:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:07.113945Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:50:38.178796","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:50:38.746003Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:50:39.411985Z","level":"error","event":"25/09/01 11:50:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:39.577238Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:39.577451Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:40.323864Z","level":"error","event":"25/09/01 11:50:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:50:41.691427Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:51:12.903843","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:51:13.594980Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:51:14.294879Z","level":"error","event":"25/09/01 11:51:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:14.497926Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:14.498146Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:15.284296Z","level":"error","event":"25/09/01 11:51:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:16.829851Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:51:48.220746","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:51:48.859896Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:51:49.594962Z","level":"error","event":"25/09/01 11:51:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:49.794299Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:49.794569Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:51:52.224887Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:52:22.797848","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:52:23.475860Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:52:24.179836Z","level":"error","event":"25/09/01 11:52:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:52:24.358719Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:52:24.359103Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:52:26.626868Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:52:57.253473","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:52:57.809932Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:52:58.446316Z","level":"error","event":"25/09/01 11:52:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:52:58.584400Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:52:58.588323Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:53:00.481839Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:53:31.238099","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:53:31.751473Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:53:32.296636Z","level":"error","event":"25/09/01 11:53:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:53:32.445996Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:53:32.446154Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:53:34.133826Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:54:04.658821","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:54:05.174802Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:54:05.789940Z","level":"error","event":"25/09/01 11:54:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:05.943568Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:05.948913Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:08.117136Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:54:39.165502","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:54:39.750670Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:54:40.377441Z","level":"error","event":"25/09/01 11:54:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:40.558084Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:40.558287Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:54:42.486405Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:55:13.109435","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:55:13.734954Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:55:14.355771Z","level":"error","event":"25/09/01 11:55:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:14.485590Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:14.485762Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:16.573771Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:55:47.361305","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:55:47.878914Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:55:48.448275Z","level":"error","event":"25/09/01 11:55:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:48.560079Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:48.560233Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:55:50.272621Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:56:20.849893","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:56:21.376594Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:56:21.987888Z","level":"error","event":"25/09/01 11:56:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:22.124710Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:22.124915Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:24.006472Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:56:54.619989","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:56:55.145126Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:56:55.743629Z","level":"error","event":"25/09/01 11:56:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:55.874814Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:55.874931Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:56:57.824389Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:57:28.569810","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:57:29.071766Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:57:29.834087Z","level":"error","event":"25/09/01 11:57:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:57:29.995593Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:57:29.995833Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:57:31.699838Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:58:02.222393","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:58:02.709795Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:58:03.352788Z","level":"error","event":"25/09/01 11:58:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:03.516102Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:03.516340Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:05.365253Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:58:36.127659","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:58:36.637612Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:58:37.220311Z","level":"error","event":"25/09/01 11:58:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:37.365281Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:37.365507Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:58:39.259304Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:59:10.135980","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:59:10.641821Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:59:11.266542Z","level":"error","event":"25/09/01 11:59:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:11.394366Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:11.394524Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:13.162231Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:59:43.867700","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T11:59:44.402967Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T11:59:45.011296Z","level":"error","event":"25/09/01 11:59:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:45.135566Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:45.138468Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T11:59:46.901983Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:00:17.645163","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:00:18.649430Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:00:19.448215Z","level":"error","event":"25/09/01 12:00:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:19.574719Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:19.574936Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:23.159768Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:00:53.850305","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:00:54.475122Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:00:55.290706Z","level":"error","event":"25/09/01 12:00:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:55.447985Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:55.452212Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:00:57.833574Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:01:28.422565","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:01:29.021479Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:01:29.795553Z","level":"error","event":"25/09/01 12:01:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:01:29.909986Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:01:29.910166Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:01:31.758438Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:02:02.344979","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:02:02.888266Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:02:03.457903Z","level":"error","event":"25/09/01 12:02:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:03.581356Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:03.584754Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:05.334846Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:02:36.175445","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:02:36.689735Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:02:37.294865Z","level":"error","event":"25/09/01 12:02:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:37.419201Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:37.419450Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:02:39.079060Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:03:09.810409","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:03:10.349076Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:03:10.946252Z","level":"error","event":"25/09/01 12:03:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:11.067877Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:11.068090Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:13.198430Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:03:44.040072","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:03:44.622471Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:03:45.223737Z","level":"error","event":"25/09/01 12:03:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:45.473442Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:45.473796Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:03:47.377741Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:04:18.038505","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:04:18.882508Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:04:19.530616Z","level":"error","event":"25/09/01 12:04:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:19.686432Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:19.686717Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:21.795730Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:04:52.774006","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:04:53.515483Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:04:54.215702Z","level":"error","event":"25/09/01 12:04:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:54.341418Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:54.341621Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:04:56.958094Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:05:28.134850","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:05:28.740185Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:05:29.406543Z","level":"error","event":"25/09/01 12:05:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:05:29.585712Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:05:29.585948Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:05:31.552614Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:06:02.430029","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:06:03.058643Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:06:03.747835Z","level":"error","event":"25/09/01 12:06:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:03.911084Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:03.911311Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:05.921969Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:06:37.334892","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:06:37.993975Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:06:38.654401Z","level":"error","event":"25/09/01 12:06:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:38.814338Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:38.814549Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:06:40.655094Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:07:11.172233","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:07:11.754701Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:07:12.669869Z","level":"error","event":"25/09/01 12:07:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:12.905606Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:12.905832Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:15.225395Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:07:45.898452","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:07:46.435855Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:07:47.164471Z","level":"error","event":"25/09/01 12:07:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:47.380000Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:47.380265Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:48.157262Z","level":"error","event":"25/09/01 12:07:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:07:49.471519Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:08:20.083202","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:08:20.702587Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:08:21.459046Z","level":"error","event":"25/09/01 12:08:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:21.634860Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:21.638063Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:23.791949Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:08:54.875131","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:08:55.477521Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:08:56.115210Z","level":"error","event":"25/09/01 12:08:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:56.238608Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:56.241913Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:08:58.505037Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:09:29.941358","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:09:30.460988Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:09:31.010982Z","level":"error","event":"25/09/01 12:09:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:09:31.140619Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:09:31.145429Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:09:33.075048Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:10:04.338434","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:10:04.904171Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:10:05.530796Z","level":"error","event":"25/09/01 12:10:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:05.668729Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:05.668892Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:07.560669Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:10:38.818160","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:10:39.364662Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:10:39.962854Z","level":"error","event":"25/09/01 12:10:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:40.080635Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:40.080777Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:40.741416Z","level":"error","event":"25/09/01 12:10:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:10:42.035227Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:11:13.211125","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:11:13.853152Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:11:14.629159Z","level":"error","event":"25/09/01 12:11:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:14.800942Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:14.801134Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:17.089542Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:11:47.864746","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:11:48.535407Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:11:49.384470Z","level":"error","event":"25/09/01 12:11:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:49.630797Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:49.631104Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:50.499848Z","level":"error","event":"25/09/01 12:11:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:11:51.962299Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:12:22.630464","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:12:23.263628Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:12:24.021625Z","level":"error","event":"25/09/01 12:12:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:24.187666Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:24.188028Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:24.902624Z","level":"error","event":"25/09/01 12:12:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:26.397946Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:12:57.504806","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:12:58.041468Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:12:58.677580Z","level":"error","event":"25/09/01 12:12:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:58.793101Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:12:58.793244Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:13:00.664989Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:13:31.809590","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:13:32.368847Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:13:32.978371Z","level":"error","event":"25/09/01 12:13:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:13:33.103317Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:13:33.103533Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:13:35.104809Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:14:06.415998","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:14:06.965769Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:14:07.549215Z","level":"error","event":"25/09/01 12:14:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:07.686963Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:07.687140Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:09.507418Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:14:40.793398","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:14:41.323588Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:14:41.977741Z","level":"error","event":"25/09/01 12:14:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:42.139206Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:42.142563Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:14:43.896620Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:15:15.247608","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:15:15.774423Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:15:16.348055Z","level":"error","event":"25/09/01 12:15:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:16.486961Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:16.487198Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:18.323043Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:15:49.679510","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:15:50.544147Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:15:51.817254Z","level":"error","event":"25/09/01 12:15:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:52.080938Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:52.085897Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:53.072888Z","level":"error","event":"25/09/01 12:15:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:15:55.180793Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:16:26.520651","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:16:27.482428Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:16:28.487281Z","level":"error","event":"25/09/01 12:16:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:16:28.708575Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:16:28.708808Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:16:31.433693Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:17:02.370305","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:17:03.259860Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:17:04.299534Z","level":"error","event":"25/09/01 12:17:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:04.588732Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:04.589021Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:05.823992Z","level":"error","event":"25/09/01 12:17:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:08.072503Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:17:39.213627","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:17:40.177951Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:17:41.278701Z","level":"error","event":"25/09/01 12:17:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:41.515649Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:41.515971Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:17:44.607787Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:18:15.647141","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:18:16.582333Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:18:17.713333Z","level":"error","event":"25/09/01 12:18:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:18.001793Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:18.007603Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:19.253278Z","level":"error","event":"25/09/01 12:18:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:21.615296Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:18:52.467976","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:18:53.264115Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:18:54.447953Z","level":"error","event":"25/09/01 12:18:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:54.750329Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:54.757646Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:55.821763Z","level":"error","event":"25/09/01 12:18:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:18:58.412859Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:19:29.317815","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:19:30.292394Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:19:31.532596Z","level":"error","event":"25/09/01 12:19:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:19:31.895197Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:19:31.895638Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:19:35.647808Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:20:06.673596","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T12:20:08.016826Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-09-01T12:20:09.496804Z","level":"error","event":"25/09/01 12:20:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:20:09.879625Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:20:09.879892Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-09-01T12:20:13.247817Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"processor"}
