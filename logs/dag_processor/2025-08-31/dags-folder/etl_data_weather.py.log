{"timestamp":"2025-08-31T17:35:39.840540","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:35:42.174199Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:35:43.029814Z","level":"error","event":"25/08/31 17:35:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:35:43.316396Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:35:43.316461Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:35:43.316513Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:35:44.929477Z","level":"error","event":"25/08/31 17:35:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:36:20.122735","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:36:20.467209Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:36:21.576381Z","level":"error","event":"25/08/31 17:36:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:36:21.714579Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:36:21.719385Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:36:21.719568Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:36:22.541929Z","level":"error","event":"25/08/31 17:36:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:36:56.716725","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:36:57.051236Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:36:58.569479Z","level":"error","event":"25/08/31 17:36:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:36:58.763956Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:36:58.771573Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:36:58.771796Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:37:34.951859","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:37:35.261532Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:37:36.696178Z","level":"error","event":"25/08/31 17:37:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:37:36.867349Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:37:36.874022Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:37:36.874164Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:37:38.008674Z","level":"error","event":"25/08/31 17:37:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:38:14.770842","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:38:15.204560Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:38:16.621098Z","level":"error","event":"25/08/31 17:38:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:38:16.903537Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:38:16.910293Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:38:16.910504Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:38:54.288631","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:38:54.650668Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:38:56.518439Z","level":"error","event":"25/08/31 17:38:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:38:56.718496Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:38:56.724445Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:38:56.724612Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:39:32.634713","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:39:33.167632Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:39:34.571471Z","level":"error","event":"25/08/31 17:39:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:39:34.731812Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:39:34.737579Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:39:34.737762Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:39:35.616558Z","level":"error","event":"25/08/31 17:39:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:09.579093","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:40:10.150610Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:11.213547Z","level":"error","event":"25/08/31 17:40:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:11.357847Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:11.361511Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:11.361617Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:12.184105Z","level":"error","event":"25/08/31 17:40:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:46.210159","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:40:46.761645Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:48.311021Z","level":"error","event":"25/08/31 17:40:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:48.508032Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:48.512987Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:48.513141Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:40:49.672912Z","level":"error","event":"25/08/31 17:40:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:41:24.877156","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:41:25.346557Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:41:27.269491Z","level":"error","event":"25/08/31 17:41:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:41:27.556410Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:41:27.565522Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:41:27.565912Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:41:28.739103Z","level":"error","event":"25/08/31 17:41:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:03.639113","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:42:04.040434Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:05.424749Z","level":"error","event":"25/08/31 17:42:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:05.620089Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:05.625842Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:05.626075Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:06.660804Z","level":"error","event":"25/08/31 17:42:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:41.046389","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:42:41.370098Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:42.794696Z","level":"error","event":"25/08/31 17:42:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:42.985348Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:42.995397Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:42.995530Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:42:44.074607Z","level":"error","event":"25/08/31 17:42:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:18.369313","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:43:18.698627Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:20.006516Z","level":"error","event":"25/08/31 17:43:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:20.166856Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:20.170481Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:20.170625Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:21.118974Z","level":"error","event":"25/08/31 17:43:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:54.636738","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:43:54.930018Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:56.074380Z","level":"error","event":"25/08/31 17:43:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:56.210890Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:56.214325Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:56.214455Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:43:56.915553Z","level":"error","event":"25/08/31 17:43:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:44:30.505123","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:44:30.817095Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:44:31.907008Z","level":"error","event":"25/08/31 17:44:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:44:32.089678Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:44:32.093143Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:44:32.093257Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:44:32.806524Z","level":"error","event":"25/08/31 17:44:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:45:06.640985","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:45:06.919708Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:45:08.060504Z","level":"error","event":"25/08/31 17:45:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:45:08.262991Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:45:08.267483Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:45:08.267591Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:45:42.658777","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:45:42.933452Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:45:44.091568Z","level":"error","event":"25/08/31 17:45:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:45:44.252232Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:45:44.256885Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:45:44.257032Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:46:18.828533","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:46:19.149393Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:46:20.497478Z","level":"error","event":"25/08/31 17:46:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:46:20.731291Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:46:20.736165Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:46:20.736288Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:46:56.253294","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:46:56.569305Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:46:57.970111Z","level":"error","event":"25/08/31 17:46:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:46:58.133406Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:46:58.137392Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:46:58.137523Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:46:58.833244Z","level":"error","event":"25/08/31 17:46:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:47:32.453499","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:47:32.755722Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:47:34.092281Z","level":"error","event":"25/08/31 17:47:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:47:34.275853Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:47:34.282024Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:47:34.282219Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:48:09.488658","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:48:09.771963Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:48:10.894668Z","level":"error","event":"25/08/31 17:48:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:48:11.036339Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:48:11.040816Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:48:11.040974Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:48:45.233991","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:48:45.510574Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:48:46.538389Z","level":"error","event":"25/08/31 17:48:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:48:46.694820Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:48:46.700006Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:48:46.700117Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:49:20.913199","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:49:21.225835Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:49:22.350199Z","level":"error","event":"25/08/31 17:49:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:49:22.498417Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:49:22.502734Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:49:22.502873Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:49:23.334035Z","level":"error","event":"25/08/31 17:49:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:49:57.045315","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:49:57.337906Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:49:58.579117Z","level":"error","event":"25/08/31 17:49:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:49:58.770747Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:49:58.775509Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:49:58.775693Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:50:33.010727","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:50:33.445003Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:50:34.829588Z","level":"error","event":"25/08/31 17:50:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:50:35.057255Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:50:35.061119Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:50:35.061253Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:51:10.327040","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:51:10.632803Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:51:11.839958Z","level":"error","event":"25/08/31 17:51:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:51:12.020395Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:51:12.024674Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:51:12.024867Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:51:47.410859","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:51:47.695308Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:51:48.965445Z","level":"error","event":"25/08/31 17:51:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:51:49.121851Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:51:49.126152Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:51:49.126318Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:51:50.075647Z","level":"error","event":"25/08/31 17:51:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:52:23.973516","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:52:24.273438Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:52:25.498857Z","level":"error","event":"25/08/31 17:52:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:52:25.641545Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:52:25.645113Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:52:25.645225Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:52:26.472282Z","level":"error","event":"25/08/31 17:52:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:52:59.988312","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:53:00.271353Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:53:01.370456Z","level":"error","event":"25/08/31 17:53:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:53:01.515902Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:53:01.521088Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:53:01.521239Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:53:02.210530Z","level":"error","event":"25/08/31 17:53:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:53:36.045891","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:53:36.358768Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:53:37.771382Z","level":"error","event":"25/08/31 17:53:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:53:37.966687Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:53:37.970772Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:53:37.970913Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:53:38.805756Z","level":"error","event":"25/08/31 17:53:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:54:12.012026","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:54:12.282329Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:54:13.566981Z","level":"error","event":"25/08/31 17:54:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:54:13.740537Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:54:13.745053Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:54:13.745183Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:54:48.664757","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:54:48.993313Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:54:50.057849Z","level":"error","event":"25/08/31 17:54:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:54:50.225035Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:54:50.227981Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:54:50.228091Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:55:24.715862","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:55:25.217711Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:55:26.386929Z","level":"error","event":"25/08/31 17:55:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:55:26.581037Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:55:26.595659Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:55:26.595857Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:00.875659","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:56:01.325865Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.368736Z","level":"error","event":"25/08/31 17:56:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.534561Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.539995Z","level":"error","event":"25/08/31 17:56:02 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.540182Z","level":"error","event":"25/08/31 17:56:02 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.724325Z","level":"error","event":"25/08/31 17:56:02 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.727484Z","level":"error","event":"25/08/31 17:56:02 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.727639Z","level":"error","event":"25/08/31 17:56:02 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.746253Z","level":"error","event":"25/08/31 17:56:02 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.751433Z","level":"error","event":"25/08/31 17:56:02 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.751566Z","level":"error","event":"25/08/31 17:56:02 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.751608Z","level":"error","event":"25/08/31 17:56:02 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.767860Z","level":"error","event":"25/08/31 17:56:02 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.771472Z","level":"error","event":"25/08/31 17:56:02 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.771591Z","level":"error","event":"25/08/31 17:56:02 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.810506Z","level":"error","event":"25/08/31 17:56:02 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.810575Z","level":"error","event":"25/08/31 17:56:02 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.810634Z","level":"error","event":"25/08/31 17:56:02 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.810687Z","level":"error","event":"25/08/31 17:56:02 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:02.810736Z","level":"error","event":"25/08/31 17:56:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.003563Z","level":"error","event":"25/08/31 17:56:03 INFO Utils: Successfully started service 'sparkDriver' on port 44223.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.026717Z","level":"error","event":"25/08/31 17:56:03 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.034597Z","level":"error","event":"25/08/31 17:56:03 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.047959Z","level":"error","event":"25/08/31 17:56:03 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.053148Z","level":"error","event":"25/08/31 17:56:03 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.053345Z","level":"error","event":"25/08/31 17:56:03 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.073801Z","level":"error","event":"25/08/31 17:56:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-849fd540-e7b0-4692-991f-310d8962a716","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.091139Z","level":"error","event":"25/08/31 17:56:03 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.201653Z","level":"error","event":"25/08/31 17:56:03 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.264102Z","level":"error","event":"25/08/31 17:56:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.304932Z","level":"error","event":"25/08/31 17:56:03 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://b444cfaee251:44223/jars/hadoop-aws-3.3.6.jar with timestamp 1756662962720","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.305037Z","level":"error","event":"25/08/31 17:56:03 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://b444cfaee251:44223/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756662962720","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.305073Z","level":"error","event":"25/08/31 17:56:03 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://b444cfaee251:44223/jars/ojdbc11.jar with timestamp 1756662962720","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307493Z","level":"error","event":"25/08/31 17:56:03 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307594Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307630Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307661Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307693Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307724Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307753Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307792Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307823Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307852Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307881Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307909Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307937Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307967Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.307995Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308023Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308052Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308080Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308110Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308140Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308169Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308198Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308227Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308254Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308282Z","level":"error","event":"25/08/31 17:56:03 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308319Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308348Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308375Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308403Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308438Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308469Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308498Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308528Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308559Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308587Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308617Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308646Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308674Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308702Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308729Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308756Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308784Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308811Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308838Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308864Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308891Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308918Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.308944Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.325365Z","level":"error","event":"25/08/31 17:56:03 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.327428Z","level":"error","event":"25/08/31 17:56:03 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.327528Z","level":"error","event":"25/08/31 17:56:03 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.327594Z","level":"error","event":"25/08/31 17:56:03 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.327628Z","level":"error","event":"25/08/31 17:56:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.415711Z","level":"error","event":"25/08/31 17:56:03 INFO Executor: Starting executor ID driver on host b444cfaee251","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.418422Z","level":"error","event":"25/08/31 17:56:03 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.418535Z","level":"error","event":"25/08/31 17:56:03 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.425011Z","level":"error","event":"25/08/31 17:56:03 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.427715Z","level":"error","event":"25/08/31 17:56:03 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5f8d356e for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.434351Z","level":"error","event":"25/08/31 17:56:03 INFO Executor: Fetching spark://b444cfaee251:44223/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756662962720","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.475537Z","level":"error","event":"25/08/31 17:56:03 INFO TransportClientFactory: Successfully created connection to b444cfaee251/172.18.0.11:44223 after 16 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:03.481147Z","level":"error","event":"25/08/31 17:56:03 INFO Utils: Fetching spark://b444cfaee251:44223/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-965388d9-23e9-422d-b06b-26793cdab598/userFiles-8277325e-f1e2-4c40-8ffc-0d4cfe3d1c17/fetchFileTemp3300358592639841025.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.067465Z","level":"error","event":"25/08/31 17:56:04 INFO Executor: Adding file:/tmp/spark-965388d9-23e9-422d-b06b-26793cdab598/userFiles-8277325e-f1e2-4c40-8ffc-0d4cfe3d1c17/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.074584Z","level":"error","event":"25/08/31 17:56:04 INFO Executor: Fetching spark://b444cfaee251:44223/jars/hadoop-aws-3.3.6.jar with timestamp 1756662962720","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.074784Z","level":"error","event":"25/08/31 17:56:04 INFO Utils: Fetching spark://b444cfaee251:44223/jars/hadoop-aws-3.3.6.jar to /tmp/spark-965388d9-23e9-422d-b06b-26793cdab598/userFiles-8277325e-f1e2-4c40-8ffc-0d4cfe3d1c17/fetchFileTemp5588397020915344284.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.079395Z","level":"error","event":"25/08/31 17:56:04 INFO Executor: Adding file:/tmp/spark-965388d9-23e9-422d-b06b-26793cdab598/userFiles-8277325e-f1e2-4c40-8ffc-0d4cfe3d1c17/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.108141Z","level":"error","event":"25/08/31 17:56:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41049.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.113409Z","level":"error","event":"25/08/31 17:56:04 INFO NettyBlockTransferService: Server created on b444cfaee251:41049","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.113555Z","level":"error","event":"25/08/31 17:56:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.142671Z","level":"error","event":"25/08/31 17:56:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b444cfaee251, 41049, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.150581Z","level":"error","event":"25/08/31 17:56:04 INFO BlockManagerMasterEndpoint: Registering block manager b444cfaee251:41049 with 434.4 MiB RAM, BlockManagerId(driver, b444cfaee251, 41049, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.154476Z","level":"error","event":"25/08/31 17:56:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b444cfaee251, 41049, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.157768Z","level":"error","event":"25/08/31 17:56:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b444cfaee251, 41049, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.564742Z","level":"error","event":"25/08/31 17:56:04 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565091Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565197Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565257Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565330Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565386Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565434Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565484Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565537Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565589Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565647Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565700Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565752Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565809Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565861Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565913Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.565992Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566054Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566114Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566171Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566232Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566287Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566358Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566415Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566470Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566529Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566588Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566646Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566703Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566754Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:04.566805Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:05.951264Z","level":"error","event":"25/08/31 17:56:05 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:05.954256Z","level":"error","event":"25/08/31 17:56:05 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:05.959911Z","level":"error","event":"25/08/31 17:56:05 INFO SparkUI: Stopped Spark web UI at http://b444cfaee251:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:05.967215Z","level":"error","event":"25/08/31 17:56:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:05.978709Z","level":"error","event":"25/08/31 17:56:05 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:05.982227Z","level":"error","event":"25/08/31 17:56:05 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:05.982395Z","level":"error","event":"25/08/31 17:56:05 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:05.985105Z","level":"error","event":"25/08/31 17:56:05 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:05.987366Z","level":"error","event":"25/08/31 17:56:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:06.014485Z","level":"error","event":"25/08/31 17:56:06 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:06.017245Z","level":"error","event":"25/08/31 17:56:06 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:06.017352Z","level":"error","event":"25/08/31 17:56:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-1fecd192-6286-4ca8-bcef-1ce1dc3f24b6","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:06.019256Z","level":"error","event":"25/08/31 17:56:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-965388d9-23e9-422d-b06b-26793cdab598/pyspark-d0543608-6b03-4234-ac4a-33c1be8a78d0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:56:06.021072Z","level":"error","event":"25/08/31 17:56:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-965388d9-23e9-422d-b06b-26793cdab598","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:29.006734","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:57:31.620170Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:31.991497Z","level":"error","event":"25/08/31 17:57:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.421684Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.426837Z","level":"error","event":"25/08/31 17:57:32 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.433958Z","level":"error","event":"25/08/31 17:57:32 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.805710Z","level":"error","event":"25/08/31 17:57:32 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.811537Z","level":"error","event":"25/08/31 17:57:32 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.811719Z","level":"error","event":"25/08/31 17:57:32 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.844850Z","level":"error","event":"25/08/31 17:57:32 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.850004Z","level":"error","event":"25/08/31 17:57:32 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.850217Z","level":"error","event":"25/08/31 17:57:32 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.850314Z","level":"error","event":"25/08/31 17:57:32 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.888932Z","level":"error","event":"25/08/31 17:57:32 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.895181Z","level":"error","event":"25/08/31 17:57:32 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.895453Z","level":"error","event":"25/08/31 17:57:32 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.967499Z","level":"error","event":"25/08/31 17:57:32 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.973844Z","level":"error","event":"25/08/31 17:57:32 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.974026Z","level":"error","event":"25/08/31 17:57:32 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.974100Z","level":"error","event":"25/08/31 17:57:32 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:32.978844Z","level":"error","event":"25/08/31 17:57:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:33.403738Z","level":"error","event":"25/08/31 17:57:33 INFO Utils: Successfully started service 'sparkDriver' on port 43343.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:33.449403Z","level":"error","event":"25/08/31 17:57:33 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:33.467781Z","level":"error","event":"25/08/31 17:57:33 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:33.491844Z","level":"error","event":"25/08/31 17:57:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:33.498141Z","level":"error","event":"25/08/31 17:57:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:33.503388Z","level":"error","event":"25/08/31 17:57:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:33.534832Z","level":"error","event":"25/08/31 17:57:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-633524c8-a36d-41f7-8ebb-192033f56351","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:33.572999Z","level":"error","event":"25/08/31 17:57:33 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:33.765809Z","level":"error","event":"25/08/31 17:57:33 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:33.930559Z","level":"error","event":"25/08/31 17:57:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.034052Z","level":"error","event":"25/08/31 17:57:34 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:43343/jars/hadoop-aws-3.3.6.jar with timestamp 1756663052798","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053075Z","level":"error","event":"25/08/31 17:57:34 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:43343/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663052798","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053347Z","level":"error","event":"25/08/31 17:57:34 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:43343/jars/ojdbc11.jar with timestamp 1756663052798","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053425Z","level":"error","event":"25/08/31 17:57:34 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053482Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053530Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053577Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053624Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053670Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053717Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053763Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053808Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053855Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053902Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.053954Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054002Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054049Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054095Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054141Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054188Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054234Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054283Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054390Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054443Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054489Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054536Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054587Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054636Z","level":"error","event":"25/08/31 17:57:34 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054683Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054728Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054775Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054820Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054863Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054908Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.054954Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.055000Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.055046Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.055093Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.055140Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.055188Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.055239Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.061489Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.061728Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.061790Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.061879Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.061934Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.061986Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.062036Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.062083Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.069223Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.069479Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.136058Z","level":"error","event":"25/08/31 17:57:34 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.136115Z","level":"error","event":"25/08/31 17:57:34 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.136162Z","level":"error","event":"25/08/31 17:57:34 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.136206Z","level":"error","event":"25/08/31 17:57:34 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.136253Z","level":"error","event":"25/08/31 17:57:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.377942Z","level":"error","event":"25/08/31 17:57:34 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.383846Z","level":"error","event":"25/08/31 17:57:34 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.384127Z","level":"error","event":"25/08/31 17:57:34 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.403404Z","level":"error","event":"25/08/31 17:57:34 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.416526Z","level":"error","event":"25/08/31 17:57:34 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@53660e10 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.440606Z","level":"error","event":"25/08/31 17:57:34 INFO Executor: Fetching spark://f80e8a4e0fa3:43343/jars/hadoop-aws-3.3.6.jar with timestamp 1756663052798","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.504537Z","level":"error","event":"25/08/31 17:57:34 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:43343 after 29 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.514764Z","level":"error","event":"25/08/31 17:57:34 INFO Utils: Fetching spark://f80e8a4e0fa3:43343/jars/hadoop-aws-3.3.6.jar to /tmp/spark-fe6e91f4-5129-4a2e-b5b0-aa9e9d464ce9/userFiles-0e556ad6-f30d-433f-82f6-3ff1b7b85679/fetchFileTemp3664003310588437996.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.570544Z","level":"error","event":"25/08/31 17:57:34 INFO Executor: Adding file:/tmp/spark-fe6e91f4-5129-4a2e-b5b0-aa9e9d464ce9/userFiles-0e556ad6-f30d-433f-82f6-3ff1b7b85679/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.570780Z","level":"error","event":"25/08/31 17:57:34 INFO Executor: Fetching spark://f80e8a4e0fa3:43343/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663052798","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:34.581125Z","level":"error","event":"25/08/31 17:57:34 INFO Utils: Fetching spark://f80e8a4e0fa3:43343/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-fe6e91f4-5129-4a2e-b5b0-aa9e9d464ce9/userFiles-0e556ad6-f30d-433f-82f6-3ff1b7b85679/fetchFileTemp313137893890345337.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:35.940856Z","level":"error","event":"25/08/31 17:57:35 INFO Executor: Adding file:/tmp/spark-fe6e91f4-5129-4a2e-b5b0-aa9e9d464ce9/userFiles-0e556ad6-f30d-433f-82f6-3ff1b7b85679/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:35.965310Z","level":"error","event":"25/08/31 17:57:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46069.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:35.965428Z","level":"error","event":"25/08/31 17:57:35 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:46069","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:35.965531Z","level":"error","event":"25/08/31 17:57:35 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:35.991263Z","level":"error","event":"25/08/31 17:57:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 46069, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:35.999145Z","level":"error","event":"25/08/31 17:57:35 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:46069 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 46069, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.006514Z","level":"error","event":"25/08/31 17:57:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 46069, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.014442Z","level":"error","event":"25/08/31 17:57:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 46069, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316028Z","level":"error","event":"25/08/31 17:57:36 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316202Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316244Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316279Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316326Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316357Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316398Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316429Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316460Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316490Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316528Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316572Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316615Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316645Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316674Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316703Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316732Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316761Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316790Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316822Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316852Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316883Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316912Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316940Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.316979Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.317009Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.317039Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.317074Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.317103Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.317132Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:36.317161Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:37.955420Z","level":"error","event":"25/08/31 17:57:37 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:37.958240Z","level":"error","event":"25/08/31 17:57:37 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:37.968115Z","level":"error","event":"25/08/31 17:57:37 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:37.976799Z","level":"error","event":"25/08/31 17:57:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:37.988966Z","level":"error","event":"25/08/31 17:57:37 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:37.991700Z","level":"error","event":"25/08/31 17:57:37 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:37.992799Z","level":"error","event":"25/08/31 17:57:37 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:37.995048Z","level":"error","event":"25/08/31 17:57:37 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:37.999938Z","level":"error","event":"25/08/31 17:57:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:38.048492Z","level":"error","event":"25/08/31 17:57:38 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:38.052770Z","level":"error","event":"25/08/31 17:57:38 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:38.052900Z","level":"error","event":"25/08/31 17:57:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-a516bda4-eff8-4a16-a1f0-b6eeeaf6b3c0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:38.057478Z","level":"error","event":"25/08/31 17:57:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-fe6e91f4-5129-4a2e-b5b0-aa9e9d464ce9/pyspark-bd86b58c-c6fd-4e14-9bad-7c318d07c0d5","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:57:38.061316Z","level":"error","event":"25/08/31 17:57:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-fe6e91f4-5129-4a2e-b5b0-aa9e9d464ce9","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:09.027575","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:58:09.522447Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:11.715592Z","level":"error","event":"25/08/31 17:58:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.020119Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.024239Z","level":"error","event":"25/08/31 17:58:12 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.024362Z","level":"error","event":"25/08/31 17:58:12 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.186259Z","level":"error","event":"25/08/31 17:58:12 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.195163Z","level":"error","event":"25/08/31 17:58:12 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.195482Z","level":"error","event":"25/08/31 17:58:12 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.227033Z","level":"error","event":"25/08/31 17:58:12 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.234078Z","level":"error","event":"25/08/31 17:58:12 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.234428Z","level":"error","event":"25/08/31 17:58:12 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.234520Z","level":"error","event":"25/08/31 17:58:12 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.275391Z","level":"error","event":"25/08/31 17:58:12 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.285367Z","level":"error","event":"25/08/31 17:58:12 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.285589Z","level":"error","event":"25/08/31 17:58:12 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.384357Z","level":"error","event":"25/08/31 17:58:12 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.396283Z","level":"error","event":"25/08/31 17:58:12 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.396700Z","level":"error","event":"25/08/31 17:58:12 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.396769Z","level":"error","event":"25/08/31 17:58:12 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.406259Z","level":"error","event":"25/08/31 17:58:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.874558Z","level":"error","event":"25/08/31 17:58:12 INFO Utils: Successfully started service 'sparkDriver' on port 38037.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.911217Z","level":"error","event":"25/08/31 17:58:12 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.936671Z","level":"error","event":"25/08/31 17:58:12 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.954251Z","level":"error","event":"25/08/31 17:58:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.971878Z","level":"error","event":"25/08/31 17:58:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.972028Z","level":"error","event":"25/08/31 17:58:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:12.988333Z","level":"error","event":"25/08/31 17:58:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-91da9971-7b45-4793-9967-47ac319b5ee5","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.020177Z","level":"error","event":"25/08/31 17:58:13 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.186564Z","level":"error","event":"25/08/31 17:58:13 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.353257Z","level":"error","event":"25/08/31 17:58:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.454548Z","level":"error","event":"25/08/31 17:58:13 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:38037/jars/hadoop-aws-3.3.6.jar with timestamp 1756663092180","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.465774Z","level":"error","event":"25/08/31 17:58:13 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:38037/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663092180","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466026Z","level":"error","event":"25/08/31 17:58:13 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:38037/jars/ojdbc11.jar with timestamp 1756663092180","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466098Z","level":"error","event":"25/08/31 17:58:13 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466161Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466217Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466275Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466346Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466402Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466459Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466507Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466558Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466635Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466685Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466738Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466788Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466845Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466905Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.466963Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467033Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467093Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467149Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467217Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467265Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467351Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467409Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467463Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467520Z","level":"error","event":"25/08/31 17:58:13 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467573Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467626Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467677Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467729Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467774Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467827Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467891Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467948Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.467991Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468041Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468100Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468159Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468208Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468257Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468331Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468396Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468456Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468508Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468560Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468608Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.468657Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.479338Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.479740Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.526254Z","level":"error","event":"25/08/31 17:58:13 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.526351Z","level":"error","event":"25/08/31 17:58:13 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.526417Z","level":"error","event":"25/08/31 17:58:13 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.526468Z","level":"error","event":"25/08/31 17:58:13 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.526525Z","level":"error","event":"25/08/31 17:58:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.727950Z","level":"error","event":"25/08/31 17:58:13 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.739461Z","level":"error","event":"25/08/31 17:58:13 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.739744Z","level":"error","event":"25/08/31 17:58:13 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.769411Z","level":"error","event":"25/08/31 17:58:13 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.779745Z","level":"error","event":"25/08/31 17:58:13 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5f8d356e for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.832275Z","level":"error","event":"25/08/31 17:58:13 INFO Executor: Fetching spark://f80e8a4e0fa3:38037/jars/hadoop-aws-3.3.6.jar with timestamp 1756663092180","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.948776Z","level":"error","event":"25/08/31 17:58:13 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:38037 after 58 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:13.960355Z","level":"error","event":"25/08/31 17:58:13 INFO Utils: Fetching spark://f80e8a4e0fa3:38037/jars/hadoop-aws-3.3.6.jar to /tmp/spark-899d0c9c-cccf-456b-825e-8c3e991d02b9/userFiles-fddf41ea-51c0-43c7-97bf-3e4f1443636b/fetchFileTemp14444359376320247260.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:14.063699Z","level":"error","event":"25/08/31 17:58:14 INFO Executor: Adding file:/tmp/spark-899d0c9c-cccf-456b-825e-8c3e991d02b9/userFiles-fddf41ea-51c0-43c7-97bf-3e4f1443636b/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:14.076734Z","level":"error","event":"25/08/31 17:58:14 INFO Executor: Fetching spark://f80e8a4e0fa3:38037/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663092180","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:14.077045Z","level":"error","event":"25/08/31 17:58:14 INFO Utils: Fetching spark://f80e8a4e0fa3:38037/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-899d0c9c-cccf-456b-825e-8c3e991d02b9/userFiles-fddf41ea-51c0-43c7-97bf-3e4f1443636b/fetchFileTemp6871244962782466611.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.505095Z","level":"error","event":"25/08/31 17:58:15 INFO Executor: Adding file:/tmp/spark-899d0c9c-cccf-456b-825e-8c3e991d02b9/userFiles-fddf41ea-51c0-43c7-97bf-3e4f1443636b/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.528496Z","level":"error","event":"25/08/31 17:58:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38127.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.535649Z","level":"error","event":"25/08/31 17:58:15 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:38127","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.535913Z","level":"error","event":"25/08/31 17:58:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.560077Z","level":"error","event":"25/08/31 17:58:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 38127, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.565054Z","level":"error","event":"25/08/31 17:58:15 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:38127 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 38127, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.569198Z","level":"error","event":"25/08/31 17:58:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 38127, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.573454Z","level":"error","event":"25/08/31 17:58:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 38127, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.918161Z","level":"error","event":"25/08/31 17:58:15 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.918570Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.918669Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.918726Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.918780Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.918832Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.918885Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.918923Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.918955Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.918987Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919019Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919049Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919079Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919108Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919137Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919168Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919197Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919247Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919277Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919341Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919375Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919411Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919438Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919466Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919493Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919520Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919547Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919574Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919600Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919626Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:15.919652Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.204022Z","level":"error","event":"25/08/31 17:58:18 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.212088Z","level":"error","event":"25/08/31 17:58:18 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.219388Z","level":"error","event":"25/08/31 17:58:18 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.231259Z","level":"error","event":"25/08/31 17:58:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.246957Z","level":"error","event":"25/08/31 17:58:18 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.252275Z","level":"error","event":"25/08/31 17:58:18 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.252425Z","level":"error","event":"25/08/31 17:58:18 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.257768Z","level":"error","event":"25/08/31 17:58:18 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.265722Z","level":"error","event":"25/08/31 17:58:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.326909Z","level":"error","event":"25/08/31 17:58:18 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.326969Z","level":"error","event":"25/08/31 17:58:18 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.333675Z","level":"error","event":"25/08/31 17:58:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-bce2f42c-6769-4653-bbf8-47931453dbe7","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.333771Z","level":"error","event":"25/08/31 17:58:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-899d0c9c-cccf-456b-825e-8c3e991d02b9/pyspark-24aedc67-e870-4225-a6a6-0643582e4a73","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:18.343489Z","level":"error","event":"25/08/31 17:58:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-899d0c9c-cccf-456b-825e-8c3e991d02b9","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:48.892942","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:58:49.224959Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:50.678580Z","level":"error","event":"25/08/31 17:58:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:50.869631Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:50.882481Z","level":"error","event":"25/08/31 17:58:50 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:50.882713Z","level":"error","event":"25/08/31 17:58:50 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.109995Z","level":"error","event":"25/08/31 17:58:51 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.116837Z","level":"error","event":"25/08/31 17:58:51 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.117040Z","level":"error","event":"25/08/31 17:58:51 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.150942Z","level":"error","event":"25/08/31 17:58:51 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.155656Z","level":"error","event":"25/08/31 17:58:51 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.155863Z","level":"error","event":"25/08/31 17:58:51 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.155905Z","level":"error","event":"25/08/31 17:58:51 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.190181Z","level":"error","event":"25/08/31 17:58:51 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.197530Z","level":"error","event":"25/08/31 17:58:51 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.197798Z","level":"error","event":"25/08/31 17:58:51 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.265565Z","level":"error","event":"25/08/31 17:58:51 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.280283Z","level":"error","event":"25/08/31 17:58:51 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.280553Z","level":"error","event":"25/08/31 17:58:51 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.280619Z","level":"error","event":"25/08/31 17:58:51 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.290079Z","level":"error","event":"25/08/31 17:58:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.621024Z","level":"error","event":"25/08/31 17:58:51 INFO Utils: Successfully started service 'sparkDriver' on port 34203.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.644181Z","level":"error","event":"25/08/31 17:58:51 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.658449Z","level":"error","event":"25/08/31 17:58:51 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.672398Z","level":"error","event":"25/08/31 17:58:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.672612Z","level":"error","event":"25/08/31 17:58:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.676504Z","level":"error","event":"25/08/31 17:58:51 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.692678Z","level":"error","event":"25/08/31 17:58:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a02d76b9-f36c-461c-a75c-5fad7e8a5501","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.712482Z","level":"error","event":"25/08/31 17:58:51 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.829103Z","level":"error","event":"25/08/31 17:58:51 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.898311Z","level":"error","event":"25/08/31 17:58:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946031Z","level":"error","event":"25/08/31 17:58:51 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:34203/jars/hadoop-aws-3.3.6.jar with timestamp 1756663131103","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946266Z","level":"error","event":"25/08/31 17:58:51 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:34203/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663131103","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946377Z","level":"error","event":"25/08/31 17:58:51 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:34203/jars/ojdbc11.jar with timestamp 1756663131103","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946449Z","level":"error","event":"25/08/31 17:58:51 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946518Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946587Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946659Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946731Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946798Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946864Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946931Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.946994Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947057Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947122Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947188Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947252Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947331Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947398Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947465Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947532Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947595Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947666Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947740Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947818Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947916Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.947995Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948069Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948140Z","level":"error","event":"25/08/31 17:58:51 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948214Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948291Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948381Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948459Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948528Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948613Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948687Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948756Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948829Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948900Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.948967Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.949035Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.949106Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.949177Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.949247Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.949342Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.949413Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.949493Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.949567Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.958276Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.958548Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.958652Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.958722Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.972521Z","level":"error","event":"25/08/31 17:58:51 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.980512Z","level":"error","event":"25/08/31 17:58:51 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.980773Z","level":"error","event":"25/08/31 17:58:51 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.980839Z","level":"error","event":"25/08/31 17:58:51 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:51.980878Z","level":"error","event":"25/08/31 17:58:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:52.114052Z","level":"error","event":"25/08/31 17:58:52 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:52.120848Z","level":"error","event":"25/08/31 17:58:52 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:52.121057Z","level":"error","event":"25/08/31 17:58:52 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:52.130592Z","level":"error","event":"25/08/31 17:58:52 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:52.138802Z","level":"error","event":"25/08/31 17:58:52 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@36ddc84e for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:52.152427Z","level":"error","event":"25/08/31 17:58:52 INFO Executor: Fetching spark://f80e8a4e0fa3:34203/jars/hadoop-aws-3.3.6.jar with timestamp 1756663131103","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:52.225934Z","level":"error","event":"25/08/31 17:58:52 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:34203 after 30 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:52.234608Z","level":"error","event":"25/08/31 17:58:52 INFO Utils: Fetching spark://f80e8a4e0fa3:34203/jars/hadoop-aws-3.3.6.jar to /tmp/spark-95d0d07a-c830-4705-88a6-59e15c42f3ff/userFiles-97144056-95c6-4cb6-a2db-475b2ec42779/fetchFileTemp1517576447473321313.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:52.265089Z","level":"error","event":"25/08/31 17:58:52 INFO Executor: Adding file:/tmp/spark-95d0d07a-c830-4705-88a6-59e15c42f3ff/userFiles-97144056-95c6-4cb6-a2db-475b2ec42779/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:52.271795Z","level":"error","event":"25/08/31 17:58:52 INFO Executor: Fetching spark://f80e8a4e0fa3:34203/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663131103","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:52.272044Z","level":"error","event":"25/08/31 17:58:52 INFO Utils: Fetching spark://f80e8a4e0fa3:34203/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-95d0d07a-c830-4705-88a6-59e15c42f3ff/userFiles-97144056-95c6-4cb6-a2db-475b2ec42779/fetchFileTemp11792830373056626580.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.064143Z","level":"error","event":"25/08/31 17:58:53 INFO Executor: Adding file:/tmp/spark-95d0d07a-c830-4705-88a6-59e15c42f3ff/userFiles-97144056-95c6-4cb6-a2db-475b2ec42779/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.074763Z","level":"error","event":"25/08/31 17:58:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46077.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.081133Z","level":"error","event":"25/08/31 17:58:53 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:46077","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.081337Z","level":"error","event":"25/08/31 17:58:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.092234Z","level":"error","event":"25/08/31 17:58:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 46077, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.101483Z","level":"error","event":"25/08/31 17:58:53 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:46077 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 46077, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.109770Z","level":"error","event":"25/08/31 17:58:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 46077, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.110279Z","level":"error","event":"25/08/31 17:58:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 46077, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.493693Z","level":"error","event":"25/08/31 17:58:53 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.493920Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.493964Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.493998Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494028Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494057Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494087Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494120Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494163Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494193Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494223Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494252Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494281Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494321Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494350Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494378Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494406Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494434Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494463Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494495Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494540Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494580Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494610Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494637Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494665Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494692Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494721Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494750Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494781Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494814Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:53.494844Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.249280Z","level":"error","event":"25/08/31 17:58:55 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.249467Z","level":"error","event":"25/08/31 17:58:55 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.259636Z","level":"error","event":"25/08/31 17:58:55 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.273858Z","level":"error","event":"25/08/31 17:58:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.294539Z","level":"error","event":"25/08/31 17:58:55 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.301962Z","level":"error","event":"25/08/31 17:58:55 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.302182Z","level":"error","event":"25/08/31 17:58:55 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.310349Z","level":"error","event":"25/08/31 17:58:55 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.310822Z","level":"error","event":"25/08/31 17:58:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.355288Z","level":"error","event":"25/08/31 17:58:55 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.362190Z","level":"error","event":"25/08/31 17:58:55 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.362383Z","level":"error","event":"25/08/31 17:58:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-b8ca5048-bd04-410e-b778-a720596aa339","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.362463Z","level":"error","event":"25/08/31 17:58:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-95d0d07a-c830-4705-88a6-59e15c42f3ff","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:58:55.367229Z","level":"error","event":"25/08/31 17:58:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-95d0d07a-c830-4705-88a6-59e15c42f3ff/pyspark-0393efed-0601-48b0-9781-a872beddb50e","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:26.204019","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T17:59:26.557757Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.051684Z","level":"error","event":"25/08/31 17:59:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.245547Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.250355Z","level":"error","event":"25/08/31 17:59:28 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.253231Z","level":"error","event":"25/08/31 17:59:28 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.406055Z","level":"error","event":"25/08/31 17:59:28 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.412583Z","level":"error","event":"25/08/31 17:59:28 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.412761Z","level":"error","event":"25/08/31 17:59:28 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.444916Z","level":"error","event":"25/08/31 17:59:28 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.448903Z","level":"error","event":"25/08/31 17:59:28 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.449081Z","level":"error","event":"25/08/31 17:59:28 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.449357Z","level":"error","event":"25/08/31 17:59:28 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.472770Z","level":"error","event":"25/08/31 17:59:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.476715Z","level":"error","event":"25/08/31 17:59:28 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.480749Z","level":"error","event":"25/08/31 17:59:28 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.532413Z","level":"error","event":"25/08/31 17:59:28 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.542006Z","level":"error","event":"25/08/31 17:59:28 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.542282Z","level":"error","event":"25/08/31 17:59:28 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.542409Z","level":"error","event":"25/08/31 17:59:28 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.551684Z","level":"error","event":"25/08/31 17:59:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.865269Z","level":"error","event":"25/08/31 17:59:28 INFO Utils: Successfully started service 'sparkDriver' on port 38303.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.891522Z","level":"error","event":"25/08/31 17:59:28 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.905041Z","level":"error","event":"25/08/31 17:59:28 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.921960Z","level":"error","event":"25/08/31 17:59:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.925968Z","level":"error","event":"25/08/31 17:59:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.929607Z","level":"error","event":"25/08/31 17:59:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.947569Z","level":"error","event":"25/08/31 17:59:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bac68e1a-a508-44b5-84c5-90208ec62cd7","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:28.969065Z","level":"error","event":"25/08/31 17:59:28 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.082967Z","level":"error","event":"25/08/31 17:59:29 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.170377Z","level":"error","event":"25/08/31 17:59:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.188241Z","level":"error","event":"25/08/31 17:59:29 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.274705Z","level":"error","event":"25/08/31 17:59:29 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:38303/jars/hadoop-aws-3.3.6.jar with timestamp 1756663168402","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.274947Z","level":"error","event":"25/08/31 17:59:29 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:38303/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663168402","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.281588Z","level":"error","event":"25/08/31 17:59:29 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:38303/jars/ojdbc11.jar with timestamp 1756663168402","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.281876Z","level":"error","event":"25/08/31 17:59:29 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.281966Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282029Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282089Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282147Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282203Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282267Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282354Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282432Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282538Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282611Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282703Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282768Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282829Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282892Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.282950Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283012Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283069Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283125Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283182Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283240Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283320Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283400Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283462Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283529Z","level":"error","event":"25/08/31 17:59:29 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283592Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283657Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283720Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283782Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283849Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.283915Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284007Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284081Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284147Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284210Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284278Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284376Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284442Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284504Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284560Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284609Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284661Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284722Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284786Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284909Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.284970Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.285209Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.285347Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.305105Z","level":"error","event":"25/08/31 17:59:29 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.312292Z","level":"error","event":"25/08/31 17:59:29 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.312508Z","level":"error","event":"25/08/31 17:59:29 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.312549Z","level":"error","event":"25/08/31 17:59:29 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.312585Z","level":"error","event":"25/08/31 17:59:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.453900Z","level":"error","event":"25/08/31 17:59:29 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.457933Z","level":"error","event":"25/08/31 17:59:29 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.458102Z","level":"error","event":"25/08/31 17:59:29 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.468173Z","level":"error","event":"25/08/31 17:59:29 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.474157Z","level":"error","event":"25/08/31 17:59:29 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7c1c067f for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.480271Z","level":"error","event":"25/08/31 17:59:29 INFO Executor: Fetching spark://f80e8a4e0fa3:38303/jars/hadoop-aws-3.3.6.jar with timestamp 1756663168402","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.528047Z","level":"error","event":"25/08/31 17:59:29 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:38303 after 24 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.535717Z","level":"error","event":"25/08/31 17:59:29 INFO Utils: Fetching spark://f80e8a4e0fa3:38303/jars/hadoop-aws-3.3.6.jar to /tmp/spark-4de05662-9757-41cb-a176-611b93af55a7/userFiles-139c59f3-53f4-456d-bca7-8c28b5f43971/fetchFileTemp17897409421144378257.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.559803Z","level":"error","event":"25/08/31 17:59:29 INFO Executor: Adding file:/tmp/spark-4de05662-9757-41cb-a176-611b93af55a7/userFiles-139c59f3-53f4-456d-bca7-8c28b5f43971/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.565599Z","level":"error","event":"25/08/31 17:59:29 INFO Executor: Fetching spark://f80e8a4e0fa3:38303/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663168402","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:29.565799Z","level":"error","event":"25/08/31 17:59:29 INFO Utils: Fetching spark://f80e8a4e0fa3:38303/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-4de05662-9757-41cb-a176-611b93af55a7/userFiles-139c59f3-53f4-456d-bca7-8c28b5f43971/fetchFileTemp15015944074506107829.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.302015Z","level":"error","event":"25/08/31 17:59:30 INFO Executor: Adding file:/tmp/spark-4de05662-9757-41cb-a176-611b93af55a7/userFiles-139c59f3-53f4-456d-bca7-8c28b5f43971/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.311618Z","level":"error","event":"25/08/31 17:59:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40803.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.314846Z","level":"error","event":"25/08/31 17:59:30 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:40803","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.314968Z","level":"error","event":"25/08/31 17:59:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.329011Z","level":"error","event":"25/08/31 17:59:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 40803, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.335906Z","level":"error","event":"25/08/31 17:59:30 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:40803 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 40803, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.342266Z","level":"error","event":"25/08/31 17:59:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 40803, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.342486Z","level":"error","event":"25/08/31 17:59:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 40803, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679053Z","level":"error","event":"25/08/31 17:59:30 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679313Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679389Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679444Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679495Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679542Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679589Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679638Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679689Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679739Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679788Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679835Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679884Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679933Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.679981Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680028Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680078Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680127Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680192Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680242Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680292Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680363Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680413Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680463Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680516Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680567Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680620Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680672Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680722Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680769Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:30.680817Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.299444Z","level":"error","event":"25/08/31 17:59:32 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.299584Z","level":"error","event":"25/08/31 17:59:32 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.305824Z","level":"error","event":"25/08/31 17:59:32 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.313168Z","level":"error","event":"25/08/31 17:59:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.323989Z","level":"error","event":"25/08/31 17:59:32 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.328466Z","level":"error","event":"25/08/31 17:59:32 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.328641Z","level":"error","event":"25/08/31 17:59:32 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.332229Z","level":"error","event":"25/08/31 17:59:32 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.336674Z","level":"error","event":"25/08/31 17:59:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.371440Z","level":"error","event":"25/08/31 17:59:32 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.375925Z","level":"error","event":"25/08/31 17:59:32 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.376058Z","level":"error","event":"25/08/31 17:59:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-4de05662-9757-41cb-a176-611b93af55a7/pyspark-cb2228b9-1d65-435c-9d36-76cfb3c227b0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.379714Z","level":"error","event":"25/08/31 17:59:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-4de05662-9757-41cb-a176-611b93af55a7","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T17:59:32.383266Z","level":"error","event":"25/08/31 17:59:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-e8ab90ec-aa5b-4cb8-a245-a9e14be54575","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:03.108826","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:00:04.068175Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.353854Z","level":"error","event":"25/08/31 18:00:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.630453Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.639385Z","level":"error","event":"25/08/31 18:00:06 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.646992Z","level":"error","event":"25/08/31 18:00:06 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.878764Z","level":"error","event":"25/08/31 18:00:06 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.888930Z","level":"error","event":"25/08/31 18:00:06 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.889222Z","level":"error","event":"25/08/31 18:00:06 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.926466Z","level":"error","event":"25/08/31 18:00:06 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.939798Z","level":"error","event":"25/08/31 18:00:06 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.940027Z","level":"error","event":"25/08/31 18:00:06 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.940129Z","level":"error","event":"25/08/31 18:00:06 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.971144Z","level":"error","event":"25/08/31 18:00:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.978228Z","level":"error","event":"25/08/31 18:00:06 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:06.978545Z","level":"error","event":"25/08/31 18:00:06 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.062570Z","level":"error","event":"25/08/31 18:00:07 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.072965Z","level":"error","event":"25/08/31 18:00:07 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.073315Z","level":"error","event":"25/08/31 18:00:07 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.073450Z","level":"error","event":"25/08/31 18:00:07 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.073568Z","level":"error","event":"25/08/31 18:00:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.432209Z","level":"error","event":"25/08/31 18:00:07 INFO Utils: Successfully started service 'sparkDriver' on port 39243.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.483177Z","level":"error","event":"25/08/31 18:00:07 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.512953Z","level":"error","event":"25/08/31 18:00:07 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.544846Z","level":"error","event":"25/08/31 18:00:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.560038Z","level":"error","event":"25/08/31 18:00:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.560370Z","level":"error","event":"25/08/31 18:00:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.598003Z","level":"error","event":"25/08/31 18:00:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-904217cf-79b1-43e2-b8c8-b0f31a13b75e","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.656887Z","level":"error","event":"25/08/31 18:00:07 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:07.883607Z","level":"error","event":"25/08/31 18:00:07 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.027765Z","level":"error","event":"25/08/31 18:00:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.102983Z","level":"error","event":"25/08/31 18:00:08 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:39243/jars/hadoop-aws-3.3.6.jar with timestamp 1756663206871","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.111780Z","level":"error","event":"25/08/31 18:00:08 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:39243/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663206871","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112089Z","level":"error","event":"25/08/31 18:00:08 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:39243/jars/ojdbc11.jar with timestamp 1756663206871","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112200Z","level":"error","event":"25/08/31 18:00:08 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112261Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112331Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112388Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112441Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112496Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112548Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112599Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112648Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112703Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112759Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112811Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112871Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112931Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.112983Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.113031Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.113079Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.113129Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.113175Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.113220Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.113264Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.113343Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.113393Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.113444Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.121373Z","level":"error","event":"25/08/31 18:00:08 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.121659Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.121738Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.121793Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.121842Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.121900Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.121959Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122013Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122064Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122111Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122164Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122222Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122282Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122365Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122418Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122473Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122526Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122574Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122622Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122699Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122745Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122789Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122838Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.122880Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.171185Z","level":"error","event":"25/08/31 18:00:08 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.182766Z","level":"error","event":"25/08/31 18:00:08 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.183031Z","level":"error","event":"25/08/31 18:00:08 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.183094Z","level":"error","event":"25/08/31 18:00:08 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.183147Z","level":"error","event":"25/08/31 18:00:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.458155Z","level":"error","event":"25/08/31 18:00:08 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.458219Z","level":"error","event":"25/08/31 18:00:08 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.458268Z","level":"error","event":"25/08/31 18:00:08 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.487665Z","level":"error","event":"25/08/31 18:00:08 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.495686Z","level":"error","event":"25/08/31 18:00:08 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@335c844f for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.515371Z","level":"error","event":"25/08/31 18:00:08 INFO Executor: Fetching spark://f80e8a4e0fa3:39243/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663206871","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.611243Z","level":"error","event":"25/08/31 18:00:08 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:39243 after 45 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:08.621193Z","level":"error","event":"25/08/31 18:00:08 INFO Utils: Fetching spark://f80e8a4e0fa3:39243/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-d2833aa4-d639-418c-9b96-bf2a748e5120/userFiles-d6f64288-c0a1-495e-90a4-71b1b87186d6/fetchFileTemp3204083420051342335.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.031099Z","level":"error","event":"25/08/31 18:00:10 INFO Executor: Adding file:/tmp/spark-d2833aa4-d639-418c-9b96-bf2a748e5120/userFiles-d6f64288-c0a1-495e-90a4-71b1b87186d6/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.039473Z","level":"error","event":"25/08/31 18:00:10 INFO Executor: Fetching spark://f80e8a4e0fa3:39243/jars/hadoop-aws-3.3.6.jar with timestamp 1756663206871","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.039676Z","level":"error","event":"25/08/31 18:00:10 INFO Utils: Fetching spark://f80e8a4e0fa3:39243/jars/hadoop-aws-3.3.6.jar to /tmp/spark-d2833aa4-d639-418c-9b96-bf2a748e5120/userFiles-d6f64288-c0a1-495e-90a4-71b1b87186d6/fetchFileTemp18235601240751365265.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.046211Z","level":"error","event":"25/08/31 18:00:10 INFO Executor: Adding file:/tmp/spark-d2833aa4-d639-418c-9b96-bf2a748e5120/userFiles-d6f64288-c0a1-495e-90a4-71b1b87186d6/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.057992Z","level":"error","event":"25/08/31 18:00:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35201.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.067358Z","level":"error","event":"25/08/31 18:00:10 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:35201","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.068632Z","level":"error","event":"25/08/31 18:00:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.089136Z","level":"error","event":"25/08/31 18:00:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 35201, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.096180Z","level":"error","event":"25/08/31 18:00:10 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:35201 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 35201, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.100833Z","level":"error","event":"25/08/31 18:00:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 35201, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.106515Z","level":"error","event":"25/08/31 18:00:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 35201, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.554758Z","level":"error","event":"25/08/31 18:00:10 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555104Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555184Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555242Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555323Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555390Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555456Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555516Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555610Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555666Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555718Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555773Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555834Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555888Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555942Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.555991Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556042Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556091Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556142Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556192Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556248Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556319Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556380Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556435Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556487Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556536Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556590Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556641Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556691Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556759Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:10.556818Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.771547Z","level":"error","event":"25/08/31 18:00:12 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.778974Z","level":"error","event":"25/08/31 18:00:12 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.793561Z","level":"error","event":"25/08/31 18:00:12 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.812028Z","level":"error","event":"25/08/31 18:00:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.832928Z","level":"error","event":"25/08/31 18:00:12 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.839147Z","level":"error","event":"25/08/31 18:00:12 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.839351Z","level":"error","event":"25/08/31 18:00:12 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.845357Z","level":"error","event":"25/08/31 18:00:12 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.851575Z","level":"error","event":"25/08/31 18:00:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.926117Z","level":"error","event":"25/08/31 18:00:12 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.926441Z","level":"error","event":"25/08/31 18:00:12 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.926561Z","level":"error","event":"25/08/31 18:00:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-d2833aa4-d639-418c-9b96-bf2a748e5120/pyspark-24c53404-cc2a-4dec-85b7-e11a91459015","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.935100Z","level":"error","event":"25/08/31 18:00:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-21ceca72-6889-42c8-a13c-34fe5ca814f5","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:12.943331Z","level":"error","event":"25/08/31 18:00:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-d2833aa4-d639-418c-9b96-bf2a748e5120","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:43.760273","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:00:44.296083Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:45.809826Z","level":"error","event":"25/08/31 18:00:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:45.990320Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:45.994660Z","level":"error","event":"25/08/31 18:00:45 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:45.997644Z","level":"error","event":"25/08/31 18:00:45 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.162077Z","level":"error","event":"25/08/31 18:00:46 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.168240Z","level":"error","event":"25/08/31 18:00:46 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.168438Z","level":"error","event":"25/08/31 18:00:46 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.193343Z","level":"error","event":"25/08/31 18:00:46 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.199384Z","level":"error","event":"25/08/31 18:00:46 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.199578Z","level":"error","event":"25/08/31 18:00:46 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.199652Z","level":"error","event":"25/08/31 18:00:46 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.221200Z","level":"error","event":"25/08/31 18:00:46 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.226209Z","level":"error","event":"25/08/31 18:00:46 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.226379Z","level":"error","event":"25/08/31 18:00:46 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.276049Z","level":"error","event":"25/08/31 18:00:46 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.283240Z","level":"error","event":"25/08/31 18:00:46 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.283450Z","level":"error","event":"25/08/31 18:00:46 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.283491Z","level":"error","event":"25/08/31 18:00:46 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.283529Z","level":"error","event":"25/08/31 18:00:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.543185Z","level":"error","event":"25/08/31 18:00:46 INFO Utils: Successfully started service 'sparkDriver' on port 43149.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.573213Z","level":"error","event":"25/08/31 18:00:46 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.597114Z","level":"error","event":"25/08/31 18:00:46 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.611713Z","level":"error","event":"25/08/31 18:00:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.617766Z","level":"error","event":"25/08/31 18:00:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.617918Z","level":"error","event":"25/08/31 18:00:46 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.640621Z","level":"error","event":"25/08/31 18:00:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-275dc9dd-9a69-45b9-b3d1-5e1606469b89","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.663639Z","level":"error","event":"25/08/31 18:00:46 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.808497Z","level":"error","event":"25/08/31 18:00:46 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.920511Z","level":"error","event":"25/08/31 18:00:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.977507Z","level":"error","event":"25/08/31 18:00:46 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:43149/jars/hadoop-aws-3.3.6.jar with timestamp 1756663246157","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.986412Z","level":"error","event":"25/08/31 18:00:46 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:43149/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663246157","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.986755Z","level":"error","event":"25/08/31 18:00:46 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:43149/jars/ojdbc11.jar with timestamp 1756663246157","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.986903Z","level":"error","event":"25/08/31 18:00:46 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.986974Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987019Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987056Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987095Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987129Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987169Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987208Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987241Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987277Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987330Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987403Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987440Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987475Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987506Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987539Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987578Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987610Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987653Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987687Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987745Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987781Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987822Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987896Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.987972Z","level":"error","event":"25/08/31 18:00:46 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988055Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988134Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988213Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988318Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988387Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988452Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988500Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988554Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988647Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988715Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988790Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988863Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.988962Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.989045Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.989117Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.989214Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.989288Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.989354Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.989408Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.989459Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.989511Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.998709Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:46.998933Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.022559Z","level":"error","event":"25/08/31 18:00:47 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.022797Z","level":"error","event":"25/08/31 18:00:47 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.022867Z","level":"error","event":"25/08/31 18:00:47 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.022920Z","level":"error","event":"25/08/31 18:00:47 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.022972Z","level":"error","event":"25/08/31 18:00:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.212110Z","level":"error","event":"25/08/31 18:00:47 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.220794Z","level":"error","event":"25/08/31 18:00:47 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.221055Z","level":"error","event":"25/08/31 18:00:47 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.241089Z","level":"error","event":"25/08/31 18:00:47 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.249138Z","level":"error","event":"25/08/31 18:00:47 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5f8d356e for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.269111Z","level":"error","event":"25/08/31 18:00:47 INFO Executor: Fetching spark://f80e8a4e0fa3:43149/jars/hadoop-aws-3.3.6.jar with timestamp 1756663246157","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.359017Z","level":"error","event":"25/08/31 18:00:47 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:43149 after 43 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.377119Z","level":"error","event":"25/08/31 18:00:47 INFO Utils: Fetching spark://f80e8a4e0fa3:43149/jars/hadoop-aws-3.3.6.jar to /tmp/spark-f6ad4f1e-4fff-4594-b95b-a8d34497f1d1/userFiles-aa45d6f0-e31b-40f3-9c85-acbe8cb516cf/fetchFileTemp15660474949044687353.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.421369Z","level":"error","event":"25/08/31 18:00:47 INFO Executor: Adding file:/tmp/spark-f6ad4f1e-4fff-4594-b95b-a8d34497f1d1/userFiles-aa45d6f0-e31b-40f3-9c85-acbe8cb516cf/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.421629Z","level":"error","event":"25/08/31 18:00:47 INFO Executor: Fetching spark://f80e8a4e0fa3:43149/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663246157","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:47.421693Z","level":"error","event":"25/08/31 18:00:47 INFO Utils: Fetching spark://f80e8a4e0fa3:43149/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-f6ad4f1e-4fff-4594-b95b-a8d34497f1d1/userFiles-aa45d6f0-e31b-40f3-9c85-acbe8cb516cf/fetchFileTemp8069861117260779288.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.191247Z","level":"error","event":"25/08/31 18:00:48 INFO Executor: Adding file:/tmp/spark-f6ad4f1e-4fff-4594-b95b-a8d34497f1d1/userFiles-aa45d6f0-e31b-40f3-9c85-acbe8cb516cf/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.204147Z","level":"error","event":"25/08/31 18:00:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43937.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.210348Z","level":"error","event":"25/08/31 18:00:48 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:43937","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.210503Z","level":"error","event":"25/08/31 18:00:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.222573Z","level":"error","event":"25/08/31 18:00:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 43937, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.228326Z","level":"error","event":"25/08/31 18:00:48 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:43937 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 43937, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.232797Z","level":"error","event":"25/08/31 18:00:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 43937, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.236036Z","level":"error","event":"25/08/31 18:00:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 43937, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.495939Z","level":"error","event":"25/08/31 18:00:48 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496170Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496253Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496320Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496372Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496419Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496470Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496517Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496565Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496611Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496657Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496703Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496751Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496802Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496865Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496915Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.496971Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497021Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497066Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497140Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497200Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497259Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497394Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497452Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497505Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497558Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497609Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497659Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497708Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497757Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:48.497809Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.261654Z","level":"error","event":"25/08/31 18:00:50 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.266335Z","level":"error","event":"25/08/31 18:00:50 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.272647Z","level":"error","event":"25/08/31 18:00:50 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.283777Z","level":"error","event":"25/08/31 18:00:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.295165Z","level":"error","event":"25/08/31 18:00:50 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.298533Z","level":"error","event":"25/08/31 18:00:50 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.298655Z","level":"error","event":"25/08/31 18:00:50 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.301237Z","level":"error","event":"25/08/31 18:00:50 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.305025Z","level":"error","event":"25/08/31 18:00:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.334067Z","level":"error","event":"25/08/31 18:00:50 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.338332Z","level":"error","event":"25/08/31 18:00:50 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.338445Z","level":"error","event":"25/08/31 18:00:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-6466409e-5c9b-4877-98e0-1573b2d60f7e","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.341379Z","level":"error","event":"25/08/31 18:00:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-f6ad4f1e-4fff-4594-b95b-a8d34497f1d1/pyspark-7a587e47-e318-457c-939a-8212db1af7c5","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:00:50.345067Z","level":"error","event":"25/08/31 18:00:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-f6ad4f1e-4fff-4594-b95b-a8d34497f1d1","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:21.710474","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:01:22.303254Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:23.788917Z","level":"error","event":"25/08/31 18:01:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.001853Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.005294Z","level":"error","event":"25/08/31 18:01:24 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.008085Z","level":"error","event":"25/08/31 18:01:24 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.146402Z","level":"error","event":"25/08/31 18:01:24 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.152323Z","level":"error","event":"25/08/31 18:01:24 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.152470Z","level":"error","event":"25/08/31 18:01:24 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.185260Z","level":"error","event":"25/08/31 18:01:24 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.192257Z","level":"error","event":"25/08/31 18:01:24 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.192437Z","level":"error","event":"25/08/31 18:01:24 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.192480Z","level":"error","event":"25/08/31 18:01:24 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.225985Z","level":"error","event":"25/08/31 18:01:24 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.231712Z","level":"error","event":"25/08/31 18:01:24 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.236070Z","level":"error","event":"25/08/31 18:01:24 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.303670Z","level":"error","event":"25/08/31 18:01:24 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.310745Z","level":"error","event":"25/08/31 18:01:24 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.310975Z","level":"error","event":"25/08/31 18:01:24 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.311070Z","level":"error","event":"25/08/31 18:01:24 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.311128Z","level":"error","event":"25/08/31 18:01:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.581733Z","level":"error","event":"25/08/31 18:01:24 INFO Utils: Successfully started service 'sparkDriver' on port 40441.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.621255Z","level":"error","event":"25/08/31 18:01:24 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.638781Z","level":"error","event":"25/08/31 18:01:24 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.650946Z","level":"error","event":"25/08/31 18:01:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.659877Z","level":"error","event":"25/08/31 18:01:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.659998Z","level":"error","event":"25/08/31 18:01:24 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.672061Z","level":"error","event":"25/08/31 18:01:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-446392d1-da86-4af5-83c3-8e4ad925f1f7","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.694131Z","level":"error","event":"25/08/31 18:01:24 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.831259Z","level":"error","event":"25/08/31 18:01:24 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.927224Z","level":"error","event":"25/08/31 18:01:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:24.940479Z","level":"error","event":"25/08/31 18:01:24 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.009553Z","level":"error","event":"25/08/31 18:01:25 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:40441/jars/hadoop-aws-3.3.6.jar with timestamp 1756663284140","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.015030Z","level":"error","event":"25/08/31 18:01:25 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:40441/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663284140","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.015264Z","level":"error","event":"25/08/31 18:01:25 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:40441/jars/ojdbc11.jar with timestamp 1756663284140","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.015577Z","level":"error","event":"25/08/31 18:01:25 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.015642Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.015703Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.015763Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.015822Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.015872Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.015919Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.015977Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016038Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016083Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016129Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016176Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016224Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016283Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016386Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016440Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016486Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016532Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016583Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016637Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016691Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016756Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016800Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.016851Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.023578Z","level":"error","event":"25/08/31 18:01:25 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.023770Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.023838Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.023892Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.023945Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.023998Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024051Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024103Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024154Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024205Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024257Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024323Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024374Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024423Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024469Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024516Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024569Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024614Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024667Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024750Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024808Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024860Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024916Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.024970Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.041634Z","level":"error","event":"25/08/31 18:01:25 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.047367Z","level":"error","event":"25/08/31 18:01:25 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.047564Z","level":"error","event":"25/08/31 18:01:25 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.047635Z","level":"error","event":"25/08/31 18:01:25 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.047697Z","level":"error","event":"25/08/31 18:01:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.162763Z","level":"error","event":"25/08/31 18:01:25 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.166070Z","level":"error","event":"25/08/31 18:01:25 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.166188Z","level":"error","event":"25/08/31 18:01:25 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.174241Z","level":"error","event":"25/08/31 18:01:25 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.177095Z","level":"error","event":"25/08/31 18:01:25 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@390acac5 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.186531Z","level":"error","event":"25/08/31 18:01:25 INFO Executor: Fetching spark://f80e8a4e0fa3:40441/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663284140","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.236970Z","level":"error","event":"25/08/31 18:01:25 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:40441 after 26 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.242332Z","level":"error","event":"25/08/31 18:01:25 INFO Utils: Fetching spark://f80e8a4e0fa3:40441/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-4274e314-3efd-49cb-8a20-88f2ddf32f7f/userFiles-23c5d153-3bc1-48bf-9d78-11a49a051be1/fetchFileTemp1758433836434050221.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.989382Z","level":"error","event":"25/08/31 18:01:25 INFO Executor: Adding file:/tmp/spark-4274e314-3efd-49cb-8a20-88f2ddf32f7f/userFiles-23c5d153-3bc1-48bf-9d78-11a49a051be1/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.989534Z","level":"error","event":"25/08/31 18:01:25 INFO Executor: Fetching spark://f80e8a4e0fa3:40441/jars/hadoop-aws-3.3.6.jar with timestamp 1756663284140","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:25.994923Z","level":"error","event":"25/08/31 18:01:25 INFO Utils: Fetching spark://f80e8a4e0fa3:40441/jars/hadoop-aws-3.3.6.jar to /tmp/spark-4274e314-3efd-49cb-8a20-88f2ddf32f7f/userFiles-23c5d153-3bc1-48bf-9d78-11a49a051be1/fetchFileTemp2577000724342873512.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.000819Z","level":"error","event":"25/08/31 18:01:25 INFO Executor: Adding file:/tmp/spark-4274e314-3efd-49cb-8a20-88f2ddf32f7f/userFiles-23c5d153-3bc1-48bf-9d78-11a49a051be1/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.009837Z","level":"error","event":"25/08/31 18:01:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36593.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.015910Z","level":"error","event":"25/08/31 18:01:26 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:36593","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.016123Z","level":"error","event":"25/08/31 18:01:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.025262Z","level":"error","event":"25/08/31 18:01:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 36593, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.032458Z","level":"error","event":"25/08/31 18:01:26 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:36593 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 36593, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.035799Z","level":"error","event":"25/08/31 18:01:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 36593, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.040716Z","level":"error","event":"25/08/31 18:01:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 36593, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.418815Z","level":"error","event":"25/08/31 18:01:26 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419100Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419187Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419247Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419309Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419365Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419416Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419467Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419534Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419588Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419639Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419692Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419745Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419795Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419839Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419887Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419941Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.419996Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420050Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420103Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420159Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420215Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420272Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420339Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420388Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420439Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420502Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420569Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420630Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420722Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:26.420783Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.416230Z","level":"error","event":"25/08/31 18:01:28 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.416415Z","level":"error","event":"25/08/31 18:01:28 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.428589Z","level":"error","event":"25/08/31 18:01:28 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.436753Z","level":"error","event":"25/08/31 18:01:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.450373Z","level":"error","event":"25/08/31 18:01:28 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.454651Z","level":"error","event":"25/08/31 18:01:28 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.454760Z","level":"error","event":"25/08/31 18:01:28 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.458143Z","level":"error","event":"25/08/31 18:01:28 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.462636Z","level":"error","event":"25/08/31 18:01:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.508003Z","level":"error","event":"25/08/31 18:01:28 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.512316Z","level":"error","event":"25/08/31 18:01:28 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.512477Z","level":"error","event":"25/08/31 18:01:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-4274e314-3efd-49cb-8a20-88f2ddf32f7f","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.516314Z","level":"error","event":"25/08/31 18:01:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-aae624ec-d611-47d6-a275-4cbe803e6be6","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:28.519675Z","level":"error","event":"25/08/31 18:01:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-4274e314-3efd-49cb-8a20-88f2ddf32f7f/pyspark-e78d0709-6642-49a0-bee4-bb70798972ff","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:01:59.462684","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:01:59.981660Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.255855Z","level":"error","event":"25/08/31 18:02:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.414361Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.418794Z","level":"error","event":"25/08/31 18:02:01 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.422377Z","level":"error","event":"25/08/31 18:02:01 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.539139Z","level":"error","event":"25/08/31 18:02:01 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.544204Z","level":"error","event":"25/08/31 18:02:01 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.544430Z","level":"error","event":"25/08/31 18:02:01 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.578375Z","level":"error","event":"25/08/31 18:02:01 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.583393Z","level":"error","event":"25/08/31 18:02:01 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.583525Z","level":"error","event":"25/08/31 18:02:01 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.583564Z","level":"error","event":"25/08/31 18:02:01 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.610061Z","level":"error","event":"25/08/31 18:02:01 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.616661Z","level":"error","event":"25/08/31 18:02:01 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.616860Z","level":"error","event":"25/08/31 18:02:01 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.681360Z","level":"error","event":"25/08/31 18:02:01 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.689266Z","level":"error","event":"25/08/31 18:02:01 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.689544Z","level":"error","event":"25/08/31 18:02:01 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.689628Z","level":"error","event":"25/08/31 18:02:01 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.689695Z","level":"error","event":"25/08/31 18:02:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:01.991752Z","level":"error","event":"25/08/31 18:02:01 INFO Utils: Successfully started service 'sparkDriver' on port 46503.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.027343Z","level":"error","event":"25/08/31 18:02:02 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.041840Z","level":"error","event":"25/08/31 18:02:02 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.056220Z","level":"error","event":"25/08/31 18:02:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.061352Z","level":"error","event":"25/08/31 18:02:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.061525Z","level":"error","event":"25/08/31 18:02:02 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.078172Z","level":"error","event":"25/08/31 18:02:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f8df3b79-5cee-49c5-9c51-be2f34b0969a","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.098229Z","level":"error","event":"25/08/31 18:02:02 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.224105Z","level":"error","event":"25/08/31 18:02:02 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.327802Z","level":"error","event":"25/08/31 18:02:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.338181Z","level":"error","event":"25/08/31 18:02:02 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.414959Z","level":"error","event":"25/08/31 18:02:02 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:46503/jars/hadoop-aws-3.3.6.jar with timestamp 1756663321535","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423277Z","level":"error","event":"25/08/31 18:02:02 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:46503/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663321535","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423488Z","level":"error","event":"25/08/31 18:02:02 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:46503/jars/ojdbc11.jar with timestamp 1756663321535","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423535Z","level":"error","event":"25/08/31 18:02:02 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423573Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423607Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423640Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423672Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423703Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423734Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423764Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423794Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423824Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423874Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423904Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423937Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.423970Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.424001Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.424030Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.424060Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.424089Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.424117Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.424147Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.424176Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.424205Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.424233Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.424260Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.431973Z","level":"error","event":"25/08/31 18:02:02 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432187Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432237Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432273Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432321Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432355Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432387Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432420Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432468Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432500Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432531Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432564Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432597Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432629Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432660Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432690Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432725Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432757Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432803Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432840Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432870Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432901Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432931Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.432959Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.459459Z","level":"error","event":"25/08/31 18:02:02 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.459815Z","level":"error","event":"25/08/31 18:02:02 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.459933Z","level":"error","event":"25/08/31 18:02:02 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.459993Z","level":"error","event":"25/08/31 18:02:02 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.466624Z","level":"error","event":"25/08/31 18:02:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.618110Z","level":"error","event":"25/08/31 18:02:02 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.618257Z","level":"error","event":"25/08/31 18:02:02 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.618308Z","level":"error","event":"25/08/31 18:02:02 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.631958Z","level":"error","event":"25/08/31 18:02:02 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.638114Z","level":"error","event":"25/08/31 18:02:02 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7c1c067f for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.650347Z","level":"error","event":"25/08/31 18:02:02 INFO Executor: Fetching spark://f80e8a4e0fa3:46503/jars/hadoop-aws-3.3.6.jar with timestamp 1756663321535","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.715791Z","level":"error","event":"25/08/31 18:02:02 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:46503 after 27 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.725775Z","level":"error","event":"25/08/31 18:02:02 INFO Utils: Fetching spark://f80e8a4e0fa3:46503/jars/hadoop-aws-3.3.6.jar to /tmp/spark-b4b0693d-94b7-4f79-8b98-4ec1bee0f509/userFiles-1aace475-aa62-49b6-8336-18a737db70a3/fetchFileTemp7233138185738610175.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.770332Z","level":"error","event":"25/08/31 18:02:02 INFO Executor: Adding file:/tmp/spark-b4b0693d-94b7-4f79-8b98-4ec1bee0f509/userFiles-1aace475-aa62-49b6-8336-18a737db70a3/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.777809Z","level":"error","event":"25/08/31 18:02:02 INFO Executor: Fetching spark://f80e8a4e0fa3:46503/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663321535","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:02.777997Z","level":"error","event":"25/08/31 18:02:02 INFO Utils: Fetching spark://f80e8a4e0fa3:46503/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-b4b0693d-94b7-4f79-8b98-4ec1bee0f509/userFiles-1aace475-aa62-49b6-8336-18a737db70a3/fetchFileTemp2826281458467225470.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:03.772236Z","level":"error","event":"25/08/31 18:02:03 INFO Executor: Adding file:/tmp/spark-b4b0693d-94b7-4f79-8b98-4ec1bee0f509/userFiles-1aace475-aa62-49b6-8336-18a737db70a3/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:03.784699Z","level":"error","event":"25/08/31 18:02:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46091.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:03.792280Z","level":"error","event":"25/08/31 18:02:03 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:46091","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:03.792510Z","level":"error","event":"25/08/31 18:02:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:03.803516Z","level":"error","event":"25/08/31 18:02:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 46091, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:03.809746Z","level":"error","event":"25/08/31 18:02:03 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:46091 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 46091, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:03.814324Z","level":"error","event":"25/08/31 18:02:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 46091, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:03.818718Z","level":"error","event":"25/08/31 18:02:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 46091, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.105649Z","level":"error","event":"25/08/31 18:02:04 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.105867Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.105953Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106019Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106081Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106143Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106203Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106262Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106345Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106408Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106470Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106531Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106592Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106651Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106712Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106775Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106832Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106891Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.106956Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107035Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107097Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107158Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107215Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107270Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107343Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107403Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107461Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107522Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107579Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107633Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:04.107690Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:05.983966Z","level":"error","event":"25/08/31 18:02:05 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:05.988085Z","level":"error","event":"25/08/31 18:02:05 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:05.997386Z","level":"error","event":"25/08/31 18:02:05 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:06.008944Z","level":"error","event":"25/08/31 18:02:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:06.022393Z","level":"error","event":"25/08/31 18:02:06 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:06.026450Z","level":"error","event":"25/08/31 18:02:06 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:06.026698Z","level":"error","event":"25/08/31 18:02:06 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:06.031115Z","level":"error","event":"25/08/31 18:02:06 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:06.031355Z","level":"error","event":"25/08/31 18:02:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:06.066979Z","level":"error","event":"25/08/31 18:02:06 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:06.071040Z","level":"error","event":"25/08/31 18:02:06 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:06.071184Z","level":"error","event":"25/08/31 18:02:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-b4b0693d-94b7-4f79-8b98-4ec1bee0f509/pyspark-33c40308-9aa1-4c8d-95e4-f04622ac2535","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:06.071251Z","level":"error","event":"25/08/31 18:02:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-cd16c5aa-0587-49fc-a05a-37f415761c27","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:06.074216Z","level":"error","event":"25/08/31 18:02:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-b4b0693d-94b7-4f79-8b98-4ec1bee0f509","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:36.874701","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:02:37.235160Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:38.829608Z","level":"error","event":"25/08/31 18:02:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.004730Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.008524Z","level":"error","event":"25/08/31 18:02:39 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.012260Z","level":"error","event":"25/08/31 18:02:39 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.203885Z","level":"error","event":"25/08/31 18:02:39 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.208779Z","level":"error","event":"25/08/31 18:02:39 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.208916Z","level":"error","event":"25/08/31 18:02:39 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.241637Z","level":"error","event":"25/08/31 18:02:39 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.247975Z","level":"error","event":"25/08/31 18:02:39 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.248140Z","level":"error","event":"25/08/31 18:02:39 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.248212Z","level":"error","event":"25/08/31 18:02:39 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.278776Z","level":"error","event":"25/08/31 18:02:39 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.284991Z","level":"error","event":"25/08/31 18:02:39 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.285261Z","level":"error","event":"25/08/31 18:02:39 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.345538Z","level":"error","event":"25/08/31 18:02:39 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.350833Z","level":"error","event":"25/08/31 18:02:39 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.350959Z","level":"error","event":"25/08/31 18:02:39 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.351000Z","level":"error","event":"25/08/31 18:02:39 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.356715Z","level":"error","event":"25/08/31 18:02:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.651896Z","level":"error","event":"25/08/31 18:02:39 INFO Utils: Successfully started service 'sparkDriver' on port 33005.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.678837Z","level":"error","event":"25/08/31 18:02:39 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.694467Z","level":"error","event":"25/08/31 18:02:39 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.715004Z","level":"error","event":"25/08/31 18:02:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.723726Z","level":"error","event":"25/08/31 18:02:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.723962Z","level":"error","event":"25/08/31 18:02:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.742044Z","level":"error","event":"25/08/31 18:02:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5f95cf76-746f-468c-bf0b-a73414ccf74b","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.769816Z","level":"error","event":"25/08/31 18:02:39 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:39.960024Z","level":"error","event":"25/08/31 18:02:39 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.045489Z","level":"error","event":"25/08/31 18:02:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.063153Z","level":"error","event":"25/08/31 18:02:40 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.113800Z","level":"error","event":"25/08/31 18:02:40 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:33005/jars/hadoop-aws-3.3.6.jar with timestamp 1756663359198","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.120444Z","level":"error","event":"25/08/31 18:02:40 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:33005/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663359198","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.120666Z","level":"error","event":"25/08/31 18:02:40 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:33005/jars/ojdbc11.jar with timestamp 1756663359198","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.120783Z","level":"error","event":"25/08/31 18:02:40 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.120852Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.120914Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.120973Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121032Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121095Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121162Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121220Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121280Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121356Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121414Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121475Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121532Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121592Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121647Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121699Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121750Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121801Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121849Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121902Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.121961Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122041Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122097Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122151Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122208Z","level":"error","event":"25/08/31 18:02:40 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122265Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122339Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122392Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122447Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122503Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122554Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122604Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122653Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122701Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122755Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122817Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122877Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.122941Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.123004Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.123077Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.123144Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.123210Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.123275Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.123381Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.123441Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.123496Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.130171Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.130366Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.144513Z","level":"error","event":"25/08/31 18:02:40 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.144607Z","level":"error","event":"25/08/31 18:02:40 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.144671Z","level":"error","event":"25/08/31 18:02:40 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.144724Z","level":"error","event":"25/08/31 18:02:40 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.144776Z","level":"error","event":"25/08/31 18:02:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.292654Z","level":"error","event":"25/08/31 18:02:40 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.299606Z","level":"error","event":"25/08/31 18:02:40 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.299776Z","level":"error","event":"25/08/31 18:02:40 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.311114Z","level":"error","event":"25/08/31 18:02:40 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.318583Z","level":"error","event":"25/08/31 18:02:40 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@390acac5 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.326455Z","level":"error","event":"25/08/31 18:02:40 INFO Executor: Fetching spark://f80e8a4e0fa3:33005/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663359198","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.381219Z","level":"error","event":"25/08/31 18:02:40 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:33005 after 25 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:40.389790Z","level":"error","event":"25/08/31 18:02:40 INFO Utils: Fetching spark://f80e8a4e0fa3:33005/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-1640ca36-5aa0-470e-bed4-926b7b0426cd/userFiles-81d25c86-b30e-45b2-a393-4b5c2ee0195f/fetchFileTemp11431840857490047590.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.200379Z","level":"error","event":"25/08/31 18:02:41 INFO Executor: Adding file:/tmp/spark-1640ca36-5aa0-470e-bed4-926b7b0426cd/userFiles-81d25c86-b30e-45b2-a393-4b5c2ee0195f/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.208047Z","level":"error","event":"25/08/31 18:02:41 INFO Executor: Fetching spark://f80e8a4e0fa3:33005/jars/hadoop-aws-3.3.6.jar with timestamp 1756663359198","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.208218Z","level":"error","event":"25/08/31 18:02:41 INFO Utils: Fetching spark://f80e8a4e0fa3:33005/jars/hadoop-aws-3.3.6.jar to /tmp/spark-1640ca36-5aa0-470e-bed4-926b7b0426cd/userFiles-81d25c86-b30e-45b2-a393-4b5c2ee0195f/fetchFileTemp10120109287512872005.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.214350Z","level":"error","event":"25/08/31 18:02:41 INFO Executor: Adding file:/tmp/spark-1640ca36-5aa0-470e-bed4-926b7b0426cd/userFiles-81d25c86-b30e-45b2-a393-4b5c2ee0195f/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.226378Z","level":"error","event":"25/08/31 18:02:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45751.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.234317Z","level":"error","event":"25/08/31 18:02:41 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:45751","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.234556Z","level":"error","event":"25/08/31 18:02:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.247832Z","level":"error","event":"25/08/31 18:02:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 45751, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.257014Z","level":"error","event":"25/08/31 18:02:41 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:45751 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 45751, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.261424Z","level":"error","event":"25/08/31 18:02:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 45751, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.264890Z","level":"error","event":"25/08/31 18:02:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 45751, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.573688Z","level":"error","event":"25/08/31 18:02:41 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.573910Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.573985Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574043Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574095Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574146Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574196Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574245Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574325Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574378Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574423Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574468Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574520Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574575Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574625Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574673Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574721Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574770Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574820Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574871Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574919Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.574961Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.575007Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.575055Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.575101Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.575146Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.575196Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.575245Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.575294Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.575396Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:41.575450Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.147175Z","level":"error","event":"25/08/31 18:02:43 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.152685Z","level":"error","event":"25/08/31 18:02:43 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.162933Z","level":"error","event":"25/08/31 18:02:43 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.170516Z","level":"error","event":"25/08/31 18:02:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.183225Z","level":"error","event":"25/08/31 18:02:43 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.186278Z","level":"error","event":"25/08/31 18:02:43 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.186402Z","level":"error","event":"25/08/31 18:02:43 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.188770Z","level":"error","event":"25/08/31 18:02:43 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.191945Z","level":"error","event":"25/08/31 18:02:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.242239Z","level":"error","event":"25/08/31 18:02:43 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.245500Z","level":"error","event":"25/08/31 18:02:43 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.245608Z","level":"error","event":"25/08/31 18:02:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-1640ca36-5aa0-470e-bed4-926b7b0426cd/pyspark-d2d2a86a-39d9-4e85-8448-826eb7d53274","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.248789Z","level":"error","event":"25/08/31 18:02:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-1640ca36-5aa0-470e-bed4-926b7b0426cd","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:02:43.251262Z","level":"error","event":"25/08/31 18:02:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-907c3acb-43cf-4a52-9ec9-821b04606efd","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:14.415349","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:03:14.697001Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:15.764003Z","level":"error","event":"25/08/31 18:03:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:15.916548Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:15.919359Z","level":"error","event":"25/08/31 18:03:15 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:15.922438Z","level":"error","event":"25/08/31 18:03:15 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.076443Z","level":"error","event":"25/08/31 18:03:16 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.080098Z","level":"error","event":"25/08/31 18:03:16 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.080207Z","level":"error","event":"25/08/31 18:03:16 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.096915Z","level":"error","event":"25/08/31 18:03:16 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.102241Z","level":"error","event":"25/08/31 18:03:16 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.102442Z","level":"error","event":"25/08/31 18:03:16 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.102516Z","level":"error","event":"25/08/31 18:03:16 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.125663Z","level":"error","event":"25/08/31 18:03:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.131329Z","level":"error","event":"25/08/31 18:03:16 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.131534Z","level":"error","event":"25/08/31 18:03:16 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.173807Z","level":"error","event":"25/08/31 18:03:16 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.173883Z","level":"error","event":"25/08/31 18:03:16 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.173933Z","level":"error","event":"25/08/31 18:03:16 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.173979Z","level":"error","event":"25/08/31 18:03:16 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.178092Z","level":"error","event":"25/08/31 18:03:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.336817Z","level":"error","event":"25/08/31 18:03:16 INFO Utils: Successfully started service 'sparkDriver' on port 34145.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.361797Z","level":"error","event":"25/08/31 18:03:16 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.383564Z","level":"error","event":"25/08/31 18:03:16 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.403113Z","level":"error","event":"25/08/31 18:03:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.408928Z","level":"error","event":"25/08/31 18:03:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.409099Z","level":"error","event":"25/08/31 18:03:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.429970Z","level":"error","event":"25/08/31 18:03:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-be1b3b6b-4bc3-45ea-b913-5ed43d205890","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.452085Z","level":"error","event":"25/08/31 18:03:16 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.557735Z","level":"error","event":"25/08/31 18:03:16 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.615669Z","level":"error","event":"25/08/31 18:03:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.645138Z","level":"error","event":"25/08/31 18:03:16 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:34145/jars/hadoop-aws-3.3.6.jar with timestamp 1756663396073","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649016Z","level":"error","event":"25/08/31 18:03:16 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:34145/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663396073","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649154Z","level":"error","event":"25/08/31 18:03:16 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:34145/jars/ojdbc11.jar with timestamp 1756663396073","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649194Z","level":"error","event":"25/08/31 18:03:16 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649226Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649259Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649293Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649340Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649371Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649401Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649430Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649460Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649490Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649519Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649561Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649592Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649621Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649649Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649678Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649706Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649734Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649762Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649791Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649820Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649850Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649880Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649908Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649938Z","level":"error","event":"25/08/31 18:03:16 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649967Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.649996Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650025Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650055Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650086Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650115Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650143Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650170Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650202Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650232Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650260Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650293Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650330Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650361Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650390Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650421Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650449Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650478Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650507Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650535Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.650563Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.654548Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.654669Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.665292Z","level":"error","event":"25/08/31 18:03:16 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.670180Z","level":"error","event":"25/08/31 18:03:16 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.670316Z","level":"error","event":"25/08/31 18:03:16 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.670358Z","level":"error","event":"25/08/31 18:03:16 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.670394Z","level":"error","event":"25/08/31 18:03:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.764269Z","level":"error","event":"25/08/31 18:03:16 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.767658Z","level":"error","event":"25/08/31 18:03:16 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.767789Z","level":"error","event":"25/08/31 18:03:16 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.777630Z","level":"error","event":"25/08/31 18:03:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.780876Z","level":"error","event":"25/08/31 18:03:16 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5f8d356e for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.789623Z","level":"error","event":"25/08/31 18:03:16 INFO Executor: Fetching spark://f80e8a4e0fa3:34145/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663396073","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.832327Z","level":"error","event":"25/08/31 18:03:16 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:34145 after 21 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:16.836484Z","level":"error","event":"25/08/31 18:03:16 INFO Utils: Fetching spark://f80e8a4e0fa3:34145/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-c1d22ee6-7caf-4ca5-ac53-9f04aaa8afb2/userFiles-b700ea8e-ef81-4194-9670-2a149fa5208f/fetchFileTemp2171020250377292193.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.572779Z","level":"error","event":"25/08/31 18:03:17 INFO Executor: Adding file:/tmp/spark-c1d22ee6-7caf-4ca5-ac53-9f04aaa8afb2/userFiles-b700ea8e-ef81-4194-9670-2a149fa5208f/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.579996Z","level":"error","event":"25/08/31 18:03:17 INFO Executor: Fetching spark://f80e8a4e0fa3:34145/jars/hadoop-aws-3.3.6.jar with timestamp 1756663396073","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.580086Z","level":"error","event":"25/08/31 18:03:17 INFO Utils: Fetching spark://f80e8a4e0fa3:34145/jars/hadoop-aws-3.3.6.jar to /tmp/spark-c1d22ee6-7caf-4ca5-ac53-9f04aaa8afb2/userFiles-b700ea8e-ef81-4194-9670-2a149fa5208f/fetchFileTemp10576892801485347424.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.584813Z","level":"error","event":"25/08/31 18:03:17 INFO Executor: Adding file:/tmp/spark-c1d22ee6-7caf-4ca5-ac53-9f04aaa8afb2/userFiles-b700ea8e-ef81-4194-9670-2a149fa5208f/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.591846Z","level":"error","event":"25/08/31 18:03:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37743.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.594428Z","level":"error","event":"25/08/31 18:03:17 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:37743","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.597022Z","level":"error","event":"25/08/31 18:03:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.615630Z","level":"error","event":"25/08/31 18:03:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 37743, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.615668Z","level":"error","event":"25/08/31 18:03:17 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:37743 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 37743, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.618743Z","level":"error","event":"25/08/31 18:03:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 37743, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.618786Z","level":"error","event":"25/08/31 18:03:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 37743, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.883452Z","level":"error","event":"25/08/31 18:03:17 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.883709Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.883787Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.883845Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.883893Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.883943Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.883989Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884033Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884077Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884120Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884166Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884213Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884258Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884314Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884382Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884429Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884475Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884520Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884567Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884626Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884674Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884718Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884761Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884803Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884852Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884902Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.884956Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.885009Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.885051Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.885082Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:17.885111Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.185815Z","level":"error","event":"25/08/31 18:03:19 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.188901Z","level":"error","event":"25/08/31 18:03:19 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.195254Z","level":"error","event":"25/08/31 18:03:19 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.202736Z","level":"error","event":"25/08/31 18:03:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.216631Z","level":"error","event":"25/08/31 18:03:19 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.219987Z","level":"error","event":"25/08/31 18:03:19 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.220095Z","level":"error","event":"25/08/31 18:03:19 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.222468Z","level":"error","event":"25/08/31 18:03:19 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.225983Z","level":"error","event":"25/08/31 18:03:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.254562Z","level":"error","event":"25/08/31 18:03:19 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.257715Z","level":"error","event":"25/08/31 18:03:19 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.257843Z","level":"error","event":"25/08/31 18:03:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-f1797336-b62e-402f-9726-82eb824832dd","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.260361Z","level":"error","event":"25/08/31 18:03:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-c1d22ee6-7caf-4ca5-ac53-9f04aaa8afb2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:19.263367Z","level":"error","event":"25/08/31 18:03:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-c1d22ee6-7caf-4ca5-ac53-9f04aaa8afb2/pyspark-8be478bf-2cd0-448c-bbae-3dcb8c296f91","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:50.268615","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:03:50.681364Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:51.856375Z","level":"error","event":"25/08/31 18:03:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.015809Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.021962Z","level":"error","event":"25/08/31 18:03:52 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.022063Z","level":"error","event":"25/08/31 18:03:52 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.158154Z","level":"error","event":"25/08/31 18:03:52 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.161865Z","level":"error","event":"25/08/31 18:03:52 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.161991Z","level":"error","event":"25/08/31 18:03:52 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.186013Z","level":"error","event":"25/08/31 18:03:52 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.194097Z","level":"error","event":"25/08/31 18:03:52 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.194245Z","level":"error","event":"25/08/31 18:03:52 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.194294Z","level":"error","event":"25/08/31 18:03:52 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.216137Z","level":"error","event":"25/08/31 18:03:52 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.216368Z","level":"error","event":"25/08/31 18:03:52 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.216467Z","level":"error","event":"25/08/31 18:03:52 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.272447Z","level":"error","event":"25/08/31 18:03:52 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.279200Z","level":"error","event":"25/08/31 18:03:52 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.279434Z","level":"error","event":"25/08/31 18:03:52 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.279496Z","level":"error","event":"25/08/31 18:03:52 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.279544Z","level":"error","event":"25/08/31 18:03:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.497863Z","level":"error","event":"25/08/31 18:03:52 INFO Utils: Successfully started service 'sparkDriver' on port 46745.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.519402Z","level":"error","event":"25/08/31 18:03:52 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.530144Z","level":"error","event":"25/08/31 18:03:52 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.538805Z","level":"error","event":"25/08/31 18:03:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.543445Z","level":"error","event":"25/08/31 18:03:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.543501Z","level":"error","event":"25/08/31 18:03:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.560805Z","level":"error","event":"25/08/31 18:03:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7e59e81e-ef81-4a2d-9ec4-2cc2cfda3a6f","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.579194Z","level":"error","event":"25/08/31 18:03:52 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.687631Z","level":"error","event":"25/08/31 18:03:52 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.745802Z","level":"error","event":"25/08/31 18:03:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.752728Z","level":"error","event":"25/08/31 18:03:52 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.784513Z","level":"error","event":"25/08/31 18:03:52 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:46745/jars/hadoop-aws-3.3.6.jar with timestamp 1756663432154","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.790492Z","level":"error","event":"25/08/31 18:03:52 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:46745/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663432154","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.790690Z","level":"error","event":"25/08/31 18:03:52 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:46745/jars/ojdbc11.jar with timestamp 1756663432154","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.790777Z","level":"error","event":"25/08/31 18:03:52 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.790842Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.790903Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.790962Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791021Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791082Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791142Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791199Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791254Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791323Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791379Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791430Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791501Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791577Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791633Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791687Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791744Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791801Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791864Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791919Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.791971Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792038Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792093Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792145Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792199Z","level":"error","event":"25/08/31 18:03:52 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792255Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792325Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792392Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792448Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792499Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792547Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792596Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792651Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792706Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792757Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792806Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792858Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792912Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.792969Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.793022Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.793078Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.793131Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.793185Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.793254Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.793319Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.793389Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.800066Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.800253Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.809550Z","level":"error","event":"25/08/31 18:03:52 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.809735Z","level":"error","event":"25/08/31 18:03:52 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.809775Z","level":"error","event":"25/08/31 18:03:52 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.809809Z","level":"error","event":"25/08/31 18:03:52 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.809843Z","level":"error","event":"25/08/31 18:03:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.905206Z","level":"error","event":"25/08/31 18:03:52 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.908454Z","level":"error","event":"25/08/31 18:03:52 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.908558Z","level":"error","event":"25/08/31 18:03:52 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.914688Z","level":"error","event":"25/08/31 18:03:52 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.918981Z","level":"error","event":"25/08/31 18:03:52 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@390acac5 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.924320Z","level":"error","event":"25/08/31 18:03:52 INFO Executor: Fetching spark://f80e8a4e0fa3:46745/jars/hadoop-aws-3.3.6.jar with timestamp 1756663432154","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.968427Z","level":"error","event":"25/08/31 18:03:52 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:46745 after 19 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.975520Z","level":"error","event":"25/08/31 18:03:52 INFO Utils: Fetching spark://f80e8a4e0fa3:46745/jars/hadoop-aws-3.3.6.jar to /tmp/spark-d195a78f-e80a-4587-99d0-4003fc0c5127/userFiles-cd9631ad-66de-43bd-8259-985e50dfb17d/fetchFileTemp7833879347841475977.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.994443Z","level":"error","event":"25/08/31 18:03:52 INFO Executor: Adding file:/tmp/spark-d195a78f-e80a-4587-99d0-4003fc0c5127/userFiles-cd9631ad-66de-43bd-8259-985e50dfb17d/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.999499Z","level":"error","event":"25/08/31 18:03:52 INFO Executor: Fetching spark://f80e8a4e0fa3:46745/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663432154","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:52.999683Z","level":"error","event":"25/08/31 18:03:52 INFO Utils: Fetching spark://f80e8a4e0fa3:46745/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-d195a78f-e80a-4587-99d0-4003fc0c5127/userFiles-cd9631ad-66de-43bd-8259-985e50dfb17d/fetchFileTemp3620055611308503136.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:53.793738Z","level":"error","event":"25/08/31 18:03:53 INFO Executor: Adding file:/tmp/spark-d195a78f-e80a-4587-99d0-4003fc0c5127/userFiles-cd9631ad-66de-43bd-8259-985e50dfb17d/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:53.803794Z","level":"error","event":"25/08/31 18:03:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34993.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:53.803873Z","level":"error","event":"25/08/31 18:03:53 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:34993","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:53.803926Z","level":"error","event":"25/08/31 18:03:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:53.817610Z","level":"error","event":"25/08/31 18:03:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 34993, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:53.820980Z","level":"error","event":"25/08/31 18:03:53 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:34993 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 34993, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:53.824012Z","level":"error","event":"25/08/31 18:03:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 34993, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:53.824127Z","level":"error","event":"25/08/31 18:03:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 34993, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124266Z","level":"error","event":"25/08/31 18:03:54 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124347Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124405Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124455Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124507Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124564Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124615Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124669Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124735Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124782Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124825Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124870Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124924Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.124977Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125027Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125075Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125125Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125175Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125224Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125276Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125343Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125388Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125431Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125478Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125527Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125576Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125628Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125683Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125729Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125776Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:54.125842Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.499637Z","level":"error","event":"25/08/31 18:03:55 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.499781Z","level":"error","event":"25/08/31 18:03:55 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.505817Z","level":"error","event":"25/08/31 18:03:55 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.517170Z","level":"error","event":"25/08/31 18:03:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.527857Z","level":"error","event":"25/08/31 18:03:55 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.532757Z","level":"error","event":"25/08/31 18:03:55 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.532930Z","level":"error","event":"25/08/31 18:03:55 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.538966Z","level":"error","event":"25/08/31 18:03:55 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.539278Z","level":"error","event":"25/08/31 18:03:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.586366Z","level":"error","event":"25/08/31 18:03:55 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.589543Z","level":"error","event":"25/08/31 18:03:55 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.589643Z","level":"error","event":"25/08/31 18:03:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-d195a78f-e80a-4587-99d0-4003fc0c5127/pyspark-3efa73d2-2cd5-472c-89b6-7b56ac4daf3d","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.591720Z","level":"error","event":"25/08/31 18:03:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-d195a78f-e80a-4587-99d0-4003fc0c5127","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:03:55.593507Z","level":"error","event":"25/08/31 18:03:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-f3649201-3afa-472f-aa2d-12835ca748ff","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:26.906956","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:04:27.189425Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.381571Z","level":"error","event":"25/08/31 18:04:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.527810Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.531470Z","level":"error","event":"25/08/31 18:04:28 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.534813Z","level":"error","event":"25/08/31 18:04:28 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.667728Z","level":"error","event":"25/08/31 18:04:28 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.672036Z","level":"error","event":"25/08/31 18:04:28 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.672292Z","level":"error","event":"25/08/31 18:04:28 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.692387Z","level":"error","event":"25/08/31 18:04:28 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.697287Z","level":"error","event":"25/08/31 18:04:28 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.697478Z","level":"error","event":"25/08/31 18:04:28 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.697543Z","level":"error","event":"25/08/31 18:04:28 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.718356Z","level":"error","event":"25/08/31 18:04:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.724344Z","level":"error","event":"25/08/31 18:04:28 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.724554Z","level":"error","event":"25/08/31 18:04:28 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.770052Z","level":"error","event":"25/08/31 18:04:28 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.777463Z","level":"error","event":"25/08/31 18:04:28 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.777713Z","level":"error","event":"25/08/31 18:04:28 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.777785Z","level":"error","event":"25/08/31 18:04:28 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.777843Z","level":"error","event":"25/08/31 18:04:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:28.997781Z","level":"error","event":"25/08/31 18:04:28 INFO Utils: Successfully started service 'sparkDriver' on port 35815.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.021840Z","level":"error","event":"25/08/31 18:04:29 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.035216Z","level":"error","event":"25/08/31 18:04:29 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.053125Z","level":"error","event":"25/08/31 18:04:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.059058Z","level":"error","event":"25/08/31 18:04:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.059260Z","level":"error","event":"25/08/31 18:04:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.078188Z","level":"error","event":"25/08/31 18:04:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c470ee14-2d1d-4c00-ae56-ad8b49b5f07e","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.095608Z","level":"error","event":"25/08/31 18:04:29 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.187947Z","level":"error","event":"25/08/31 18:04:29 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.241390Z","level":"error","event":"25/08/31 18:04:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.275606Z","level":"error","event":"25/08/31 18:04:29 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:35815/jars/hadoop-aws-3.3.6.jar with timestamp 1756663468664","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279389Z","level":"error","event":"25/08/31 18:04:29 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:35815/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663468664","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279529Z","level":"error","event":"25/08/31 18:04:29 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:35815/jars/ojdbc11.jar with timestamp 1756663468664","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279584Z","level":"error","event":"25/08/31 18:04:29 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279619Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279652Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279684Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279715Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279745Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279774Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279803Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279831Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279862Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279892Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279931Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279962Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.279994Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280026Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280056Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280085Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280114Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280143Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280172Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280202Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280230Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280258Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280286Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280333Z","level":"error","event":"25/08/31 18:04:29 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280365Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280395Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280424Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280453Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280483Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280513Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280542Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280572Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280606Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280638Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280668Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280700Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280731Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280768Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280808Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280845Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280876Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280912Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280947Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.280979Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.281012Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.285003Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.285135Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.294094Z","level":"error","event":"25/08/31 18:04:29 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.297876Z","level":"error","event":"25/08/31 18:04:29 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.297994Z","level":"error","event":"25/08/31 18:04:29 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.298032Z","level":"error","event":"25/08/31 18:04:29 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.298067Z","level":"error","event":"25/08/31 18:04:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.409818Z","level":"error","event":"25/08/31 18:04:29 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.414191Z","level":"error","event":"25/08/31 18:04:29 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.414346Z","level":"error","event":"25/08/31 18:04:29 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.422636Z","level":"error","event":"25/08/31 18:04:29 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.428668Z","level":"error","event":"25/08/31 18:04:29 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1aea2cd3 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.435984Z","level":"error","event":"25/08/31 18:04:29 INFO Executor: Fetching spark://f80e8a4e0fa3:35815/jars/hadoop-aws-3.3.6.jar with timestamp 1756663468664","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.488406Z","level":"error","event":"25/08/31 18:04:29 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:35815 after 22 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.494729Z","level":"error","event":"25/08/31 18:04:29 INFO Utils: Fetching spark://f80e8a4e0fa3:35815/jars/hadoop-aws-3.3.6.jar to /tmp/spark-a85e7506-0b57-49ce-a0bc-463986094d18/userFiles-62b87668-3b29-464f-851b-a8cad3b2f8a0/fetchFileTemp11065438224734280029.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.513015Z","level":"error","event":"25/08/31 18:04:29 INFO Executor: Adding file:/tmp/spark-a85e7506-0b57-49ce-a0bc-463986094d18/userFiles-62b87668-3b29-464f-851b-a8cad3b2f8a0/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.516191Z","level":"error","event":"25/08/31 18:04:29 INFO Executor: Fetching spark://f80e8a4e0fa3:35815/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663468664","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:29.516294Z","level":"error","event":"25/08/31 18:04:29 INFO Utils: Fetching spark://f80e8a4e0fa3:35815/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-a85e7506-0b57-49ce-a0bc-463986094d18/userFiles-62b87668-3b29-464f-851b-a8cad3b2f8a0/fetchFileTemp13079318897166623432.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.089121Z","level":"error","event":"25/08/31 18:04:30 INFO Executor: Adding file:/tmp/spark-a85e7506-0b57-49ce-a0bc-463986094d18/userFiles-62b87668-3b29-464f-851b-a8cad3b2f8a0/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.097204Z","level":"error","event":"25/08/31 18:04:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40829.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.099888Z","level":"error","event":"25/08/31 18:04:30 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:40829","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.099988Z","level":"error","event":"25/08/31 18:04:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.110501Z","level":"error","event":"25/08/31 18:04:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 40829, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.116240Z","level":"error","event":"25/08/31 18:04:30 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:40829 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 40829, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.120922Z","level":"error","event":"25/08/31 18:04:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 40829, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.121087Z","level":"error","event":"25/08/31 18:04:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 40829, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410487Z","level":"error","event":"25/08/31 18:04:30 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410638Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410682Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410714Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410757Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410785Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410814Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410844Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410871Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410898Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410924Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410951Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.410979Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411010Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411038Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411066Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411093Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411121Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411148Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411187Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411217Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411247Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411275Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411321Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411355Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411383Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411412Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411444Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411471Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411498Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:30.411526Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.853502Z","level":"error","event":"25/08/31 18:04:31 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.855884Z","level":"error","event":"25/08/31 18:04:31 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.862310Z","level":"error","event":"25/08/31 18:04:31 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.870317Z","level":"error","event":"25/08/31 18:04:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.880657Z","level":"error","event":"25/08/31 18:04:31 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.883997Z","level":"error","event":"25/08/31 18:04:31 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.884110Z","level":"error","event":"25/08/31 18:04:31 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.887001Z","level":"error","event":"25/08/31 18:04:31 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.890490Z","level":"error","event":"25/08/31 18:04:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.928729Z","level":"error","event":"25/08/31 18:04:31 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.932134Z","level":"error","event":"25/08/31 18:04:31 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.932268Z","level":"error","event":"25/08/31 18:04:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-706cbf84-7729-4af0-8f94-d0a928bfc408","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.935049Z","level":"error","event":"25/08/31 18:04:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-a85e7506-0b57-49ce-a0bc-463986094d18/pyspark-737bb32c-a6a3-4220-8d89-4d0b5511bad9","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:04:31.937459Z","level":"error","event":"25/08/31 18:04:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-a85e7506-0b57-49ce-a0bc-463986094d18","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:03.036373","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:05:03.310356Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.400788Z","level":"error","event":"25/08/31 18:05:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.563735Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.566985Z","level":"error","event":"25/08/31 18:05:04 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.567081Z","level":"error","event":"25/08/31 18:05:04 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.726608Z","level":"error","event":"25/08/31 18:05:04 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.726643Z","level":"error","event":"25/08/31 18:05:04 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.726675Z","level":"error","event":"25/08/31 18:05:04 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.748768Z","level":"error","event":"25/08/31 18:05:04 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.748804Z","level":"error","event":"25/08/31 18:05:04 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.748834Z","level":"error","event":"25/08/31 18:05:04 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.748863Z","level":"error","event":"25/08/31 18:05:04 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.769754Z","level":"error","event":"25/08/31 18:05:04 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.769795Z","level":"error","event":"25/08/31 18:05:04 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.774101Z","level":"error","event":"25/08/31 18:05:04 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.818673Z","level":"error","event":"25/08/31 18:05:04 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.818882Z","level":"error","event":"25/08/31 18:05:04 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.818951Z","level":"error","event":"25/08/31 18:05:04 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.819006Z","level":"error","event":"25/08/31 18:05:04 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:04.824202Z","level":"error","event":"25/08/31 18:05:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.037133Z","level":"error","event":"25/08/31 18:05:05 INFO Utils: Successfully started service 'sparkDriver' on port 40125.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.057882Z","level":"error","event":"25/08/31 18:05:05 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.069591Z","level":"error","event":"25/08/31 18:05:05 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.083954Z","level":"error","event":"25/08/31 18:05:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.088421Z","level":"error","event":"25/08/31 18:05:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.088550Z","level":"error","event":"25/08/31 18:05:05 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.106160Z","level":"error","event":"25/08/31 18:05:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-029ffba3-6ea4-460d-8d72-3c09ba5d7c22","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.122375Z","level":"error","event":"25/08/31 18:05:05 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.227791Z","level":"error","event":"25/08/31 18:05:05 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.302446Z","level":"error","event":"25/08/31 18:05:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.307227Z","level":"error","event":"25/08/31 18:05:05 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.338371Z","level":"error","event":"25/08/31 18:05:05 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:40125/jars/hadoop-aws-3.3.6.jar with timestamp 1756663504718","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.343346Z","level":"error","event":"25/08/31 18:05:05 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:40125/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663504718","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.343522Z","level":"error","event":"25/08/31 18:05:05 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:40125/jars/ojdbc11.jar with timestamp 1756663504718","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.343627Z","level":"error","event":"25/08/31 18:05:05 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.343694Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.343755Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.343810Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.343866Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.343922Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.343975Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344030Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344086Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344140Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344196Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344251Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344318Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344372Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344429Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344485Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344538Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344588Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344637Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344687Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344737Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344786Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344841Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344883Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344926Z","level":"error","event":"25/08/31 18:05:05 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.344967Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345013Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345066Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345116Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345159Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345204Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345254Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345319Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345368Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345414Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345459Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345503Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345548Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345593Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345639Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345683Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345731Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345782Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345837Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345895Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.345947Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.350786Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.351005Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.360626Z","level":"error","event":"25/08/31 18:05:05 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.365339Z","level":"error","event":"25/08/31 18:05:05 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.365518Z","level":"error","event":"25/08/31 18:05:05 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.365578Z","level":"error","event":"25/08/31 18:05:05 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.365627Z","level":"error","event":"25/08/31 18:05:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.456523Z","level":"error","event":"25/08/31 18:05:05 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.462611Z","level":"error","event":"25/08/31 18:05:05 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.462765Z","level":"error","event":"25/08/31 18:05:05 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.470468Z","level":"error","event":"25/08/31 18:05:05 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.476269Z","level":"error","event":"25/08/31 18:05:05 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@36add9cf for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.483562Z","level":"error","event":"25/08/31 18:05:05 INFO Executor: Fetching spark://f80e8a4e0fa3:40125/jars/hadoop-aws-3.3.6.jar with timestamp 1756663504718","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.535347Z","level":"error","event":"25/08/31 18:05:05 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:40125 after 26 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.541345Z","level":"error","event":"25/08/31 18:05:05 INFO Utils: Fetching spark://f80e8a4e0fa3:40125/jars/hadoop-aws-3.3.6.jar to /tmp/spark-9f1bf9cc-6b3c-4c35-bdf4-65c7fde76e88/userFiles-fc6314e8-7d83-48c8-add9-920fc84b00d9/fetchFileTemp7427416689077228991.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.574398Z","level":"error","event":"25/08/31 18:05:05 INFO Executor: Adding file:/tmp/spark-9f1bf9cc-6b3c-4c35-bdf4-65c7fde76e88/userFiles-fc6314e8-7d83-48c8-add9-920fc84b00d9/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.582316Z","level":"error","event":"25/08/31 18:05:05 INFO Executor: Fetching spark://f80e8a4e0fa3:40125/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663504718","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:05.582611Z","level":"error","event":"25/08/31 18:05:05 INFO Utils: Fetching spark://f80e8a4e0fa3:40125/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-9f1bf9cc-6b3c-4c35-bdf4-65c7fde76e88/userFiles-fc6314e8-7d83-48c8-add9-920fc84b00d9/fetchFileTemp3911236821815628169.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.165805Z","level":"error","event":"25/08/31 18:05:06 INFO Executor: Adding file:/tmp/spark-9f1bf9cc-6b3c-4c35-bdf4-65c7fde76e88/userFiles-fc6314e8-7d83-48c8-add9-920fc84b00d9/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.175958Z","level":"error","event":"25/08/31 18:05:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39959.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.181636Z","level":"error","event":"25/08/31 18:05:06 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:39959","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.181806Z","level":"error","event":"25/08/31 18:05:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.193350Z","level":"error","event":"25/08/31 18:05:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 39959, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.199800Z","level":"error","event":"25/08/31 18:05:06 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:39959 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 39959, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.203513Z","level":"error","event":"25/08/31 18:05:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 39959, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.203688Z","level":"error","event":"25/08/31 18:05:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 39959, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.418572Z","level":"error","event":"25/08/31 18:05:06 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.418761Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.418835Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.418870Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.418901Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.418931Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.418969Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419010Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419065Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419137Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419194Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419245Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419314Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419377Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419433Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419490Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419546Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419597Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419654Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419712Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419768Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419820Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419872Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419922Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419955Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.419985Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.420015Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.420044Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.420072Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.420100Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:06.420138Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.772206Z","level":"error","event":"25/08/31 18:05:07 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.774661Z","level":"error","event":"25/08/31 18:05:07 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.778209Z","level":"error","event":"25/08/31 18:05:07 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.784483Z","level":"error","event":"25/08/31 18:05:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.794268Z","level":"error","event":"25/08/31 18:05:07 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.796985Z","level":"error","event":"25/08/31 18:05:07 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.797089Z","level":"error","event":"25/08/31 18:05:07 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.799162Z","level":"error","event":"25/08/31 18:05:07 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.801855Z","level":"error","event":"25/08/31 18:05:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.838682Z","level":"error","event":"25/08/31 18:05:07 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.841085Z","level":"error","event":"25/08/31 18:05:07 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.841172Z","level":"error","event":"25/08/31 18:05:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-9f1bf9cc-6b3c-4c35-bdf4-65c7fde76e88","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.842629Z","level":"error","event":"25/08/31 18:05:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-9f1bf9cc-6b3c-4c35-bdf4-65c7fde76e88/pyspark-1d3c4efd-bef6-4b6b-be6e-8a358e2d3f16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:07.844435Z","level":"error","event":"25/08/31 18:05:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-a50feff5-16d1-465b-9033-320076e57529","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:38.771179","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:05:39.095362Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.281695Z","level":"error","event":"25/08/31 18:05:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.470576Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.474971Z","level":"error","event":"25/08/31 18:05:40 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.478280Z","level":"error","event":"25/08/31 18:05:40 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.699794Z","level":"error","event":"25/08/31 18:05:40 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.703353Z","level":"error","event":"25/08/31 18:05:40 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.703474Z","level":"error","event":"25/08/31 18:05:40 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.733790Z","level":"error","event":"25/08/31 18:05:40 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.738462Z","level":"error","event":"25/08/31 18:05:40 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.738685Z","level":"error","event":"25/08/31 18:05:40 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.738749Z","level":"error","event":"25/08/31 18:05:40 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.765592Z","level":"error","event":"25/08/31 18:05:40 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.770605Z","level":"error","event":"25/08/31 18:05:40 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.774551Z","level":"error","event":"25/08/31 18:05:40 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.814726Z","level":"error","event":"25/08/31 18:05:40 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.821011Z","level":"error","event":"25/08/31 18:05:40 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.821257Z","level":"error","event":"25/08/31 18:05:40 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.821342Z","level":"error","event":"25/08/31 18:05:40 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:40.821402Z","level":"error","event":"25/08/31 18:05:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.048907Z","level":"error","event":"25/08/31 18:05:41 INFO Utils: Successfully started service 'sparkDriver' on port 39923.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.077110Z","level":"error","event":"25/08/31 18:05:41 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.091712Z","level":"error","event":"25/08/31 18:05:41 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.109676Z","level":"error","event":"25/08/31 18:05:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.113040Z","level":"error","event":"25/08/31 18:05:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.115965Z","level":"error","event":"25/08/31 18:05:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.136770Z","level":"error","event":"25/08/31 18:05:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e3d3c548-c1d1-458b-83f5-3884b99e1b74","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.164700Z","level":"error","event":"25/08/31 18:05:41 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.314967Z","level":"error","event":"25/08/31 18:05:41 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.383012Z","level":"error","event":"25/08/31 18:05:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.393014Z","level":"error","event":"25/08/31 18:05:41 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.433083Z","level":"error","event":"25/08/31 18:05:41 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:39923/jars/hadoop-aws-3.3.6.jar with timestamp 1756663540694","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.437264Z","level":"error","event":"25/08/31 18:05:41 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:39923/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663540694","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.437480Z","level":"error","event":"25/08/31 18:05:41 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:39923/jars/ojdbc11.jar with timestamp 1756663540694","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.437557Z","level":"error","event":"25/08/31 18:05:41 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.437612Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.437661Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.437713Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.437767Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.437814Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.437861Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.437914Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.437966Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438018Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438072Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438141Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438190Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438239Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438287Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438345Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438395Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438444Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438497Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438553Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438605Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438655Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438705Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438754Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438802Z","level":"error","event":"25/08/31 18:05:41 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438852Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438904Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.438955Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439009Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439060Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439107Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439157Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439222Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439273Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439337Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439392Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439440Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439489Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439545Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439599Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439656Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439711Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439770Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439827Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439883Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.439936Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.445870Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.446046Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.457466Z","level":"error","event":"25/08/31 18:05:41 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.463928Z","level":"error","event":"25/08/31 18:05:41 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.464151Z","level":"error","event":"25/08/31 18:05:41 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.464232Z","level":"error","event":"25/08/31 18:05:41 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.464292Z","level":"error","event":"25/08/31 18:05:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.599509Z","level":"error","event":"25/08/31 18:05:41 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.604835Z","level":"error","event":"25/08/31 18:05:41 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.604986Z","level":"error","event":"25/08/31 18:05:41 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.615888Z","level":"error","event":"25/08/31 18:05:41 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.622370Z","level":"error","event":"25/08/31 18:05:41 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@141a8777 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.634611Z","level":"error","event":"25/08/31 18:05:41 INFO Executor: Fetching spark://f80e8a4e0fa3:39923/jars/hadoop-aws-3.3.6.jar with timestamp 1756663540694","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.702838Z","level":"error","event":"25/08/31 18:05:41 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:39923 after 37 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.710902Z","level":"error","event":"25/08/31 18:05:41 INFO Utils: Fetching spark://f80e8a4e0fa3:39923/jars/hadoop-aws-3.3.6.jar to /tmp/spark-b7283ede-ad05-470e-92eb-c75f5b34ff9d/userFiles-51b9fdc1-cadb-4155-9aed-ae3918bc6792/fetchFileTemp10798486579194289610.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.749697Z","level":"error","event":"25/08/31 18:05:41 INFO Executor: Adding file:/tmp/spark-b7283ede-ad05-470e-92eb-c75f5b34ff9d/userFiles-51b9fdc1-cadb-4155-9aed-ae3918bc6792/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.756660Z","level":"error","event":"25/08/31 18:05:41 INFO Executor: Fetching spark://f80e8a4e0fa3:39923/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663540694","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:41.756857Z","level":"error","event":"25/08/31 18:05:41 INFO Utils: Fetching spark://f80e8a4e0fa3:39923/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-b7283ede-ad05-470e-92eb-c75f5b34ff9d/userFiles-51b9fdc1-cadb-4155-9aed-ae3918bc6792/fetchFileTemp10545511697381886701.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.385824Z","level":"error","event":"25/08/31 18:05:42 INFO Executor: Adding file:/tmp/spark-b7283ede-ad05-470e-92eb-c75f5b34ff9d/userFiles-51b9fdc1-cadb-4155-9aed-ae3918bc6792/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.399258Z","level":"error","event":"25/08/31 18:05:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33277.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.399469Z","level":"error","event":"25/08/31 18:05:42 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:33277","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.399541Z","level":"error","event":"25/08/31 18:05:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.410609Z","level":"error","event":"25/08/31 18:05:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 33277, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.418007Z","level":"error","event":"25/08/31 18:05:42 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:33277 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 33277, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.421663Z","level":"error","event":"25/08/31 18:05:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 33277, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.424132Z","level":"error","event":"25/08/31 18:05:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 33277, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732008Z","level":"error","event":"25/08/31 18:05:42 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732315Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732404Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732460Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732507Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732552Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732598Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732640Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732693Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732752Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732802Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732853Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732906Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.732956Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733006Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733061Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733114Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733169Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733222Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733323Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733379Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733427Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733530Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733592Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733645Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733856Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733921Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.733973Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.734028Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.734081Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:42.734130Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.179230Z","level":"error","event":"25/08/31 18:05:45 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.179372Z","level":"error","event":"25/08/31 18:05:45 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.184537Z","level":"error","event":"25/08/31 18:05:45 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.191276Z","level":"error","event":"25/08/31 18:05:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.200955Z","level":"error","event":"25/08/31 18:05:45 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.203594Z","level":"error","event":"25/08/31 18:05:45 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.203697Z","level":"error","event":"25/08/31 18:05:45 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.205666Z","level":"error","event":"25/08/31 18:05:45 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.208378Z","level":"error","event":"25/08/31 18:05:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.239990Z","level":"error","event":"25/08/31 18:05:45 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.244140Z","level":"error","event":"25/08/31 18:05:45 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.244246Z","level":"error","event":"25/08/31 18:05:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-b7283ede-ad05-470e-92eb-c75f5b34ff9d","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.248077Z","level":"error","event":"25/08/31 18:05:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-635f45bb-5bf1-4505-9918-96ab94c255f2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:05:45.250982Z","level":"error","event":"25/08/31 18:05:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-b7283ede-ad05-470e-92eb-c75f5b34ff9d/pyspark-6b46a9c1-700e-4641-87e6-97484a801d36","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:16.238379","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:06:16.561512Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:17.672010Z","level":"error","event":"25/08/31 18:06:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:17.831154Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:17.835432Z","level":"error","event":"25/08/31 18:06:17 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:17.839231Z","level":"error","event":"25/08/31 18:06:17 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.012219Z","level":"error","event":"25/08/31 18:06:18 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.015413Z","level":"error","event":"25/08/31 18:06:18 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.015519Z","level":"error","event":"25/08/31 18:06:18 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.032555Z","level":"error","event":"25/08/31 18:06:18 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.035013Z","level":"error","event":"25/08/31 18:06:18 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.035124Z","level":"error","event":"25/08/31 18:06:18 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.035161Z","level":"error","event":"25/08/31 18:06:18 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.054584Z","level":"error","event":"25/08/31 18:06:18 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.056942Z","level":"error","event":"25/08/31 18:06:18 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.057057Z","level":"error","event":"25/08/31 18:06:18 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.090870Z","level":"error","event":"25/08/31 18:06:18 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.095111Z","level":"error","event":"25/08/31 18:06:18 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.095247Z","level":"error","event":"25/08/31 18:06:18 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.095286Z","level":"error","event":"25/08/31 18:06:18 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.095335Z","level":"error","event":"25/08/31 18:06:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.273740Z","level":"error","event":"25/08/31 18:06:18 INFO Utils: Successfully started service 'sparkDriver' on port 33481.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.290552Z","level":"error","event":"25/08/31 18:06:18 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.299633Z","level":"error","event":"25/08/31 18:06:18 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.312049Z","level":"error","event":"25/08/31 18:06:18 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.316062Z","level":"error","event":"25/08/31 18:06:18 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.316181Z","level":"error","event":"25/08/31 18:06:18 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.329907Z","level":"error","event":"25/08/31 18:06:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-eb79acd5-7205-4358-ad6b-d6a1358dca84","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.348148Z","level":"error","event":"25/08/31 18:06:18 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.465669Z","level":"error","event":"25/08/31 18:06:18 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.530245Z","level":"error","event":"25/08/31 18:06:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.572947Z","level":"error","event":"25/08/31 18:06:18 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:33481/jars/hadoop-aws-3.3.6.jar with timestamp 1756663578008","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.577588Z","level":"error","event":"25/08/31 18:06:18 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:33481/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663578008","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.577837Z","level":"error","event":"25/08/31 18:06:18 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:33481/jars/ojdbc11.jar with timestamp 1756663578008","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.577945Z","level":"error","event":"25/08/31 18:06:18 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578016Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578081Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578144Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578207Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578268Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578349Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578408Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578467Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578524Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578581Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578642Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578704Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578765Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578827Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578886Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.578949Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579010Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579068Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579120Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579173Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579226Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579310Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579376Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579430Z","level":"error","event":"25/08/31 18:06:18 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579480Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579534Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579593Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579649Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579704Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579757Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579811Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579865Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579921Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.579972Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.580027Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.580078Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.580126Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.580177Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.580229Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.580286Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.580359Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.580412Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.580462Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.580526Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.580580Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.588012Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.588242Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.598475Z","level":"error","event":"25/08/31 18:06:18 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.602532Z","level":"error","event":"25/08/31 18:06:18 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.602645Z","level":"error","event":"25/08/31 18:06:18 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.602701Z","level":"error","event":"25/08/31 18:06:18 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.602736Z","level":"error","event":"25/08/31 18:06:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.687725Z","level":"error","event":"25/08/31 18:06:18 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.692073Z","level":"error","event":"25/08/31 18:06:18 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.692209Z","level":"error","event":"25/08/31 18:06:18 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.707263Z","level":"error","event":"25/08/31 18:06:18 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.711623Z","level":"error","event":"25/08/31 18:06:18 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@6669a0c1 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.717891Z","level":"error","event":"25/08/31 18:06:18 INFO Executor: Fetching spark://f80e8a4e0fa3:33481/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663578008","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.755756Z","level":"error","event":"25/08/31 18:06:18 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:33481 after 16 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:18.765505Z","level":"error","event":"25/08/31 18:06:18 INFO Utils: Fetching spark://f80e8a4e0fa3:33481/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-75ace13e-b775-4791-b02f-914b7b674917/userFiles-d19ee475-4960-4535-96fe-33ed9abd7ac5/fetchFileTemp6468363184299876597.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.370485Z","level":"error","event":"25/08/31 18:06:19 INFO Executor: Adding file:/tmp/spark-75ace13e-b775-4791-b02f-914b7b674917/userFiles-d19ee475-4960-4535-96fe-33ed9abd7ac5/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.373226Z","level":"error","event":"25/08/31 18:06:19 INFO Executor: Fetching spark://f80e8a4e0fa3:33481/jars/hadoop-aws-3.3.6.jar with timestamp 1756663578008","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.373326Z","level":"error","event":"25/08/31 18:06:19 INFO Utils: Fetching spark://f80e8a4e0fa3:33481/jars/hadoop-aws-3.3.6.jar to /tmp/spark-75ace13e-b775-4791-b02f-914b7b674917/userFiles-d19ee475-4960-4535-96fe-33ed9abd7ac5/fetchFileTemp10274224718146831814.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.376880Z","level":"error","event":"25/08/31 18:06:19 INFO Executor: Adding file:/tmp/spark-75ace13e-b775-4791-b02f-914b7b674917/userFiles-d19ee475-4960-4535-96fe-33ed9abd7ac5/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.383458Z","level":"error","event":"25/08/31 18:06:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38843.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.387246Z","level":"error","event":"25/08/31 18:06:19 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:38843","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.387402Z","level":"error","event":"25/08/31 18:06:19 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.393830Z","level":"error","event":"25/08/31 18:06:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 38843, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.397448Z","level":"error","event":"25/08/31 18:06:19 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:38843 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 38843, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.399527Z","level":"error","event":"25/08/31 18:06:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 38843, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.401447Z","level":"error","event":"25/08/31 18:06:19 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 38843, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618157Z","level":"error","event":"25/08/31 18:06:19 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618335Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618388Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618426Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618457Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618487Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618518Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618548Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618577Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618617Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618646Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618674Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618702Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618730Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618758Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618786Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618814Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618842Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618871Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618898Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618927Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618956Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.618984Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.619012Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.619039Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.619066Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.619094Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.619122Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.619149Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.619176Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:19.619206Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.909145Z","level":"error","event":"25/08/31 18:06:20 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.911694Z","level":"error","event":"25/08/31 18:06:20 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.918746Z","level":"error","event":"25/08/31 18:06:20 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.925746Z","level":"error","event":"25/08/31 18:06:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.934803Z","level":"error","event":"25/08/31 18:06:20 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.938249Z","level":"error","event":"25/08/31 18:06:20 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.938406Z","level":"error","event":"25/08/31 18:06:20 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.941324Z","level":"error","event":"25/08/31 18:06:20 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.941505Z","level":"error","event":"25/08/31 18:06:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.980903Z","level":"error","event":"25/08/31 18:06:20 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.985457Z","level":"error","event":"25/08/31 18:06:20 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.985569Z","level":"error","event":"25/08/31 18:06:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-1fc7333c-a58a-4143-be9c-d2c4d61eabf9","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.985629Z","level":"error","event":"25/08/31 18:06:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-75ace13e-b775-4791-b02f-914b7b674917","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:20.988903Z","level":"error","event":"25/08/31 18:06:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-75ace13e-b775-4791-b02f-914b7b674917/pyspark-db2e6bda-ce8d-4c74-8d1d-177ee1ef3335","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:52.118505","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:06:52.419980Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:53.643524Z","level":"error","event":"25/08/31 18:06:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:53.819075Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:53.825425Z","level":"error","event":"25/08/31 18:06:53 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:53.831698Z","level":"error","event":"25/08/31 18:06:53 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.004670Z","level":"error","event":"25/08/31 18:06:54 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.004707Z","level":"error","event":"25/08/31 18:06:54 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.008109Z","level":"error","event":"25/08/31 18:06:54 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.045912Z","level":"error","event":"25/08/31 18:06:54 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.045948Z","level":"error","event":"25/08/31 18:06:54 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.045977Z","level":"error","event":"25/08/31 18:06:54 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.046007Z","level":"error","event":"25/08/31 18:06:54 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.072978Z","level":"error","event":"25/08/31 18:06:54 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.073020Z","level":"error","event":"25/08/31 18:06:54 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.076929Z","level":"error","event":"25/08/31 18:06:54 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.125552Z","level":"error","event":"25/08/31 18:06:54 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.136396Z","level":"error","event":"25/08/31 18:06:54 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.137077Z","level":"error","event":"25/08/31 18:06:54 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.137182Z","level":"error","event":"25/08/31 18:06:54 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.137243Z","level":"error","event":"25/08/31 18:06:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.408978Z","level":"error","event":"25/08/31 18:06:54 INFO Utils: Successfully started service 'sparkDriver' on port 44005.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.428771Z","level":"error","event":"25/08/31 18:06:54 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.439553Z","level":"error","event":"25/08/31 18:06:54 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.453323Z","level":"error","event":"25/08/31 18:06:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.457639Z","level":"error","event":"25/08/31 18:06:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.460704Z","level":"error","event":"25/08/31 18:06:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.472880Z","level":"error","event":"25/08/31 18:06:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-072ae59a-87ff-494e-8f39-3945309fa7a6","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.487807Z","level":"error","event":"25/08/31 18:06:54 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.576547Z","level":"error","event":"25/08/31 18:06:54 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.627142Z","level":"error","event":"25/08/31 18:06:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.668994Z","level":"error","event":"25/08/31 18:06:54 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:44005/jars/hadoop-aws-3.3.6.jar with timestamp 1756663613995","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.673852Z","level":"error","event":"25/08/31 18:06:54 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:44005/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663613995","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674001Z","level":"error","event":"25/08/31 18:06:54 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:44005/jars/ojdbc11.jar with timestamp 1756663613995","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674043Z","level":"error","event":"25/08/31 18:06:54 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674077Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674109Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674140Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674170Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674199Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674231Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674262Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674292Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674349Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674380Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674410Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674459Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674501Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674539Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674574Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674609Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674641Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674674Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674710Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674742Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674788Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674824Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674857Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674896Z","level":"error","event":"25/08/31 18:06:54 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674934Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.674972Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675010Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675049Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675088Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675123Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675157Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675190Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675227Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675269Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675330Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675368Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675402Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675443Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675476Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675509Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675541Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675572Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675605Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675635Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.675664Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.681168Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.681307Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.692735Z","level":"error","event":"25/08/31 18:06:54 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.696492Z","level":"error","event":"25/08/31 18:06:54 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.696616Z","level":"error","event":"25/08/31 18:06:54 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.696652Z","level":"error","event":"25/08/31 18:06:54 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.696684Z","level":"error","event":"25/08/31 18:06:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.793747Z","level":"error","event":"25/08/31 18:06:54 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.798751Z","level":"error","event":"25/08/31 18:06:54 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.798923Z","level":"error","event":"25/08/31 18:06:54 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.807357Z","level":"error","event":"25/08/31 18:06:54 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.815343Z","level":"error","event":"25/08/31 18:06:54 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5f8d356e for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.825555Z","level":"error","event":"25/08/31 18:06:54 INFO Executor: Fetching spark://f80e8a4e0fa3:44005/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663613995","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.877679Z","level":"error","event":"25/08/31 18:06:54 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:44005 after 21 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:54.888246Z","level":"error","event":"25/08/31 18:06:54 INFO Utils: Fetching spark://f80e8a4e0fa3:44005/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-a84952f6-e9f3-41a7-822f-b39e3a5497c6/userFiles-768dc23f-f5df-4feb-a53a-187cc0d7cd27/fetchFileTemp4264139165747685774.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.555227Z","level":"error","event":"25/08/31 18:06:55 INFO Executor: Adding file:/tmp/spark-a84952f6-e9f3-41a7-822f-b39e3a5497c6/userFiles-768dc23f-f5df-4feb-a53a-187cc0d7cd27/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.558335Z","level":"error","event":"25/08/31 18:06:55 INFO Executor: Fetching spark://f80e8a4e0fa3:44005/jars/hadoop-aws-3.3.6.jar with timestamp 1756663613995","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.558429Z","level":"error","event":"25/08/31 18:06:55 INFO Utils: Fetching spark://f80e8a4e0fa3:44005/jars/hadoop-aws-3.3.6.jar to /tmp/spark-a84952f6-e9f3-41a7-822f-b39e3a5497c6/userFiles-768dc23f-f5df-4feb-a53a-187cc0d7cd27/fetchFileTemp3554376020553574521.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.562019Z","level":"error","event":"25/08/31 18:06:55 INFO Executor: Adding file:/tmp/spark-a84952f6-e9f3-41a7-822f-b39e3a5497c6/userFiles-768dc23f-f5df-4feb-a53a-187cc0d7cd27/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.568534Z","level":"error","event":"25/08/31 18:06:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36461.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.570812Z","level":"error","event":"25/08/31 18:06:55 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:36461","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.570910Z","level":"error","event":"25/08/31 18:06:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.581658Z","level":"error","event":"25/08/31 18:06:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 36461, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.585405Z","level":"error","event":"25/08/31 18:06:55 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:36461 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 36461, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.587293Z","level":"error","event":"25/08/31 18:06:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 36461, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.588961Z","level":"error","event":"25/08/31 18:06:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 36461, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.855880Z","level":"error","event":"25/08/31 18:06:55 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856090Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856143Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856198Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856235Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856267Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856309Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856344Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856376Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856405Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856440Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856469Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856509Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856536Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856565Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856593Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856622Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856650Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856680Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856708Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856748Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856779Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856808Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856837Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856866Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856895Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856939Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.856972Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.857010Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.857043Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:55.857075Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.487388Z","level":"error","event":"25/08/31 18:06:57 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.492845Z","level":"error","event":"25/08/31 18:06:57 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.502312Z","level":"error","event":"25/08/31 18:06:57 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.512642Z","level":"error","event":"25/08/31 18:06:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.525197Z","level":"error","event":"25/08/31 18:06:57 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.529277Z","level":"error","event":"25/08/31 18:06:57 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.529458Z","level":"error","event":"25/08/31 18:06:57 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.532783Z","level":"error","event":"25/08/31 18:06:57 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.537578Z","level":"error","event":"25/08/31 18:06:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.583832Z","level":"error","event":"25/08/31 18:06:57 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.584030Z","level":"error","event":"25/08/31 18:06:57 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.584112Z","level":"error","event":"25/08/31 18:06:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-a84952f6-e9f3-41a7-822f-b39e3a5497c6/pyspark-65cab370-f343-480b-aa9d-608bd652dea6","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.588957Z","level":"error","event":"25/08/31 18:06:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-a84952f6-e9f3-41a7-822f-b39e3a5497c6","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:06:57.594328Z","level":"error","event":"25/08/31 18:06:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-73ac5db0-da5f-4e25-8351-f206cc515a2d","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:28.754457","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:07:29.047535Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.270731Z","level":"error","event":"25/08/31 18:07:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.436015Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.439635Z","level":"error","event":"25/08/31 18:07:30 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.439758Z","level":"error","event":"25/08/31 18:07:30 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.622835Z","level":"error","event":"25/08/31 18:07:30 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.625995Z","level":"error","event":"25/08/31 18:07:30 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.629415Z","level":"error","event":"25/08/31 18:07:30 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.658368Z","level":"error","event":"25/08/31 18:07:30 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.664409Z","level":"error","event":"25/08/31 18:07:30 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.664621Z","level":"error","event":"25/08/31 18:07:30 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.664709Z","level":"error","event":"25/08/31 18:07:30 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.696455Z","level":"error","event":"25/08/31 18:07:30 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.702283Z","level":"error","event":"25/08/31 18:07:30 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.705844Z","level":"error","event":"25/08/31 18:07:30 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.773696Z","level":"error","event":"25/08/31 18:07:30 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.780016Z","level":"error","event":"25/08/31 18:07:30 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.780242Z","level":"error","event":"25/08/31 18:07:30 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.780284Z","level":"error","event":"25/08/31 18:07:30 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:30.780339Z","level":"error","event":"25/08/31 18:07:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.032939Z","level":"error","event":"25/08/31 18:07:31 INFO Utils: Successfully started service 'sparkDriver' on port 43945.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.050439Z","level":"error","event":"25/08/31 18:07:31 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.059770Z","level":"error","event":"25/08/31 18:07:31 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.070327Z","level":"error","event":"25/08/31 18:07:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.073423Z","level":"error","event":"25/08/31 18:07:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.073565Z","level":"error","event":"25/08/31 18:07:31 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.086217Z","level":"error","event":"25/08/31 18:07:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1690b3b2-ad62-450b-af60-fded4b64dd49","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.103788Z","level":"error","event":"25/08/31 18:07:31 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.204505Z","level":"error","event":"25/08/31 18:07:31 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.270939Z","level":"error","event":"25/08/31 18:07:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.279114Z","level":"error","event":"25/08/31 18:07:31 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.321652Z","level":"error","event":"25/08/31 18:07:31 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://f80e8a4e0fa3:43945/jars/hadoop-aws-3.3.6.jar with timestamp 1756663650618","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330079Z","level":"error","event":"25/08/31 18:07:31 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://f80e8a4e0fa3:43945/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663650618","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330348Z","level":"error","event":"25/08/31 18:07:31 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://f80e8a4e0fa3:43945/jars/ojdbc11.jar with timestamp 1756663650618","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330464Z","level":"error","event":"25/08/31 18:07:31 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330551Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330595Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330627Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330658Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330688Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330721Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330751Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330781Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330812Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330840Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330869Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330898Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330929Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330962Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.330992Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331022Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331053Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331083Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331113Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331143Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331172Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331226Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331270Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331344Z","level":"error","event":"25/08/31 18:07:31 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331401Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331457Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331509Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331563Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331599Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331629Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331660Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331710Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331743Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331773Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331802Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331836Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331892Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331950Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.331989Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.332020Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.332051Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.332080Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.332110Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.332167Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.332224Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.337017Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.337322Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.360440Z","level":"error","event":"25/08/31 18:07:31 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.366124Z","level":"error","event":"25/08/31 18:07:31 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.366330Z","level":"error","event":"25/08/31 18:07:31 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.366412Z","level":"error","event":"25/08/31 18:07:31 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.366476Z","level":"error","event":"25/08/31 18:07:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.500482Z","level":"error","event":"25/08/31 18:07:31 INFO Executor: Starting executor ID driver on host f80e8a4e0fa3","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.503884Z","level":"error","event":"25/08/31 18:07:31 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.504006Z","level":"error","event":"25/08/31 18:07:31 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.516085Z","level":"error","event":"25/08/31 18:07:31 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.522139Z","level":"error","event":"25/08/31 18:07:31 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@390acac5 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.539615Z","level":"error","event":"25/08/31 18:07:31 INFO Executor: Fetching spark://f80e8a4e0fa3:43945/jars/hadoop-aws-3.3.6.jar with timestamp 1756663650618","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.592258Z","level":"error","event":"25/08/31 18:07:31 INFO TransportClientFactory: Successfully created connection to f80e8a4e0fa3/172.18.0.11:43945 after 19 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.601594Z","level":"error","event":"25/08/31 18:07:31 INFO Utils: Fetching spark://f80e8a4e0fa3:43945/jars/hadoop-aws-3.3.6.jar to /tmp/spark-cf76eee8-9737-49ed-bb90-c3d615966cf4/userFiles-1c1bee5a-aac4-4db5-96d9-ad552ca662ae/fetchFileTemp9584954286227969879.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.631002Z","level":"error","event":"25/08/31 18:07:31 INFO Executor: Adding file:/tmp/spark-cf76eee8-9737-49ed-bb90-c3d615966cf4/userFiles-1c1bee5a-aac4-4db5-96d9-ad552ca662ae/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.635934Z","level":"error","event":"25/08/31 18:07:31 INFO Executor: Fetching spark://f80e8a4e0fa3:43945/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756663650618","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:31.636064Z","level":"error","event":"25/08/31 18:07:31 INFO Utils: Fetching spark://f80e8a4e0fa3:43945/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-cf76eee8-9737-49ed-bb90-c3d615966cf4/userFiles-1c1bee5a-aac4-4db5-96d9-ad552ca662ae/fetchFileTemp18017602211448661806.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.327528Z","level":"error","event":"25/08/31 18:07:32 INFO Executor: Adding file:/tmp/spark-cf76eee8-9737-49ed-bb90-c3d615966cf4/userFiles-1c1bee5a-aac4-4db5-96d9-ad552ca662ae/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.338093Z","level":"error","event":"25/08/31 18:07:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40933.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.343030Z","level":"error","event":"25/08/31 18:07:32 INFO NettyBlockTransferService: Server created on f80e8a4e0fa3:40933","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.343231Z","level":"error","event":"25/08/31 18:07:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.353443Z","level":"error","event":"25/08/31 18:07:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f80e8a4e0fa3, 40933, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.358078Z","level":"error","event":"25/08/31 18:07:32 INFO BlockManagerMasterEndpoint: Registering block manager f80e8a4e0fa3:40933 with 434.4 MiB RAM, BlockManagerId(driver, f80e8a4e0fa3, 40933, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.360601Z","level":"error","event":"25/08/31 18:07:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f80e8a4e0fa3, 40933, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.362454Z","level":"error","event":"25/08/31 18:07:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f80e8a4e0fa3, 40933, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.586517Z","level":"error","event":"25/08/31 18:07:32 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.586751Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.586830Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.586894Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.586947Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.586999Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587058Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587116Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587173Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587249Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587323Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587391Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587447Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587504Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587561Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587619Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587676Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587730Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587782Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587834Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587905Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.587960Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.588014Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.588067Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.588121Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.588174Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.588228Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.588281Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.588355Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.588423Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:32.588475Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.104537Z","level":"error","event":"25/08/31 18:07:34 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.107875Z","level":"error","event":"25/08/31 18:07:34 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.117024Z","level":"error","event":"25/08/31 18:07:34 INFO SparkUI: Stopped Spark web UI at http://f80e8a4e0fa3:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.125861Z","level":"error","event":"25/08/31 18:07:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.137032Z","level":"error","event":"25/08/31 18:07:34 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.140565Z","level":"error","event":"25/08/31 18:07:34 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.140679Z","level":"error","event":"25/08/31 18:07:34 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.143901Z","level":"error","event":"25/08/31 18:07:34 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.148580Z","level":"error","event":"25/08/31 18:07:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.187554Z","level":"error","event":"25/08/31 18:07:34 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.191842Z","level":"error","event":"25/08/31 18:07:34 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.191950Z","level":"error","event":"25/08/31 18:07:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-95c48d0f-d8a3-458a-99f5-87e91668ac19","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.194426Z","level":"error","event":"25/08/31 18:07:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-cf76eee8-9737-49ed-bb90-c3d615966cf4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:07:34.196762Z","level":"error","event":"25/08/31 18:07:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-cf76eee8-9737-49ed-bb90-c3d615966cf4/pyspark-b52b0cb3-1a67-4c76-94af-34344ff22761","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:04.581752","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:08:04.899773Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:05.960977Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:06.028998Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:06.029224Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:06.033308Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:06.033440Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:06.036164Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-a4d735af-bffa-4ec9-b1b1-e2101517ce51;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:06.036274Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:09.331593Z","level":"error","event":"\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:09.570047Z","level":"error","event":"downloading https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.jar ...","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.171345Z","level":"error","event":":: resolution report :: resolve 3305ms :: artifacts dl 17833ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176200Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176293Z","level":"error","event":"\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176338Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176377Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176407Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176439Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176473Z","level":"error","event":"\t|      default     |   2   |   1   |   1   |   0   ||   1   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176502Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176532Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176563Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176592Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176622Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176651Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176681Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176710Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176738Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176769Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176811Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176856Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176903Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176944Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.176972Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177017Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177057Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177097Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177140Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177180Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177218Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177248Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177276Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177312Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177347Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177376Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177403Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177430Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177458Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177485Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177513Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177542Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177571Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177599Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177628Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177655Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177683Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177711Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177740Z","level":"error","event":"\t\t[FAILED     ] org.apache.iceberg#iceberg-aws-bundle;1.9.2!iceberg-aws-bundle.jar: Downloaded file size (0) doesn't match expected Content Length (60448968) for https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.jar. Please retry. (17830ms)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177773Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177802Z","level":"error","event":"\t\t[FAILED     ] org.apache.iceberg#iceberg-aws-bundle;1.9.2!iceberg-aws-bundle.jar: Downloaded file size (0) doesn't match expected Content Length (60448968) for https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.jar. Please retry. (17830ms)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177833Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177862Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177890Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177918Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177946Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.177974Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178003Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178030Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178058Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178085Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178114Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178142Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178171Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178199Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178227Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178253Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178280Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178313Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178341Z","level":"error","event":"\t\t::              FAILED DOWNLOADS            ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178369Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178397Z","level":"error","event":"\t\t:: ^ see resolution messages for details  ^ ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178425Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178452Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178481Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178510Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-aws-bundle;1.9.2!iceberg-aws-bundle.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178539Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178571Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178599Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178626Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178652Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178679Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178706Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found, download failed: org.apache.iceberg#iceberg-aws-bundle;1.9.2!iceberg-aws-bundle.jar]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178738Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178767Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.178796Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.181799Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.181889Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.181924Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.181954Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.181982Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.182010Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.182038Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:27.197109","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":70,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:08:58.092871","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:08:58.360961Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:59.049322Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:59.090245Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:59.090417Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:59.094228Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:59.094338Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:59.094398Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-fe1fae7a-b700-4436-bedf-bbfe2e552caf;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:08:59.094431Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.084156Z","level":"error","event":"\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094353Z","level":"error","event":":: resolution report :: resolve 1995ms :: artifacts dl 2ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094466Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094504Z","level":"error","event":"\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094536Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094568Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094597Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094627Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094655Z","level":"error","event":"\t|      default     |   2   |   0   |   0   |   0   ||   1   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094684Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094714Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094747Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094776Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094806Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094843Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094875Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094905Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094934Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094964Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.094992Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095021Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095050Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095078Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095106Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095134Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095161Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095189Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095216Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095243Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095270Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095301Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095330Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095357Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095385Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095416Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095445Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095475Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095503Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095531Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095558Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095589Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095617Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095646Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095673Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095702Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095729Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095758Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095786Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095814Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095841Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095868Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095895Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095923Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095950Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.095978Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096005Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096033Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096061Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096088Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096114Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096143Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096176Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096205Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096234Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096262Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096290Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096324Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096353Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096380Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096407Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.096434Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:01.172031","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":70,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:09:32.189070","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:09:32.461283Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:33.188196Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:33.233564Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:33.233755Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:33.239051Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:33.239167Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:33.239231Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-d1ef4d04-a0e5-4968-8194-f0094f06b38f;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:33.239291Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.079053Z","level":"error","event":"\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.089535Z","level":"error","event":":: resolution report :: resolve 1849ms :: artifacts dl 3ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.096903Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097077Z","level":"error","event":"\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097143Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097198Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097254Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097315Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097368Z","level":"error","event":"\t|      default     |   2   |   0   |   0   |   0   ||   1   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097422Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097476Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097533Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097587Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097641Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097695Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097748Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097804Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097858Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097913Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.097966Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098020Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098073Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098127Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098179Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098232Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098282Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098340Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098412Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098466Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098522Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098575Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098627Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098679Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098731Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098788Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098840Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098892Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.098945Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099000Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099053Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099106Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099160Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099212Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099264Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099323Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099379Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099432Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099485Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099538Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099589Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099641Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099693Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099746Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099797Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099854Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099906Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.099959Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100011Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100061Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100113Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100166Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100221Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100275Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100334Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100388Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100440Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100491Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100542Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100592Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100644Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.100695Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:09:35.168124","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":70,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:10:05.351362","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:10:05.650393Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:06.390423Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:06.434755Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:06.434891Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:06.438551Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:06.438648Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:06.438684Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-994a4ff5-68e4-4a82-b3f8-4c16fc1c9487;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:06.438716Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.069641Z","level":"error","event":"\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.077188Z","level":"error","event":":: resolution report :: resolve 1637ms :: artifacts dl 1ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.077335Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082047Z","level":"error","event":"\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082151Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082190Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082223Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082254Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082284Z","level":"error","event":"\t|      default     |   2   |   0   |   0   |   0   ||   1   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082320Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082353Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082383Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082412Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082441Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082482Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082514Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082542Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082571Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082599Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082628Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082657Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082685Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082714Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082742Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082771Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082799Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082826Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082853Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082881Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082908Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082935Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082960Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.082988Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083016Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083043Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083084Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083116Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083146Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083175Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083205Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083237Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083267Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083296Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083332Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083364Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083394Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083423Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083451Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083479Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083505Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083533Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083559Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083587Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083613Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083641Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083669Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083697Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083724Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083749Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083774Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083817Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083858Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083889Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083931Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083959Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.083987Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.084019Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.084047Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.084074Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.084101Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.084127Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:10:08.139309","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":70,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:12:32.622331","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:12:35.433682Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:35.433752Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:35.433814Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:35.433876Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:35.433934Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:35.433992Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:35.434049Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-60d4b750-826e-4355-81c9-0eb07793c261;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:35.434107Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.605167Z","level":"error","event":":: resolution report :: resolve 5393ms :: artifacts dl 1ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.608741Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.608841Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.608896Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.608928Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.608958Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.608986Z","level":"error","event":"\t|      default     |   2   |   0   |   0   |   0   ||   0   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609016Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609045Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609076Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609104Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609133Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609161Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609190Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609218Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609246Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609274Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609310Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609340Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609368Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609395Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609422Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609451Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609478Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609506Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609533Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609560Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609594Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609633Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609662Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609690Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609719Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609747Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609775Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609803Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609830Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609857Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609889Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609919Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609947Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.609975Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610003Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610031Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610058Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610086Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610115Z","level":"error","event":"\tproblem while downloading module descriptor: https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.pom: Downloaded file size (0) doesn't match expected Content Length (1493) for https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.pom. Please retry. (306ms)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610144Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610171Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-aws-bundle;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610199Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610227Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610254Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610282Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610322Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610351Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-aws-bundle;1.9.2!iceberg-aws-bundle.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610379Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610406Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610434Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610461Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610489Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610516Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-aws-bundle/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610542Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610569Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-aws-bundle;1.9.2!iceberg-aws-bundle.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610596Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610622Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-aws-bundle/1.9.2/jars/iceberg-aws-bundle.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610649Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610676Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610702Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610728Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610755Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610781Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610808Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610834Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610861Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610887Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-aws-bundle;1.9.2!iceberg-aws-bundle.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610913Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610940Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610965Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.610991Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611017Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611043Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611071Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611099Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611125Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611152Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611179Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611205Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-aws-bundle;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611232Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611257Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611283Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611314Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611344Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.611372Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.613598Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found, unresolved dependency: org.apache.iceberg#iceberg-aws-bundle;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.613683Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.613716Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.613746Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.613775Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.613802Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.613830Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.613857Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.613883Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.613911Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.613940Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:12:40.684004","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":107,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:13:10.977075","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:13:12.037612Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:13.553388Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:14.194249Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:14.194416Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:14.211956Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:14.212250Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:14.212294Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-351d370a-a544-4a54-85b3-80fd699bfe0d;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:14.212335Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.487549Z","level":"error","event":"\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.503950Z","level":"error","event":":: resolution report :: resolve 4305ms :: artifacts dl 1ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.504128Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.508825Z","level":"error","event":"\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.508922Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.508958Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.508989Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509018Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509056Z","level":"error","event":"\t|      default     |   2   |   0   |   0   |   0   ||   1   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509084Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509112Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509141Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509169Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509200Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509228Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509255Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509286Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509320Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509356Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509385Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509413Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509440Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509466Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509491Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509518Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509544Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509571Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509597Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509623Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509649Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509675Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509700Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509726Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509751Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509780Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509807Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509833Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509858Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509884Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509909Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509935Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509961Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.509987Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510012Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510038Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510063Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510090Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510117Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510144Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510171Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510198Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510223Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510248Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510274Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510305Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510333Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510367Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510395Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510421Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510447Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510475Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510504Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510535Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510563Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510591Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510618Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510648Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510675Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510702Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510730Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.510758Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:18.587347","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":107,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:13:49.255155","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:13:49.543271Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:50.310458Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:50.374852Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:50.375050Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:50.379904Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:50.380025Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:50.380066Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-373ad3f8-4cc0-48b0-a228-3f778dd9048a;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:50.380100Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.164162Z","level":"error","event":"\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.173942Z","level":"error","event":":: resolution report :: resolve 2792ms :: artifacts dl 2ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.179602Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.179723Z","level":"error","event":"\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.179772Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.179803Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.179834Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.179862Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.179893Z","level":"error","event":"\t|      default     |   2   |   0   |   0   |   0   ||   1   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.179921Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.179950Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.179979Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180009Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180038Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180067Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180096Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180126Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180155Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180183Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180212Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180242Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180280Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180316Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180345Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180375Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180402Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180430Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180457Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180484Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180511Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180538Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180566Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180594Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180620Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180648Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180675Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180703Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180731Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180758Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180785Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180813Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180840Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180868Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180895Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180925Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180955Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.180982Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181023Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181055Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181090Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181124Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181151Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181183Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181210Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181239Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181267Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181303Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181334Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181362Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181395Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181435Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181470Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181500Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181530Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181557Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181586Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181613Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181640Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181669Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181723Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.181766Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:13:53.236689","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":107,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:14:24.077018","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:14:24.355959Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:25.086430Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:25.141510Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:25.141623Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:25.143836Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:25.145591Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:25.145669Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-081e0999-01e3-4c04-ba9c-348b5ae7876f;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:25.145706Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.075415Z","level":"error","event":"\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.088925Z","level":"error","event":":: resolution report :: resolve 2936ms :: artifacts dl 2ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089239Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089288Z","level":"error","event":"\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089336Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089380Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089415Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089444Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089484Z","level":"error","event":"\t|      default     |   2   |   0   |   0   |   0   ||   1   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089512Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089543Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089572Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089603Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089630Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089663Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089691Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089721Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089748Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089776Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089803Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089833Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089860Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089892Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089919Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089946Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089972Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.089999Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090025Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090055Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090084Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090113Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090140Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090170Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090197Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090227Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090254Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090281Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090319Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090362Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090392Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090420Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090451Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090483Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090510Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090538Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090564Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090591Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090620Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090649Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090678Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090706Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090735Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090764Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090791Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090818Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090847Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090874Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090903Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090929Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090956Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.090985Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.091019Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.091053Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.091083Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.091110Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.091141Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.091168Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.091195Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.091223Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.091251Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.091278Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:14:28.167512","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":107,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:15:46.285404","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:15:48.623283Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:48.711343Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:48.866899Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:48.885814Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:48.886036Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:48.886116Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:48.886178Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-0d4c63e2-7010-41cc-ab3d-c006a7be0295;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:48.886239Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.479954Z","level":"error","event":":: resolution report :: resolve 5603ms :: artifacts dl 0ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.483795Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.483900Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.483939Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.483972Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484004Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484032Z","level":"error","event":"\t|      default     |   2   |   0   |   0   |   0   ||   0   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484060Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484088Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484118Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484146Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484185Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484235Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484289Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484376Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484435Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484476Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484507Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484537Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484565Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484594Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484634Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484664Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484695Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484724Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484752Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484779Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484805Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484834Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484861Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484889Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484917Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484947Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.484975Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485003Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485030Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485056Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485083Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485110Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485138Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485165Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485193Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485220Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485247Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485274Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485311Z","level":"error","event":"\tproblem while downloading module descriptor: https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.pom: impossible to move part file to definitive one: /home/airflow/.ivy2.5.2/cache/org.apache.iceberg/iceberg-aws-bundle/ivy-1.9.2.xml.original.part -> /home/airflow/.ivy2.5.2/cache/org.apache.iceberg/iceberg-aws-bundle/ivy-1.9.2.xml.original (306ms)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485347Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485376Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-aws-bundle;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485405Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485432Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485459Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485486Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485513Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485540Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-aws-bundle;1.9.2!iceberg-aws-bundle.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485567Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485594Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485621Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485647Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485674Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485701Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-aws-bundle/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485728Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485754Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-aws-bundle;1.9.2!iceberg-aws-bundle.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485780Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485806Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-aws-bundle/1.9.2/jars/iceberg-aws-bundle.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485833Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485860Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485887Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485913Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485940Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485966Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.485992Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486019Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486045Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486075Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-aws-bundle;1.9.2!iceberg-aws-bundle.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486102Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486129Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486156Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486182Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486210Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486236Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486262Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486289Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486325Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486354Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486382Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486408Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-aws-bundle;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486436Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486464Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486491Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486518Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.486544Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488389Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488472Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found, unresolved dependency: org.apache.iceberg#iceberg-aws-bundle;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488510Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488547Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488576Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488605Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488633Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488661Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488694Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488722Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488751Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.488779Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:15:54.550354","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":70,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:16:24.995810","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:16:25.274057Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:26.084807Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:26.127623Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:26.127777Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:26.131616Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:26.131724Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:26.131759Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-6aac331b-484f-4816-83c9-c8037e056d5f;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:26.131790Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.217676Z","level":"error","event":"\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.233643Z","level":"error","event":":: resolution report :: resolve 3091ms :: artifacts dl 2ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.233909Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.233957Z","level":"error","event":"\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.233994Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234026Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234055Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234085Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234114Z","level":"error","event":"\t|      default     |   2   |   0   |   0   |   0   ||   1   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234146Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234175Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234210Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234241Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234270Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234307Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234336Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234366Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234396Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234425Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234453Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234480Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234510Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234538Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234567Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234597Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234626Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234655Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234682Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234715Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234745Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234775Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234802Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234833Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234860Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234891Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234919Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234946Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234972Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.234999Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235028Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235060Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235087Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235116Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235143Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235171Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235198Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235226Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235256Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235288Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235320Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235361Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235388Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235419Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235447Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235475Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235506Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235535Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235567Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235594Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235621Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235650Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235690Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235718Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235746Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235772Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235802Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235830Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235858Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235886Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235914Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.235941Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:16:29.281911","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":70,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:16:59.435010","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:16:59.766245Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:00.672151Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:00.719092Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:00.719249Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:00.723198Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:00.723326Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:00.723367Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-c393fd4c-e7ac-441a-a8fd-0042519bde54;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:00.723401Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.764464Z","level":"error","event":"\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.764860Z","level":"error","event":":: resolution report :: resolve 3020ms :: artifacts dl 2ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.764918Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.764955Z","level":"error","event":"\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.764990Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765031Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765064Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765094Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765127Z","level":"error","event":"\t|      default     |   2   |   0   |   0   |   0   ||   1   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765160Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765198Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765234Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765264Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765296Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765341Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765400Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765433Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765463Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765504Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765539Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765608Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765649Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765691Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765725Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765761Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765790Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765828Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765861Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765892Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765921Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765952Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.765984Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766014Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766041Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766075Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766104Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766135Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766164Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766197Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766226Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766259Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766308Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766345Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766382Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766415Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766449Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766480Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766513Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766546Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766575Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766605Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766635Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766664Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766691Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766725Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766758Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766787Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766816Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766846Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766873Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766901Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766944Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.766977Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.767013Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.767046Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.767081Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.767110Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.767141Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.767170Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.767200Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.767229Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:03.838809","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":70,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:17:34.639422","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:17:34.934969Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:35.741286Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:35.786452Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:35.786629Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:35.790184Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:35.790285Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:35.790331Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-f364b3ee-8536-440a-bcf9-dd0c2f19c676;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:35.790364Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.511350Z","level":"error","event":"\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.523855Z","level":"error","event":":: resolution report :: resolve 2730ms :: artifacts dl 3ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.524095Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530327Z","level":"error","event":"\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530458Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530499Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530530Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530561Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530589Z","level":"error","event":"\t|      default     |   2   |   0   |   0   |   0   ||   1   |   0   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530618Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530647Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530677Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530707Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530737Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530766Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530794Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530822Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530851Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530880Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530909Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530939Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530966Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.530994Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531024Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531053Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531082Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531110Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531137Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531177Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531207Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531237Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531266Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531295Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531335Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531365Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531394Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531422Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531450Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531478Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531507Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531538Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531566Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531595Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531623Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531652Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531681Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531709Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531737Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531766Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531793Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531823Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531851Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531879Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531908Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531937Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.531970Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532002Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532031Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532059Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532088Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532117Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532148Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532178Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532206Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532236Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532263Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532292Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532326Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532355Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532383Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.532411Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:17:38.633747","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"PySparkRuntimeError","exc_value":"[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":70,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":111,"name":"launch_gateway"}]}]}
{"timestamp":"2025-08-31T18:21:34.987532","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:21:37.473507Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:21:37.473629Z","level":"error","event":":: loading settings :: url = jar:file:/home/airflow/.local/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:21:37.495667Z","level":"error","event":"Ivy Default Cache set to: /home/airflow/.ivy2.5.2/cache","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:21:37.495885Z","level":"error","event":"The jars for the packages stored in: /home/airflow/.ivy2.5.2/jars","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:21:37.503128Z","level":"error","event":"org.apache.iceberg#iceberg-spark-runtime-4.0_2.13 added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:21:37.509737Z","level":"error","event":"org.apache.iceberg#iceberg-aws-bundle added as a dependency","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:21:37.509964Z","level":"error","event":":: resolving dependencies :: org.apache.spark#spark-submit-parent-042e1cb4-7662-4c23-82d9-e19b030a9898;1.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:21:37.510043Z","level":"error","event":"\tconfs: [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:21:41.748145Z","level":"error","event":"\tfound org.apache.iceberg#iceberg-aws-bundle;1.9.2 in central","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:21:42.009969Z","level":"error","event":"downloading https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.9.2/iceberg-aws-bundle-1.9.2.jar ...","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:04.988614","level":"error","event":"Process timed out, PID: 35","logger":"airflow.utils.timeout.TimeoutPosix"}
{"timestamp":"2025-08-31T18:22:04.996844","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"AirflowTaskTimeout","exc_value":"DagBag import timeout for /opt/airflow/dags/etl_data_weather.py after 30.0s.\nPlease take a look at these docs to improve your DAG import time:\n* https://airflow.apache.org/docs/apache-airflow/3.0.0/best-practices.html#top-level-python-code\n* https://airflow.apache.org/docs/apache-airflow/3.0.0/best-practices.html#reducing-dag-complexity, PID: 35","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":70,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":108,"name":"launch_gateway"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py","lineno":69,"name":"handle_timeout"}]}]}
{"timestamp":"2025-08-31T18:22:11.907253Z","level":"error","event":"\t[SUCCESSFUL ] org.apache.iceberg#iceberg-aws-bundle;1.9.2!iceberg-aws-bundle.jar (30150ms)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911473Z","level":"error","event":":: resolution report :: resolve 4250ms :: artifacts dl 30153ms","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911578Z","level":"error","event":"\t:: modules in use:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911616Z","level":"error","event":"\torg.apache.iceberg#iceberg-aws-bundle;1.9.2 from central in [default]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911652Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911683Z","level":"error","event":"\t|                  |            modules            ||   artifacts   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911713Z","level":"error","event":"\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911744Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911773Z","level":"error","event":"\t|      default     |   2   |   1   |   1   |   0   ||   1   |   1   |","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911802Z","level":"error","event":"\t---------------------------------------------------------------------","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911831Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911861Z","level":"error","event":":: problems summary ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911890Z","level":"error","event":":::: WARNINGS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911920Z","level":"error","event":"\t\tmodule not found: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911951Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.911982Z","level":"error","event":"\t==== local-m2-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912012Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912041Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912072Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912101Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912131Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912161Z","level":"error","event":"\t  file:/home/airflow/.m2/repository/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912190Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912218Z","level":"error","event":"\t==== local-ivy-cache: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912246Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912277Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/ivys/ivy.xml","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912324Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912374Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912403Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912431Z","level":"error","event":"\t  /home/airflow/.ivy2.5.2/local/org.apache.iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/jars/iceberg-spark-runtime-4.0_2.13.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912459Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912488Z","level":"error","event":"\t==== central: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912516Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912544Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912572Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912601Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912631Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912660Z","level":"error","event":"\t  https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912690Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912718Z","level":"error","event":"\t==== spark-packages: tried","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912747Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912776Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.pom","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912805Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912835Z","level":"error","event":"\t  -- artifact org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2!iceberg-spark-runtime-4.0_2.13.jar:","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912865Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912894Z","level":"error","event":"\t  https://repos.spark-packages.org/org/apache/iceberg/iceberg-spark-runtime-4.0_2.13/1.9.2/iceberg-spark-runtime-4.0_2.13-1.9.2.jar","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912922Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912950Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.912979Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.913008Z","level":"error","event":"\t\t::          UNRESOLVED DEPENDENCIES         ::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.913036Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.913064Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.913097Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.913127Z","level":"error","event":"\t\t:: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.913156Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.913183Z","level":"error","event":"\t\t::::::::::::::::::::::::::::::::::::::::::::::","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.913212Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.913239Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.913267Z","level":"error","event":"","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.913293Z","level":"error","event":":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.916320Z","level":"error","event":"Exception in thread \"main\" java.lang.RuntimeException: [unresolved dependency: org.apache.iceberg#iceberg-spark-runtime-4.0_2.13;1.9.2: not found]","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.916428Z","level":"error","event":"\tat org.apache.spark.util.MavenUtils$.resolveMavenCoordinates(MavenUtils.scala:540)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.916465Z","level":"error","event":"\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:123)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.916498Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:341)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.916529Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.916559Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.916589Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.916617Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.916647Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.916676Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:22:11.916704Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:30.680377","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:24:33.612430Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:33.955511Z","level":"error","event":"25/08/31 18:24:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.260427Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.266636Z","level":"error","event":"25/08/31 18:24:34 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.266880Z","level":"error","event":"25/08/31 18:24:34 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.670042Z","level":"error","event":"25/08/31 18:24:34 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.670106Z","level":"error","event":"25/08/31 18:24:34 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.670162Z","level":"error","event":"25/08/31 18:24:34 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.698905Z","level":"error","event":"25/08/31 18:24:34 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.704351Z","level":"error","event":"25/08/31 18:24:34 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.704553Z","level":"error","event":"25/08/31 18:24:34 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.704619Z","level":"error","event":"25/08/31 18:24:34 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.744627Z","level":"error","event":"25/08/31 18:24:34 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.750634Z","level":"error","event":"25/08/31 18:24:34 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.750830Z","level":"error","event":"25/08/31 18:24:34 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.834205Z","level":"error","event":"25/08/31 18:24:34 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.834446Z","level":"error","event":"25/08/31 18:24:34 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.834527Z","level":"error","event":"25/08/31 18:24:34 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.834591Z","level":"error","event":"25/08/31 18:24:34 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:34.845841Z","level":"error","event":"25/08/31 18:24:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.307463Z","level":"error","event":"25/08/31 18:24:35 INFO Utils: Successfully started service 'sparkDriver' on port 46791.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.351701Z","level":"error","event":"25/08/31 18:24:35 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.367522Z","level":"error","event":"25/08/31 18:24:35 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.403943Z","level":"error","event":"25/08/31 18:24:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.404138Z","level":"error","event":"25/08/31 18:24:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.411424Z","level":"error","event":"25/08/31 18:24:35 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.447833Z","level":"error","event":"25/08/31 18:24:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a9eb4dd7-4d79-4a90-b125-2a0f7d4a0812","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.486504Z","level":"error","event":"25/08/31 18:24:35 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.695749Z","level":"error","event":"25/08/31 18:24:35 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.826244Z","level":"error","event":"25/08/31 18:24:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.845361Z","level":"error","event":"25/08/31 18:24:35 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.939707Z","level":"error","event":"25/08/31 18:24:35 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:46791/jars/hadoop-aws-3.3.6.jar with timestamp 1756664674651","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.939935Z","level":"error","event":"25/08/31 18:24:35 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:46791/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664674651","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940019Z","level":"error","event":"25/08/31 18:24:35 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:46791/jars/ojdbc11.jar with timestamp 1756664674651","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940084Z","level":"error","event":"25/08/31 18:24:35 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940143Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940199Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940257Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940328Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940385Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940444Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940501Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940554Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940623Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940702Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940757Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940810Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940864Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940920Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.940976Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.941031Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.941084Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.941136Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.941193Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.941250Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.945828Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.945998Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946071Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946129Z","level":"error","event":"25/08/31 18:24:35 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946187Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946244Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946313Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946374Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946431Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946488Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946562Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946619Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946673Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946730Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946789Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946849Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946909Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.946970Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.947034Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.947093Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.947153Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.947209Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.947291Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.960435Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.960618Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.960686Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.960741Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.969035Z","level":"error","event":"25/08/31 18:24:35 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.974597Z","level":"error","event":"25/08/31 18:24:35 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.974782Z","level":"error","event":"25/08/31 18:24:35 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.974844Z","level":"error","event":"25/08/31 18:24:35 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:35.974896Z","level":"error","event":"25/08/31 18:24:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:36.116434Z","level":"error","event":"25/08/31 18:24:36 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:36.116757Z","level":"error","event":"25/08/31 18:24:36 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:36.116868Z","level":"error","event":"25/08/31 18:24:36 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:36.132532Z","level":"error","event":"25/08/31 18:24:36 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:36.140973Z","level":"error","event":"25/08/31 18:24:36 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@141a8777 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:36.152516Z","level":"error","event":"25/08/31 18:24:36 INFO Executor: Fetching spark://6548a13336e4:46791/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664674651","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:36.225215Z","level":"error","event":"25/08/31 18:24:36 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:46791 after 31 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:36.231759Z","level":"error","event":"25/08/31 18:24:36 INFO Utils: Fetching spark://6548a13336e4:46791/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-7ba4f1b0-ab97-4ed3-b6c0-79b55206a66a/userFiles-7a13cac1-42d8-4e26-9fe2-16e2e9b634b9/fetchFileTemp2047827526867345613.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:37.494767Z","level":"error","event":"25/08/31 18:24:37 INFO Executor: Adding file:/tmp/spark-7ba4f1b0-ab97-4ed3-b6c0-79b55206a66a/userFiles-7a13cac1-42d8-4e26-9fe2-16e2e9b634b9/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:37.495102Z","level":"error","event":"25/08/31 18:24:37 INFO Executor: Fetching spark://6548a13336e4:46791/jars/hadoop-aws-3.3.6.jar with timestamp 1756664674651","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:37.506459Z","level":"error","event":"25/08/31 18:24:37 INFO Utils: Fetching spark://6548a13336e4:46791/jars/hadoop-aws-3.3.6.jar to /tmp/spark-7ba4f1b0-ab97-4ed3-b6c0-79b55206a66a/userFiles-7a13cac1-42d8-4e26-9fe2-16e2e9b634b9/fetchFileTemp11270524044074805482.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:37.512649Z","level":"error","event":"25/08/31 18:24:37 INFO Executor: Adding file:/tmp/spark-7ba4f1b0-ab97-4ed3-b6c0-79b55206a66a/userFiles-7a13cac1-42d8-4e26-9fe2-16e2e9b634b9/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:37.528457Z","level":"error","event":"25/08/31 18:24:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41221.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:37.528789Z","level":"error","event":"25/08/31 18:24:37 INFO NettyBlockTransferService: Server created on 6548a13336e4:41221","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:37.535957Z","level":"error","event":"25/08/31 18:24:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:37.562603Z","level":"error","event":"25/08/31 18:24:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 41221, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:37.591339Z","level":"error","event":"25/08/31 18:24:37 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:41221 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 41221, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:37.620711Z","level":"error","event":"25/08/31 18:24:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 41221, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:37.640542Z","level":"error","event":"25/08/31 18:24:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 41221, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013037Z","level":"error","event":"25/08/31 18:24:38 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013208Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013253Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013287Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013327Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013358Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013387Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013415Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013443Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013472Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013499Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013527Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013555Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013583Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013611Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013640Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013668Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013696Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013733Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013762Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013791Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013818Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013846Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013874Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013901Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013930Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013958Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.013986Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.014013Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.014041Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:38.014069Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.695817Z","level":"error","event":"25/08/31 18:24:39 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.698556Z","level":"error","event":"25/08/31 18:24:39 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.706154Z","level":"error","event":"25/08/31 18:24:39 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.714322Z","level":"error","event":"25/08/31 18:24:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.724914Z","level":"error","event":"25/08/31 18:24:39 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.727787Z","level":"error","event":"25/08/31 18:24:39 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.727886Z","level":"error","event":"25/08/31 18:24:39 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.731018Z","level":"error","event":"25/08/31 18:24:39 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.735052Z","level":"error","event":"25/08/31 18:24:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.789936Z","level":"error","event":"25/08/31 18:24:39 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.795241Z","level":"error","event":"25/08/31 18:24:39 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.795425Z","level":"error","event":"25/08/31 18:24:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-474fc2db-ead2-4f72-9167-4d3b00f79a9f","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.795467Z","level":"error","event":"25/08/31 18:24:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-7ba4f1b0-ab97-4ed3-b6c0-79b55206a66a/pyspark-8614b9a8-6ca1-4f94-aa25-dadfa01c7fae","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:24:39.800832Z","level":"error","event":"25/08/31 18:24:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-7ba4f1b0-ab97-4ed3-b6c0-79b55206a66a","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:10.579356","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:25:10.864946Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:11.975239Z","level":"error","event":"25/08/31 18:25:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.127222Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.130148Z","level":"error","event":"25/08/31 18:25:12 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.132124Z","level":"error","event":"25/08/31 18:25:12 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.251888Z","level":"error","event":"25/08/31 18:25:12 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.255352Z","level":"error","event":"25/08/31 18:25:12 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.255484Z","level":"error","event":"25/08/31 18:25:12 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.281781Z","level":"error","event":"25/08/31 18:25:12 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.290182Z","level":"error","event":"25/08/31 18:25:12 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.290383Z","level":"error","event":"25/08/31 18:25:12 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.290453Z","level":"error","event":"25/08/31 18:25:12 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.313668Z","level":"error","event":"25/08/31 18:25:12 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.318603Z","level":"error","event":"25/08/31 18:25:12 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.322487Z","level":"error","event":"25/08/31 18:25:12 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.366213Z","level":"error","event":"25/08/31 18:25:12 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.371639Z","level":"error","event":"25/08/31 18:25:12 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.371805Z","level":"error","event":"25/08/31 18:25:12 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.371842Z","level":"error","event":"25/08/31 18:25:12 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.371875Z","level":"error","event":"25/08/31 18:25:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.564684Z","level":"error","event":"25/08/31 18:25:12 INFO Utils: Successfully started service 'sparkDriver' on port 33797.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.591155Z","level":"error","event":"25/08/31 18:25:12 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.606182Z","level":"error","event":"25/08/31 18:25:12 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.622109Z","level":"error","event":"25/08/31 18:25:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.626670Z","level":"error","event":"25/08/31 18:25:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.626862Z","level":"error","event":"25/08/31 18:25:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.646909Z","level":"error","event":"25/08/31 18:25:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-be3ae23f-41e2-42a1-9f6c-55f8d187033c","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.668799Z","level":"error","event":"25/08/31 18:25:12 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.789910Z","level":"error","event":"25/08/31 18:25:12 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.907437Z","level":"error","event":"25/08/31 18:25:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.953743Z","level":"error","event":"25/08/31 18:25:12 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:33797/jars/hadoop-aws-3.3.6.jar with timestamp 1756664712248","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.959425Z","level":"error","event":"25/08/31 18:25:12 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:33797/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664712248","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.959651Z","level":"error","event":"25/08/31 18:25:12 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:33797/jars/ojdbc11.jar with timestamp 1756664712248","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.959730Z","level":"error","event":"25/08/31 18:25:12 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.959790Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.959843Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.959896Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.959948Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960001Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960056Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960110Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960161Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960212Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960262Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960328Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960382Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960436Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960492Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960545Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960598Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960655Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960710Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960764Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960818Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960892Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960945Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.960999Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961053Z","level":"error","event":"25/08/31 18:25:12 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961107Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961156Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961207Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961260Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961338Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961391Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961441Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961487Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961540Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961594Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961644Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961693Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961740Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961792Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961843Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961894Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.961942Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.962006Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.962060Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.962109Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.962159Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.968122Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.968356Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.981368Z","level":"error","event":"25/08/31 18:25:12 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.985236Z","level":"error","event":"25/08/31 18:25:12 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.985402Z","level":"error","event":"25/08/31 18:25:12 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.985472Z","level":"error","event":"25/08/31 18:25:12 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:12.985526Z","level":"error","event":"25/08/31 18:25:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:13.097263Z","level":"error","event":"25/08/31 18:25:13 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:13.101333Z","level":"error","event":"25/08/31 18:25:13 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:13.101516Z","level":"error","event":"25/08/31 18:25:13 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:13.111542Z","level":"error","event":"25/08/31 18:25:13 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:13.115801Z","level":"error","event":"25/08/31 18:25:13 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@393da68f for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:13.124989Z","level":"error","event":"25/08/31 18:25:13 INFO Executor: Fetching spark://6548a13336e4:33797/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664712248","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:13.170028Z","level":"error","event":"25/08/31 18:25:13 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:33797 after 20 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:13.177140Z","level":"error","event":"25/08/31 18:25:13 INFO Utils: Fetching spark://6548a13336e4:33797/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-cc0e4726-b276-4731-9b77-1a012aaa385a/userFiles-f3ab5488-1c9f-4330-b3ee-408056270a8c/fetchFileTemp7707523620589824579.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.075018Z","level":"error","event":"25/08/31 18:25:14 INFO Executor: Adding file:/tmp/spark-cc0e4726-b276-4731-9b77-1a012aaa385a/userFiles-f3ab5488-1c9f-4330-b3ee-408056270a8c/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.080087Z","level":"error","event":"25/08/31 18:25:14 INFO Executor: Fetching spark://6548a13336e4:33797/jars/hadoop-aws-3.3.6.jar with timestamp 1756664712248","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.080232Z","level":"error","event":"25/08/31 18:25:14 INFO Utils: Fetching spark://6548a13336e4:33797/jars/hadoop-aws-3.3.6.jar to /tmp/spark-cc0e4726-b276-4731-9b77-1a012aaa385a/userFiles-f3ab5488-1c9f-4330-b3ee-408056270a8c/fetchFileTemp9781635742437744501.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.083354Z","level":"error","event":"25/08/31 18:25:14 INFO Executor: Adding file:/tmp/spark-cc0e4726-b276-4731-9b77-1a012aaa385a/userFiles-f3ab5488-1c9f-4330-b3ee-408056270a8c/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.099425Z","level":"error","event":"25/08/31 18:25:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45295.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.103330Z","level":"error","event":"25/08/31 18:25:14 INFO NettyBlockTransferService: Server created on 6548a13336e4:45295","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.103478Z","level":"error","event":"25/08/31 18:25:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.128683Z","level":"error","event":"25/08/31 18:25:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 45295, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.139858Z","level":"error","event":"25/08/31 18:25:14 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:45295 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 45295, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.142697Z","level":"error","event":"25/08/31 18:25:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 45295, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.147093Z","level":"error","event":"25/08/31 18:25:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 45295, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.450969Z","level":"error","event":"25/08/31 18:25:14 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451140Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451187Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451222Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451253Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451282Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451328Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451359Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451400Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451432Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451462Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451492Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451523Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451555Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451587Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451619Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451654Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451684Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451716Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451748Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451778Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451807Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451835Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451864Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451894Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451923Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451953Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.451982Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.452010Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.452042Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:14.452073Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.860305Z","level":"error","event":"25/08/31 18:25:15 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.862834Z","level":"error","event":"25/08/31 18:25:15 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.868827Z","level":"error","event":"25/08/31 18:25:15 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.876544Z","level":"error","event":"25/08/31 18:25:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.887042Z","level":"error","event":"25/08/31 18:25:15 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.889353Z","level":"error","event":"25/08/31 18:25:15 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.889461Z","level":"error","event":"25/08/31 18:25:15 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.893915Z","level":"error","event":"25/08/31 18:25:15 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.897274Z","level":"error","event":"25/08/31 18:25:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.943251Z","level":"error","event":"25/08/31 18:25:15 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.945987Z","level":"error","event":"25/08/31 18:25:15 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.946095Z","level":"error","event":"25/08/31 18:25:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-cc0e4726-b276-4731-9b77-1a012aaa385a/pyspark-955ccf55-b391-42be-adb7-802ec9b0f432","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.947867Z","level":"error","event":"25/08/31 18:25:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-296b938e-2081-40aa-9643-5b565706a5f9","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:15.949973Z","level":"error","event":"25/08/31 18:25:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-cc0e4726-b276-4731-9b77-1a012aaa385a","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:47.090978","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:25:47.582449Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:48.845219Z","level":"error","event":"25/08/31 18:25:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.028416Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.031606Z","level":"error","event":"25/08/31 18:25:49 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.034637Z","level":"error","event":"25/08/31 18:25:49 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.198493Z","level":"error","event":"25/08/31 18:25:49 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.202400Z","level":"error","event":"25/08/31 18:25:49 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.202540Z","level":"error","event":"25/08/31 18:25:49 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.227527Z","level":"error","event":"25/08/31 18:25:49 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.233335Z","level":"error","event":"25/08/31 18:25:49 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.233581Z","level":"error","event":"25/08/31 18:25:49 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.233673Z","level":"error","event":"25/08/31 18:25:49 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.258892Z","level":"error","event":"25/08/31 18:25:49 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.264246Z","level":"error","event":"25/08/31 18:25:49 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.264416Z","level":"error","event":"25/08/31 18:25:49 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.322666Z","level":"error","event":"25/08/31 18:25:49 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.329995Z","level":"error","event":"25/08/31 18:25:49 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.330427Z","level":"error","event":"25/08/31 18:25:49 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.330538Z","level":"error","event":"25/08/31 18:25:49 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.336644Z","level":"error","event":"25/08/31 18:25:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.625886Z","level":"error","event":"25/08/31 18:25:49 INFO Utils: Successfully started service 'sparkDriver' on port 37545.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.647264Z","level":"error","event":"25/08/31 18:25:49 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.655459Z","level":"error","event":"25/08/31 18:25:49 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.668380Z","level":"error","event":"25/08/31 18:25:49 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.671570Z","level":"error","event":"25/08/31 18:25:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.671692Z","level":"error","event":"25/08/31 18:25:49 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.686487Z","level":"error","event":"25/08/31 18:25:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dc42f3f1-04d5-4dcb-98a9-ef7fb1748e7a","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.701893Z","level":"error","event":"25/08/31 18:25:49 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.803673Z","level":"error","event":"25/08/31 18:25:49 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.876360Z","level":"error","event":"25/08/31 18:25:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.910038Z","level":"error","event":"25/08/31 18:25:49 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:37545/jars/hadoop-aws-3.3.6.jar with timestamp 1756664749193","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.916560Z","level":"error","event":"25/08/31 18:25:49 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:37545/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664749193","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.916771Z","level":"error","event":"25/08/31 18:25:49 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:37545/jars/ojdbc11.jar with timestamp 1756664749193","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.916848Z","level":"error","event":"25/08/31 18:25:49 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.916911Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.916969Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917034Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917092Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917148Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917206Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917261Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917337Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917397Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917460Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917535Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917597Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917655Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917712Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917764Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917824Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917887Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.917947Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918012Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918071Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918133Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918198Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918260Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918340Z","level":"error","event":"25/08/31 18:25:49 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918401Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918460Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918516Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918570Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918625Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918679Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918736Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918793Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918870Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918933Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.918994Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.919043Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.919097Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.919147Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.919198Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.919250Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.919326Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.919383Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.919439Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.919497Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.919545Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.925249Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.925405Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.938544Z","level":"error","event":"25/08/31 18:25:49 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.938617Z","level":"error","event":"25/08/31 18:25:49 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.945331Z","level":"error","event":"25/08/31 18:25:49 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.945543Z","level":"error","event":"25/08/31 18:25:49 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:49.945636Z","level":"error","event":"25/08/31 18:25:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.056660Z","level":"error","event":"25/08/31 18:25:50 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.061983Z","level":"error","event":"25/08/31 18:25:50 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.062196Z","level":"error","event":"25/08/31 18:25:50 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.077628Z","level":"error","event":"25/08/31 18:25:50 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.077725Z","level":"error","event":"25/08/31 18:25:50 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3cf8a601 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.091772Z","level":"error","event":"25/08/31 18:25:50 INFO Executor: Fetching spark://6548a13336e4:37545/jars/hadoop-aws-3.3.6.jar with timestamp 1756664749193","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.142102Z","level":"error","event":"25/08/31 18:25:50 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:37545 after 21 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.147213Z","level":"error","event":"25/08/31 18:25:50 INFO Utils: Fetching spark://6548a13336e4:37545/jars/hadoop-aws-3.3.6.jar to /tmp/spark-e34248de-ff56-40c6-ac7d-db5ab2596773/userFiles-b90e9973-92ac-4ca9-b6a6-0f61c4d6592a/fetchFileTemp10954035946357333949.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.175177Z","level":"error","event":"25/08/31 18:25:50 INFO Executor: Adding file:/tmp/spark-e34248de-ff56-40c6-ac7d-db5ab2596773/userFiles-b90e9973-92ac-4ca9-b6a6-0f61c4d6592a/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.181799Z","level":"error","event":"25/08/31 18:25:50 INFO Executor: Fetching spark://6548a13336e4:37545/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664749193","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.181983Z","level":"error","event":"25/08/31 18:25:50 INFO Utils: Fetching spark://6548a13336e4:37545/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-e34248de-ff56-40c6-ac7d-db5ab2596773/userFiles-b90e9973-92ac-4ca9-b6a6-0f61c4d6592a/fetchFileTemp14500579789869476071.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.934650Z","level":"error","event":"25/08/31 18:25:50 INFO Executor: Adding file:/tmp/spark-e34248de-ff56-40c6-ac7d-db5ab2596773/userFiles-b90e9973-92ac-4ca9-b6a6-0f61c4d6592a/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.941353Z","level":"error","event":"25/08/31 18:25:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32815.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.946061Z","level":"error","event":"25/08/31 18:25:50 INFO NettyBlockTransferService: Server created on 6548a13336e4:32815","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.946258Z","level":"error","event":"25/08/31 18:25:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.955371Z","level":"error","event":"25/08/31 18:25:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 32815, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.960966Z","level":"error","event":"25/08/31 18:25:50 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:32815 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 32815, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.964205Z","level":"error","event":"25/08/31 18:25:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 32815, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:50.967871Z","level":"error","event":"25/08/31 18:25:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 32815, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254199Z","level":"error","event":"25/08/31 18:25:51 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254384Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254436Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254466Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254496Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254524Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254552Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254580Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254607Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254633Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254660Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254687Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254714Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254741Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254783Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254810Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254839Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254867Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254895Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254933Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254962Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.254990Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.255017Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.255045Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.255072Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.255100Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.255128Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.255156Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.255183Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.255210Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:51.255237Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.907294Z","level":"error","event":"25/08/31 18:25:52 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.911294Z","level":"error","event":"25/08/31 18:25:52 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.917318Z","level":"error","event":"25/08/31 18:25:52 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.926644Z","level":"error","event":"25/08/31 18:25:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.942464Z","level":"error","event":"25/08/31 18:25:52 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.946122Z","level":"error","event":"25/08/31 18:25:52 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.946239Z","level":"error","event":"25/08/31 18:25:52 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.948813Z","level":"error","event":"25/08/31 18:25:52 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.952414Z","level":"error","event":"25/08/31 18:25:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.997155Z","level":"error","event":"25/08/31 18:25:52 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.997267Z","level":"error","event":"25/08/31 18:25:52 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.997315Z","level":"error","event":"25/08/31 18:25:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-e34248de-ff56-40c6-ac7d-db5ab2596773/pyspark-4d6b49b4-b551-4df6-9a90-b5ac15cd5614","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:52.999851Z","level":"error","event":"25/08/31 18:25:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-5cd306e1-8628-4106-9058-2004db629278","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:25:53.002711Z","level":"error","event":"25/08/31 18:25:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-e34248de-ff56-40c6-ac7d-db5ab2596773","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:24.193426","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:26:24.459001Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.527666Z","level":"error","event":"25/08/31 18:26:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.675519Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.679815Z","level":"error","event":"25/08/31 18:26:25 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.679959Z","level":"error","event":"25/08/31 18:26:25 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.860855Z","level":"error","event":"25/08/31 18:26:25 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.863998Z","level":"error","event":"25/08/31 18:26:25 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.864104Z","level":"error","event":"25/08/31 18:26:25 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.882931Z","level":"error","event":"25/08/31 18:26:25 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.887963Z","level":"error","event":"25/08/31 18:26:25 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.888123Z","level":"error","event":"25/08/31 18:26:25 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.888193Z","level":"error","event":"25/08/31 18:26:25 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.904469Z","level":"error","event":"25/08/31 18:26:25 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.909462Z","level":"error","event":"25/08/31 18:26:25 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.909642Z","level":"error","event":"25/08/31 18:26:25 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.946474Z","level":"error","event":"25/08/31 18:26:25 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.951726Z","level":"error","event":"25/08/31 18:26:25 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.951901Z","level":"error","event":"25/08/31 18:26:25 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.951964Z","level":"error","event":"25/08/31 18:26:25 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:25.952019Z","level":"error","event":"25/08/31 18:26:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.137102Z","level":"error","event":"25/08/31 18:26:26 INFO Utils: Successfully started service 'sparkDriver' on port 36205.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.159181Z","level":"error","event":"25/08/31 18:26:26 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.169875Z","level":"error","event":"25/08/31 18:26:26 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.184206Z","level":"error","event":"25/08/31 18:26:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.190488Z","level":"error","event":"25/08/31 18:26:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.190733Z","level":"error","event":"25/08/31 18:26:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.205062Z","level":"error","event":"25/08/31 18:26:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50e10849-b883-429a-9dfa-cc768bb8615a","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.225777Z","level":"error","event":"25/08/31 18:26:26 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.324525Z","level":"error","event":"25/08/31 18:26:26 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.404242Z","level":"error","event":"25/08/31 18:26:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.452805Z","level":"error","event":"25/08/31 18:26:26 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:36205/jars/hadoop-aws-3.3.6.jar with timestamp 1756664785857","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.457921Z","level":"error","event":"25/08/31 18:26:26 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:36205/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664785857","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458090Z","level":"error","event":"25/08/31 18:26:26 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:36205/jars/ojdbc11.jar with timestamp 1756664785857","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458161Z","level":"error","event":"25/08/31 18:26:26 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458238Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458312Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458377Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458431Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458493Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458562Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458624Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458686Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458749Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458814Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458862Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458896Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458928Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458960Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.458993Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459030Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459063Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459095Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459132Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459165Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459199Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459257Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459334Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459391Z","level":"error","event":"25/08/31 18:26:26 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459450Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459504Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459559Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459620Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459685Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459747Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459813Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459866Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459906Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459939Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.459972Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.460004Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.460037Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.460073Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.460105Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.460139Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.460171Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.460201Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.460231Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.460277Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.460329Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.466076Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.466343Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.478243Z","level":"error","event":"25/08/31 18:26:26 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.483416Z","level":"error","event":"25/08/31 18:26:26 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.483589Z","level":"error","event":"25/08/31 18:26:26 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.483656Z","level":"error","event":"25/08/31 18:26:26 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.483717Z","level":"error","event":"25/08/31 18:26:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.576357Z","level":"error","event":"25/08/31 18:26:26 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.579801Z","level":"error","event":"25/08/31 18:26:26 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.579954Z","level":"error","event":"25/08/31 18:26:26 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.588713Z","level":"error","event":"25/08/31 18:26:26 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.592069Z","level":"error","event":"25/08/31 18:26:26 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3cf8a601 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.600697Z","level":"error","event":"25/08/31 18:26:26 INFO Executor: Fetching spark://6548a13336e4:36205/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664785857","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.638007Z","level":"error","event":"25/08/31 18:26:26 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:36205 after 18 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:26.642461Z","level":"error","event":"25/08/31 18:26:26 INFO Utils: Fetching spark://6548a13336e4:36205/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-e66949db-8ff3-402a-95d9-5dc8043e853c/userFiles-3b7ad718-3374-4bad-b040-e2d81ce8a86f/fetchFileTemp15620351023010950935.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.397756Z","level":"error","event":"25/08/31 18:26:27 INFO Executor: Adding file:/tmp/spark-e66949db-8ff3-402a-95d9-5dc8043e853c/userFiles-3b7ad718-3374-4bad-b040-e2d81ce8a86f/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.405094Z","level":"error","event":"25/08/31 18:26:27 INFO Executor: Fetching spark://6548a13336e4:36205/jars/hadoop-aws-3.3.6.jar with timestamp 1756664785857","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.405260Z","level":"error","event":"25/08/31 18:26:27 INFO Utils: Fetching spark://6548a13336e4:36205/jars/hadoop-aws-3.3.6.jar to /tmp/spark-e66949db-8ff3-402a-95d9-5dc8043e853c/userFiles-3b7ad718-3374-4bad-b040-e2d81ce8a86f/fetchFileTemp6090138136968973200.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.405339Z","level":"error","event":"25/08/31 18:26:27 INFO Executor: Adding file:/tmp/spark-e66949db-8ff3-402a-95d9-5dc8043e853c/userFiles-3b7ad718-3374-4bad-b040-e2d81ce8a86f/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.410205Z","level":"error","event":"25/08/31 18:26:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43331.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.414948Z","level":"error","event":"25/08/31 18:26:27 INFO NettyBlockTransferService: Server created on 6548a13336e4:43331","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.415112Z","level":"error","event":"25/08/31 18:26:27 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.430375Z","level":"error","event":"25/08/31 18:26:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 43331, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.435192Z","level":"error","event":"25/08/31 18:26:27 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:43331 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 43331, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.435230Z","level":"error","event":"25/08/31 18:26:27 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 43331, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.438229Z","level":"error","event":"25/08/31 18:26:27 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 43331, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685329Z","level":"error","event":"25/08/31 18:26:27 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685490Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685533Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685565Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685596Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685626Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685657Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685687Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685717Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685760Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685791Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685820Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685850Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685880Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685910Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685939Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685969Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.685999Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686028Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686058Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686088Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686119Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686148Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686176Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686205Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686233Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686263Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686292Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686332Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686363Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:27.686390Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.054361Z","level":"error","event":"25/08/31 18:26:29 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.054460Z","level":"error","event":"25/08/31 18:26:29 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.061441Z","level":"error","event":"25/08/31 18:26:29 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.068693Z","level":"error","event":"25/08/31 18:26:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.078375Z","level":"error","event":"25/08/31 18:26:29 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.081198Z","level":"error","event":"25/08/31 18:26:29 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.081295Z","level":"error","event":"25/08/31 18:26:29 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.083417Z","level":"error","event":"25/08/31 18:26:29 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.086444Z","level":"error","event":"25/08/31 18:26:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.125847Z","level":"error","event":"25/08/31 18:26:29 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.128951Z","level":"error","event":"25/08/31 18:26:29 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.129060Z","level":"error","event":"25/08/31 18:26:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-e66949db-8ff3-402a-95d9-5dc8043e853c","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.131244Z","level":"error","event":"25/08/31 18:26:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-36ee18ae-de3d-4a16-9ba9-56d4ebb22c5b","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:26:29.133285Z","level":"error","event":"25/08/31 18:26:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-e66949db-8ff3-402a-95d9-5dc8043e853c/pyspark-5ed9033f-8002-4327-8e18-23b6f5f71238","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:00.060823","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:27:00.367163Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:01.731787Z","level":"error","event":"25/08/31 18:27:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:01.896932Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:01.900259Z","level":"error","event":"25/08/31 18:27:01 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:01.903419Z","level":"error","event":"25/08/31 18:27:01 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.029468Z","level":"error","event":"25/08/31 18:27:02 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.032939Z","level":"error","event":"25/08/31 18:27:02 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.033058Z","level":"error","event":"25/08/31 18:27:02 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.056151Z","level":"error","event":"25/08/31 18:27:02 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.056351Z","level":"error","event":"25/08/31 18:27:02 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.056428Z","level":"error","event":"25/08/31 18:27:02 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.056486Z","level":"error","event":"25/08/31 18:27:02 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.079265Z","level":"error","event":"25/08/31 18:27:02 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.085375Z","level":"error","event":"25/08/31 18:27:02 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.085550Z","level":"error","event":"25/08/31 18:27:02 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.141202Z","level":"error","event":"25/08/31 18:27:02 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.147278Z","level":"error","event":"25/08/31 18:27:02 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.147453Z","level":"error","event":"25/08/31 18:27:02 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.147494Z","level":"error","event":"25/08/31 18:27:02 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.154684Z","level":"error","event":"25/08/31 18:27:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.398215Z","level":"error","event":"25/08/31 18:27:02 INFO Utils: Successfully started service 'sparkDriver' on port 39991.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.418425Z","level":"error","event":"25/08/31 18:27:02 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.428470Z","level":"error","event":"25/08/31 18:27:02 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.443128Z","level":"error","event":"25/08/31 18:27:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.449550Z","level":"error","event":"25/08/31 18:27:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.449703Z","level":"error","event":"25/08/31 18:27:02 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.475998Z","level":"error","event":"25/08/31 18:27:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a6a03408-dd88-489b-b953-df97a373d011","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.499794Z","level":"error","event":"25/08/31 18:27:02 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.627007Z","level":"error","event":"25/08/31 18:27:02 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.745629Z","level":"error","event":"25/08/31 18:27:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.828827Z","level":"error","event":"25/08/31 18:27:02 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:39991/jars/hadoop-aws-3.3.6.jar with timestamp 1756664822025","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.848900Z","level":"error","event":"25/08/31 18:27:02 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:39991/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664822025","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849061Z","level":"error","event":"25/08/31 18:27:02 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:39991/jars/ojdbc11.jar with timestamp 1756664822025","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849106Z","level":"error","event":"25/08/31 18:27:02 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849150Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849189Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849224Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849257Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849292Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849339Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849374Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849411Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849477Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849541Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849606Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849695Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849781Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849857Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.849929Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850009Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850084Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850143Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850220Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850289Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850369Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850429Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850488Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850550Z","level":"error","event":"25/08/31 18:27:02 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850610Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850667Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850720Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850784Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850844Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850907Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.850963Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851016Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851084Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851160Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851215Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851268Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851335Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851395Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851449Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851501Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851550Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851604Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851655Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851710Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.851765Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.861676Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.861985Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.877770Z","level":"error","event":"25/08/31 18:27:02 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.878034Z","level":"error","event":"25/08/31 18:27:02 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.878085Z","level":"error","event":"25/08/31 18:27:02 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.878140Z","level":"error","event":"25/08/31 18:27:02 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:02.878202Z","level":"error","event":"25/08/31 18:27:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:03.088445Z","level":"error","event":"25/08/31 18:27:03 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:03.107622Z","level":"error","event":"25/08/31 18:27:03 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:03.107892Z","level":"error","event":"25/08/31 18:27:03 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:03.120621Z","level":"error","event":"25/08/31 18:27:03 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:03.133768Z","level":"error","event":"25/08/31 18:27:03 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3cf8a601 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:03.153420Z","level":"error","event":"25/08/31 18:27:03 INFO Executor: Fetching spark://6548a13336e4:39991/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664822025","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:03.260701Z","level":"error","event":"25/08/31 18:27:03 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:39991 after 75 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:03.268715Z","level":"error","event":"25/08/31 18:27:03 INFO Utils: Fetching spark://6548a13336e4:39991/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-71ab4b27-1176-4d19-968d-8f905e8368bb/userFiles-ad7b0f7b-e29b-49ad-8e8f-cf88ff39577d/fetchFileTemp11478804316583750423.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.295536Z","level":"error","event":"25/08/31 18:27:04 INFO Executor: Adding file:/tmp/spark-71ab4b27-1176-4d19-968d-8f905e8368bb/userFiles-ad7b0f7b-e29b-49ad-8e8f-cf88ff39577d/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.332177Z","level":"error","event":"25/08/31 18:27:04 INFO Executor: Fetching spark://6548a13336e4:39991/jars/hadoop-aws-3.3.6.jar with timestamp 1756664822025","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.332585Z","level":"error","event":"25/08/31 18:27:04 INFO Utils: Fetching spark://6548a13336e4:39991/jars/hadoop-aws-3.3.6.jar to /tmp/spark-71ab4b27-1176-4d19-968d-8f905e8368bb/userFiles-ad7b0f7b-e29b-49ad-8e8f-cf88ff39577d/fetchFileTemp11516769264980623162.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.332658Z","level":"error","event":"25/08/31 18:27:04 INFO Executor: Adding file:/tmp/spark-71ab4b27-1176-4d19-968d-8f905e8368bb/userFiles-ad7b0f7b-e29b-49ad-8e8f-cf88ff39577d/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.358510Z","level":"error","event":"25/08/31 18:27:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45589.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.358878Z","level":"error","event":"25/08/31 18:27:04 INFO NettyBlockTransferService: Server created on 6548a13336e4:45589","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.373716Z","level":"error","event":"25/08/31 18:27:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.402827Z","level":"error","event":"25/08/31 18:27:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 45589, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.415831Z","level":"error","event":"25/08/31 18:27:04 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:45589 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 45589, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.428263Z","level":"error","event":"25/08/31 18:27:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 45589, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.434711Z","level":"error","event":"25/08/31 18:27:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 45589, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933036Z","level":"error","event":"25/08/31 18:27:04 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933226Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933269Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933320Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933355Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933385Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933414Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933442Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933471Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933500Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933528Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933557Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933586Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933615Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933643Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933672Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933703Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933732Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933760Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933790Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933836Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933867Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933896Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933924Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933953Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.933983Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.934012Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.934040Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.934068Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.934096Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:04.934123Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.410040Z","level":"error","event":"25/08/31 18:27:06 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.413085Z","level":"error","event":"25/08/31 18:27:06 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.420442Z","level":"error","event":"25/08/31 18:27:06 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.428360Z","level":"error","event":"25/08/31 18:27:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.440096Z","level":"error","event":"25/08/31 18:27:06 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.444055Z","level":"error","event":"25/08/31 18:27:06 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.444174Z","level":"error","event":"25/08/31 18:27:06 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.448674Z","level":"error","event":"25/08/31 18:27:06 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.453453Z","level":"error","event":"25/08/31 18:27:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.493927Z","level":"error","event":"25/08/31 18:27:06 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.499559Z","level":"error","event":"25/08/31 18:27:06 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.499773Z","level":"error","event":"25/08/31 18:27:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-71ab4b27-1176-4d19-968d-8f905e8368bb/pyspark-082b43ab-a0dd-4e62-93a4-d6dd5143f03f","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.499847Z","level":"error","event":"25/08/31 18:27:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-db116cf5-cd3f-42e6-b7c1-bd6f9bcd34a8","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:06.504877Z","level":"error","event":"25/08/31 18:27:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-71ab4b27-1176-4d19-968d-8f905e8368bb","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:36.898959","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:27:37.160541Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.154225Z","level":"error","event":"25/08/31 18:27:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.296918Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.300679Z","level":"error","event":"25/08/31 18:27:38 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.303281Z","level":"error","event":"25/08/31 18:27:38 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.661988Z","level":"error","event":"25/08/31 18:27:38 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.665371Z","level":"error","event":"25/08/31 18:27:38 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.665491Z","level":"error","event":"25/08/31 18:27:38 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.687089Z","level":"error","event":"25/08/31 18:27:38 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.691354Z","level":"error","event":"25/08/31 18:27:38 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.691545Z","level":"error","event":"25/08/31 18:27:38 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.691620Z","level":"error","event":"25/08/31 18:27:38 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.712490Z","level":"error","event":"25/08/31 18:27:38 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.715699Z","level":"error","event":"25/08/31 18:27:38 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.717695Z","level":"error","event":"25/08/31 18:27:38 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.755685Z","level":"error","event":"25/08/31 18:27:38 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.758291Z","level":"error","event":"25/08/31 18:27:38 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.758413Z","level":"error","event":"25/08/31 18:27:38 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.758455Z","level":"error","event":"25/08/31 18:27:38 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.758487Z","level":"error","event":"25/08/31 18:27:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.914247Z","level":"error","event":"25/08/31 18:27:38 INFO Utils: Successfully started service 'sparkDriver' on port 45619.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.936199Z","level":"error","event":"25/08/31 18:27:38 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.946133Z","level":"error","event":"25/08/31 18:27:38 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.957577Z","level":"error","event":"25/08/31 18:27:38 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.960660Z","level":"error","event":"25/08/31 18:27:38 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.960789Z","level":"error","event":"25/08/31 18:27:38 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.975064Z","level":"error","event":"25/08/31 18:27:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c8abf109-7f10-4b84-8a87-20c3518a4bdd","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:38.992235Z","level":"error","event":"25/08/31 18:27:38 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.088965Z","level":"error","event":"25/08/31 18:27:39 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.149641Z","level":"error","event":"25/08/31 18:27:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.189789Z","level":"error","event":"25/08/31 18:27:39 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:45619/jars/hadoop-aws-3.3.6.jar with timestamp 1756664858658","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.196564Z","level":"error","event":"25/08/31 18:27:39 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:45619/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664858658","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.196766Z","level":"error","event":"25/08/31 18:27:39 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:45619/jars/ojdbc11.jar with timestamp 1756664858658","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.196827Z","level":"error","event":"25/08/31 18:27:39 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.196880Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.196947Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.196992Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197035Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197079Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197129Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197172Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197214Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197257Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197310Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197358Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197405Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197449Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197499Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197549Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197601Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197650Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197699Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197749Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197801Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197848Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197898Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.197952Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198024Z","level":"error","event":"25/08/31 18:27:39 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198073Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198121Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198169Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198218Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198265Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198330Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198380Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198428Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198476Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198521Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198575Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198627Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198673Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198723Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198772Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198821Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198869Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198917Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.198965Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.199012Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.199060Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.205172Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.205406Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.213140Z","level":"error","event":"25/08/31 18:27:39 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.219606Z","level":"error","event":"25/08/31 18:27:39 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.219871Z","level":"error","event":"25/08/31 18:27:39 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.219936Z","level":"error","event":"25/08/31 18:27:39 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.219991Z","level":"error","event":"25/08/31 18:27:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.314782Z","level":"error","event":"25/08/31 18:27:39 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.317683Z","level":"error","event":"25/08/31 18:27:39 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.317790Z","level":"error","event":"25/08/31 18:27:39 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.326881Z","level":"error","event":"25/08/31 18:27:39 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.330708Z","level":"error","event":"25/08/31 18:27:39 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5f8d356e for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.337110Z","level":"error","event":"25/08/31 18:27:39 INFO Executor: Fetching spark://6548a13336e4:45619/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664858658","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.379824Z","level":"error","event":"25/08/31 18:27:39 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:45619 after 20 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.385770Z","level":"error","event":"25/08/31 18:27:39 INFO Utils: Fetching spark://6548a13336e4:45619/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-d611c1fa-d025-4d34-b58c-3bb5e03efde7/userFiles-6d345897-0089-4d11-b616-90af8f725474/fetchFileTemp10713455242009132469.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.940667Z","level":"error","event":"25/08/31 18:27:39 INFO Executor: Adding file:/tmp/spark-d611c1fa-d025-4d34-b58c-3bb5e03efde7/userFiles-6d345897-0089-4d11-b616-90af8f725474/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.945742Z","level":"error","event":"25/08/31 18:27:39 INFO Executor: Fetching spark://6548a13336e4:45619/jars/hadoop-aws-3.3.6.jar with timestamp 1756664858658","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.945870Z","level":"error","event":"25/08/31 18:27:39 INFO Utils: Fetching spark://6548a13336e4:45619/jars/hadoop-aws-3.3.6.jar to /tmp/spark-d611c1fa-d025-4d34-b58c-3bb5e03efde7/userFiles-6d345897-0089-4d11-b616-90af8f725474/fetchFileTemp3982991673699110866.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.949732Z","level":"error","event":"25/08/31 18:27:39 INFO Executor: Adding file:/tmp/spark-d611c1fa-d025-4d34-b58c-3bb5e03efde7/userFiles-6d345897-0089-4d11-b616-90af8f725474/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.957138Z","level":"error","event":"25/08/31 18:27:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34489.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.962465Z","level":"error","event":"25/08/31 18:27:39 INFO NettyBlockTransferService: Server created on 6548a13336e4:34489","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.962610Z","level":"error","event":"25/08/31 18:27:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.973970Z","level":"error","event":"25/08/31 18:27:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 34489, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.980521Z","level":"error","event":"25/08/31 18:27:39 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:34489 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 34489, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.984503Z","level":"error","event":"25/08/31 18:27:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 34489, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:39.987918Z","level":"error","event":"25/08/31 18:27:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 34489, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.285666Z","level":"error","event":"25/08/31 18:27:40 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286086Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286227Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286280Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286348Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286391Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286436Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286482Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286527Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286572Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286621Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286679Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286728Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286772Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286815Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286860Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286903Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286949Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.286992Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287039Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287084Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287130Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287176Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287229Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287276Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287339Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287392Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287440Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287494Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287540Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:40.287583Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.835315Z","level":"error","event":"25/08/31 18:27:41 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.839676Z","level":"error","event":"25/08/31 18:27:41 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.846431Z","level":"error","event":"25/08/31 18:27:41 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.855509Z","level":"error","event":"25/08/31 18:27:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.870081Z","level":"error","event":"25/08/31 18:27:41 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.875008Z","level":"error","event":"25/08/31 18:27:41 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.875210Z","level":"error","event":"25/08/31 18:27:41 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.878944Z","level":"error","event":"25/08/31 18:27:41 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.879150Z","level":"error","event":"25/08/31 18:27:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.923845Z","level":"error","event":"25/08/31 18:27:41 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.928723Z","level":"error","event":"25/08/31 18:27:41 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.928896Z","level":"error","event":"25/08/31 18:27:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-620bd8fa-fae4-4d7f-806d-7bcc89a03ee5","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.934539Z","level":"error","event":"25/08/31 18:27:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-d611c1fa-d025-4d34-b58c-3bb5e03efde7/pyspark-01d66ad9-3e90-4b60-80cc-73d932f88196","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:27:41.934799Z","level":"error","event":"25/08/31 18:27:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-d611c1fa-d025-4d34-b58c-3bb5e03efde7","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:13.437401","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:28:15.405221Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:17.423862Z","level":"error","event":"25/08/31 18:28:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:17.687734Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:17.694499Z","level":"error","event":"25/08/31 18:28:17 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:17.694727Z","level":"error","event":"25/08/31 18:28:17 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:17.991060Z","level":"error","event":"25/08/31 18:28:17 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:17.999989Z","level":"error","event":"25/08/31 18:28:17 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.000227Z","level":"error","event":"25/08/31 18:28:17 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.041774Z","level":"error","event":"25/08/31 18:28:18 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.047317Z","level":"error","event":"25/08/31 18:28:18 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.047498Z","level":"error","event":"25/08/31 18:28:18 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.047563Z","level":"error","event":"25/08/31 18:28:18 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.094215Z","level":"error","event":"25/08/31 18:28:18 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.100737Z","level":"error","event":"25/08/31 18:28:18 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.105177Z","level":"error","event":"25/08/31 18:28:18 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.181404Z","level":"error","event":"25/08/31 18:28:18 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.187716Z","level":"error","event":"25/08/31 18:28:18 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.187901Z","level":"error","event":"25/08/31 18:28:18 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.187981Z","level":"error","event":"25/08/31 18:28:18 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.192441Z","level":"error","event":"25/08/31 18:28:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.554153Z","level":"error","event":"25/08/31 18:28:18 INFO Utils: Successfully started service 'sparkDriver' on port 39137.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.587250Z","level":"error","event":"25/08/31 18:28:18 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.602689Z","level":"error","event":"25/08/31 18:28:18 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.623485Z","level":"error","event":"25/08/31 18:28:18 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.631420Z","level":"error","event":"25/08/31 18:28:18 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.631692Z","level":"error","event":"25/08/31 18:28:18 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.651758Z","level":"error","event":"25/08/31 18:28:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50ed6356-bad7-428e-8073-3dc30ed1f32c","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.679739Z","level":"error","event":"25/08/31 18:28:18 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.855414Z","level":"error","event":"25/08/31 18:28:18 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.942279Z","level":"error","event":"25/08/31 18:28:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:18.953555Z","level":"error","event":"25/08/31 18:28:18 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.006294Z","level":"error","event":"25/08/31 18:28:19 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:39137/jars/hadoop-aws-3.3.6.jar with timestamp 1756664897982","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.013112Z","level":"error","event":"25/08/31 18:28:19 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:39137/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664897982","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.013364Z","level":"error","event":"25/08/31 18:28:19 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:39137/jars/ojdbc11.jar with timestamp 1756664897982","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.013488Z","level":"error","event":"25/08/31 18:28:19 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.013580Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.013674Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.013760Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.013850Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.013944Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.014034Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.014136Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.014232Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.014336Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.014419Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.014514Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.014601Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.014716Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.014818Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.014915Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.015013Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.015112Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.015203Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.015306Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.015407Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.015498Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.015585Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.015666Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.015766Z","level":"error","event":"25/08/31 18:28:19 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.015857Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.015951Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.016048Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.016139Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.016241Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.016357Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.016461Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.016553Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.016657Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.016751Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.016859Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.016950Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.017043Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.017135Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.017222Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.017310Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.017411Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.017507Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.017591Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.017675Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.017759Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.023921Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.024194Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.041519Z","level":"error","event":"25/08/31 18:28:19 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.049624Z","level":"error","event":"25/08/31 18:28:19 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.049892Z","level":"error","event":"25/08/31 18:28:19 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.050013Z","level":"error","event":"25/08/31 18:28:19 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.050109Z","level":"error","event":"25/08/31 18:28:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.207844Z","level":"error","event":"25/08/31 18:28:19 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.214261Z","level":"error","event":"25/08/31 18:28:19 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.214539Z","level":"error","event":"25/08/31 18:28:19 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.229223Z","level":"error","event":"25/08/31 18:28:19 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.236551Z","level":"error","event":"25/08/31 18:28:19 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3e946e1 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.252629Z","level":"error","event":"25/08/31 18:28:19 INFO Executor: Fetching spark://6548a13336e4:39137/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664897982","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.336475Z","level":"error","event":"25/08/31 18:28:19 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:39137 after 43 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:19.346514Z","level":"error","event":"25/08/31 18:28:19 INFO Utils: Fetching spark://6548a13336e4:39137/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-efb04796-bd85-458f-9b23-620344ea5302/userFiles-2d6b11ea-bc2a-4bde-886f-4ac2c837776c/fetchFileTemp435570056689735264.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.249805Z","level":"error","event":"25/08/31 18:28:20 INFO Executor: Adding file:/tmp/spark-efb04796-bd85-458f-9b23-620344ea5302/userFiles-2d6b11ea-bc2a-4bde-886f-4ac2c837776c/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.255984Z","level":"error","event":"25/08/31 18:28:20 INFO Executor: Fetching spark://6548a13336e4:39137/jars/hadoop-aws-3.3.6.jar with timestamp 1756664897982","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.256207Z","level":"error","event":"25/08/31 18:28:20 INFO Utils: Fetching spark://6548a13336e4:39137/jars/hadoop-aws-3.3.6.jar to /tmp/spark-efb04796-bd85-458f-9b23-620344ea5302/userFiles-2d6b11ea-bc2a-4bde-886f-4ac2c837776c/fetchFileTemp1826588805413436575.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.262222Z","level":"error","event":"25/08/31 18:28:20 INFO Executor: Adding file:/tmp/spark-efb04796-bd85-458f-9b23-620344ea5302/userFiles-2d6b11ea-bc2a-4bde-886f-4ac2c837776c/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.275885Z","level":"error","event":"25/08/31 18:28:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35191.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.283185Z","level":"error","event":"25/08/31 18:28:20 INFO NettyBlockTransferService: Server created on 6548a13336e4:35191","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.283441Z","level":"error","event":"25/08/31 18:28:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.296065Z","level":"error","event":"25/08/31 18:28:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 35191, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.305262Z","level":"error","event":"25/08/31 18:28:20 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:35191 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 35191, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.311376Z","level":"error","event":"25/08/31 18:28:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 35191, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.316848Z","level":"error","event":"25/08/31 18:28:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 35191, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.718013Z","level":"error","event":"25/08/31 18:28:20 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.718320Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.718522Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.718681Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.718785Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.718841Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.718901Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.718956Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719014Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719066Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719116Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719167Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719219Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719270Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719335Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719391Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719443Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719494Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719544Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719595Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719652Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719719Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719772Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719824Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719875Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719925Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.719977Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.720026Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.720069Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.720113Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:20.720159Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:22.887328Z","level":"error","event":"25/08/31 18:28:22 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:22.891622Z","level":"error","event":"25/08/31 18:28:22 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:22.904976Z","level":"error","event":"25/08/31 18:28:22 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:22.913585Z","level":"error","event":"25/08/31 18:28:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:22.929919Z","level":"error","event":"25/08/31 18:28:22 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:22.934720Z","level":"error","event":"25/08/31 18:28:22 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:22.934877Z","level":"error","event":"25/08/31 18:28:22 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:22.938946Z","level":"error","event":"25/08/31 18:28:22 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:22.943956Z","level":"error","event":"25/08/31 18:28:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:23.012014Z","level":"error","event":"25/08/31 18:28:23 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:23.016133Z","level":"error","event":"25/08/31 18:28:23 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:23.016272Z","level":"error","event":"25/08/31 18:28:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-efb04796-bd85-458f-9b23-620344ea5302","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:23.019500Z","level":"error","event":"25/08/31 18:28:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-efb04796-bd85-458f-9b23-620344ea5302/pyspark-fc3d31f1-d250-452f-8de9-f5273e683ac0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:23.023192Z","level":"error","event":"25/08/31 18:28:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-9081d6ef-169d-4666-8294-f9a853796ec0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:54.034791","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:28:54.633363Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:56.490062Z","level":"error","event":"25/08/31 18:28:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:56.730749Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:56.736414Z","level":"error","event":"25/08/31 18:28:56 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:56.736575Z","level":"error","event":"25/08/31 18:28:56 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:56.989047Z","level":"error","event":"25/08/31 18:28:56 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:56.997289Z","level":"error","event":"25/08/31 18:28:56 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:56.997447Z","level":"error","event":"25/08/31 18:28:56 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.023405Z","level":"error","event":"25/08/31 18:28:57 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.029071Z","level":"error","event":"25/08/31 18:28:57 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.029252Z","level":"error","event":"25/08/31 18:28:57 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.029335Z","level":"error","event":"25/08/31 18:28:57 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.057373Z","level":"error","event":"25/08/31 18:28:57 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.061960Z","level":"error","event":"25/08/31 18:28:57 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.065483Z","level":"error","event":"25/08/31 18:28:57 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.115846Z","level":"error","event":"25/08/31 18:28:57 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.120838Z","level":"error","event":"25/08/31 18:28:57 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.121001Z","level":"error","event":"25/08/31 18:28:57 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.121068Z","level":"error","event":"25/08/31 18:28:57 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.121129Z","level":"error","event":"25/08/31 18:28:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.398337Z","level":"error","event":"25/08/31 18:28:57 INFO Utils: Successfully started service 'sparkDriver' on port 35881.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.428341Z","level":"error","event":"25/08/31 18:28:57 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.445563Z","level":"error","event":"25/08/31 18:28:57 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.463764Z","level":"error","event":"25/08/31 18:28:57 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.469936Z","level":"error","event":"25/08/31 18:28:57 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.470102Z","level":"error","event":"25/08/31 18:28:57 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.490423Z","level":"error","event":"25/08/31 18:28:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-490da431-7951-401f-a725-941fc3933a36","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.518765Z","level":"error","event":"25/08/31 18:28:57 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.684047Z","level":"error","event":"25/08/31 18:28:57 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.767788Z","level":"error","event":"25/08/31 18:28:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.778533Z","level":"error","event":"25/08/31 18:28:57 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.828751Z","level":"error","event":"25/08/31 18:28:57 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:35881/jars/hadoop-aws-3.3.6.jar with timestamp 1756664936983","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.835603Z","level":"error","event":"25/08/31 18:28:57 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:35881/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664936983","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.835866Z","level":"error","event":"25/08/31 18:28:57 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:35881/jars/ojdbc11.jar with timestamp 1756664936983","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.835994Z","level":"error","event":"25/08/31 18:28:57 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.836133Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.836248Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.836368Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.836470Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.836569Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.836673Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.836782Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.836887Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.836986Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.837073Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.837166Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.837266Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.837390Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.837487Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.837590Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.837688Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.837784Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.837878Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.837969Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.838061Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.838149Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.838235Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.838352Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.838441Z","level":"error","event":"25/08/31 18:28:57 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.838533Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.838624Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.838718Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.838812Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.838916Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839009Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839077Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839130Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839181Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839232Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839281Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839352Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839404Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839453Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839502Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839552Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839600Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839648Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839697Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839743Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.839803Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.844588Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.844757Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.859890Z","level":"error","event":"25/08/31 18:28:57 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.860009Z","level":"error","event":"25/08/31 18:28:57 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.860111Z","level":"error","event":"25/08/31 18:28:57 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.860214Z","level":"error","event":"25/08/31 18:28:57 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.860333Z","level":"error","event":"25/08/31 18:28:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.993956Z","level":"error","event":"25/08/31 18:28:57 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.998736Z","level":"error","event":"25/08/31 18:28:57 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:57.998893Z","level":"error","event":"25/08/31 18:28:57 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.010059Z","level":"error","event":"25/08/31 18:28:58 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.015848Z","level":"error","event":"25/08/31 18:28:58 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@26abe607 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.025572Z","level":"error","event":"25/08/31 18:28:58 INFO Executor: Fetching spark://6548a13336e4:35881/jars/hadoop-aws-3.3.6.jar with timestamp 1756664936983","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.096038Z","level":"error","event":"25/08/31 18:28:58 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:35881 after 34 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.104402Z","level":"error","event":"25/08/31 18:28:58 INFO Utils: Fetching spark://6548a13336e4:35881/jars/hadoop-aws-3.3.6.jar to /tmp/spark-2c1372f5-2229-4ac1-b58c-b52b1aac846c/userFiles-9744c2d5-2075-4d2e-872e-a84e34773e7c/fetchFileTemp16117913299167816302.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.139959Z","level":"error","event":"25/08/31 18:28:58 INFO Executor: Adding file:/tmp/spark-2c1372f5-2229-4ac1-b58c-b52b1aac846c/userFiles-9744c2d5-2075-4d2e-872e-a84e34773e7c/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.145853Z","level":"error","event":"25/08/31 18:28:58 INFO Executor: Fetching spark://6548a13336e4:35881/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664936983","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.146085Z","level":"error","event":"25/08/31 18:28:58 INFO Utils: Fetching spark://6548a13336e4:35881/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-2c1372f5-2229-4ac1-b58c-b52b1aac846c/userFiles-9744c2d5-2075-4d2e-872e-a84e34773e7c/fetchFileTemp3365916481201141112.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.872396Z","level":"error","event":"25/08/31 18:28:58 INFO Executor: Adding file:/tmp/spark-2c1372f5-2229-4ac1-b58c-b52b1aac846c/userFiles-9744c2d5-2075-4d2e-872e-a84e34773e7c/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.884961Z","level":"error","event":"25/08/31 18:28:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43335.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.891571Z","level":"error","event":"25/08/31 18:28:58 INFO NettyBlockTransferService: Server created on 6548a13336e4:43335","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.891795Z","level":"error","event":"25/08/31 18:28:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.902864Z","level":"error","event":"25/08/31 18:28:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 43335, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.912026Z","level":"error","event":"25/08/31 18:28:58 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:43335 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 43335, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.918165Z","level":"error","event":"25/08/31 18:28:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 43335, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:58.923493Z","level":"error","event":"25/08/31 18:28:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 43335, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.274490Z","level":"error","event":"25/08/31 18:28:59 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.274780Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.274901Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.274998Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.275096Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.275179Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.275273Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.275373Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.275459Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.275539Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.275635Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.275717Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.275807Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.275883Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.275948Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.276019Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.276085Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.276152Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.276235Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.276347Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.276464Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.276558Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.276652Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.276747Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.276847Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.276945Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.277038Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.277134Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.277225Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.277313Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:28:59.277402Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.467675Z","level":"error","event":"25/08/31 18:29:01 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.467952Z","level":"error","event":"25/08/31 18:29:01 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.482991Z","level":"error","event":"25/08/31 18:29:01 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.504406Z","level":"error","event":"25/08/31 18:29:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.524853Z","level":"error","event":"25/08/31 18:29:01 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.531977Z","level":"error","event":"25/08/31 18:29:01 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.532224Z","level":"error","event":"25/08/31 18:29:01 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.539872Z","level":"error","event":"25/08/31 18:29:01 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.540170Z","level":"error","event":"25/08/31 18:29:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.615478Z","level":"error","event":"25/08/31 18:29:01 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.621176Z","level":"error","event":"25/08/31 18:29:01 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.621370Z","level":"error","event":"25/08/31 18:29:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-2c1372f5-2229-4ac1-b58c-b52b1aac846c","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.625793Z","level":"error","event":"25/08/31 18:29:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-71ff310e-e04f-49d5-9e54-d928d9dc4c74","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:01.630643Z","level":"error","event":"25/08/31 18:29:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-2c1372f5-2229-4ac1-b58c-b52b1aac846c/pyspark-11f8798b-fa30-4113-86f4-8aeee6574490","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:32.350061","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:29:33.169778Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:34.781010Z","level":"error","event":"25/08/31 18:29:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.005398Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.011727Z","level":"error","event":"25/08/31 18:29:35 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.011911Z","level":"error","event":"25/08/31 18:29:35 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.277443Z","level":"error","event":"25/08/31 18:29:35 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.283831Z","level":"error","event":"25/08/31 18:29:35 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.284080Z","level":"error","event":"25/08/31 18:29:35 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.320767Z","level":"error","event":"25/08/31 18:29:35 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.326475Z","level":"error","event":"25/08/31 18:29:35 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.326644Z","level":"error","event":"25/08/31 18:29:35 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.326710Z","level":"error","event":"25/08/31 18:29:35 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.360366Z","level":"error","event":"25/08/31 18:29:35 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.367603Z","level":"error","event":"25/08/31 18:29:35 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.367853Z","level":"error","event":"25/08/31 18:29:35 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.440492Z","level":"error","event":"25/08/31 18:29:35 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.440600Z","level":"error","event":"25/08/31 18:29:35 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.447522Z","level":"error","event":"25/08/31 18:29:35 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.447707Z","level":"error","event":"25/08/31 18:29:35 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.447776Z","level":"error","event":"25/08/31 18:29:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.785539Z","level":"error","event":"25/08/31 18:29:35 INFO Utils: Successfully started service 'sparkDriver' on port 37975.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.817499Z","level":"error","event":"25/08/31 18:29:35 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.832421Z","level":"error","event":"25/08/31 18:29:35 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.854142Z","level":"error","event":"25/08/31 18:29:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.862281Z","level":"error","event":"25/08/31 18:29:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.862489Z","level":"error","event":"25/08/31 18:29:35 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.898672Z","level":"error","event":"25/08/31 18:29:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fac97583-5053-4b0a-83d6-ac79b5570cfe","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:35.933881Z","level":"error","event":"25/08/31 18:29:35 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.087287Z","level":"error","event":"25/08/31 18:29:36 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.181439Z","level":"error","event":"25/08/31 18:29:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.199501Z","level":"error","event":"25/08/31 18:29:36 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.267334Z","level":"error","event":"25/08/31 18:29:36 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:37975/jars/hadoop-aws-3.3.6.jar with timestamp 1756664975270","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.275169Z","level":"error","event":"25/08/31 18:29:36 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:37975/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664975270","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.275424Z","level":"error","event":"25/08/31 18:29:36 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:37975/jars/ojdbc11.jar with timestamp 1756664975270","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.275555Z","level":"error","event":"25/08/31 18:29:36 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.275664Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.275766Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.275864Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.275961Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.276063Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.276316Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.276433Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.276534Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.276631Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.276733Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.276831Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.276946Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.277048Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.277148Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.277248Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.277359Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.277463Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.277562Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.277662Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.277763Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.277861Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.277958Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.278058Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.278156Z","level":"error","event":"25/08/31 18:29:36 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.278256Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.278368Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.278467Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.278565Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.278661Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.278760Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.278861Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.278960Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.279101Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.279214Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.279326Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.279431Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.279527Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.279619Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.279841Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.279954Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.280055Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.280157Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.280261Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.280377Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.280478Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.287796Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.288037Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.300049Z","level":"error","event":"25/08/31 18:29:36 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.305685Z","level":"error","event":"25/08/31 18:29:36 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.305921Z","level":"error","event":"25/08/31 18:29:36 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.306043Z","level":"error","event":"25/08/31 18:29:36 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.306154Z","level":"error","event":"25/08/31 18:29:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.480213Z","level":"error","event":"25/08/31 18:29:36 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.487295Z","level":"error","event":"25/08/31 18:29:36 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.487541Z","level":"error","event":"25/08/31 18:29:36 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.497047Z","level":"error","event":"25/08/31 18:29:36 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.502671Z","level":"error","event":"25/08/31 18:29:36 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@38d2738 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.516004Z","level":"error","event":"25/08/31 18:29:36 INFO Executor: Fetching spark://6548a13336e4:37975/jars/hadoop-aws-3.3.6.jar with timestamp 1756664975270","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.585632Z","level":"error","event":"25/08/31 18:29:36 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:37975 after 32 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.593152Z","level":"error","event":"25/08/31 18:29:36 INFO Utils: Fetching spark://6548a13336e4:37975/jars/hadoop-aws-3.3.6.jar to /tmp/spark-54b3cd9c-08ba-4d56-8eaf-c651d48e45a1/userFiles-1d3682cb-c803-4e48-9914-92b60b2c9a19/fetchFileTemp18151413834266023212.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.649693Z","level":"error","event":"25/08/31 18:29:36 INFO Executor: Adding file:/tmp/spark-54b3cd9c-08ba-4d56-8eaf-c651d48e45a1/userFiles-1d3682cb-c803-4e48-9914-92b60b2c9a19/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.658110Z","level":"error","event":"25/08/31 18:29:36 INFO Executor: Fetching spark://6548a13336e4:37975/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756664975270","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:36.658383Z","level":"error","event":"25/08/31 18:29:36 INFO Utils: Fetching spark://6548a13336e4:37975/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-54b3cd9c-08ba-4d56-8eaf-c651d48e45a1/userFiles-1d3682cb-c803-4e48-9914-92b60b2c9a19/fetchFileTemp10833002453790723453.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:37.582886Z","level":"error","event":"25/08/31 18:29:37 INFO Executor: Adding file:/tmp/spark-54b3cd9c-08ba-4d56-8eaf-c651d48e45a1/userFiles-1d3682cb-c803-4e48-9914-92b60b2c9a19/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:37.602661Z","level":"error","event":"25/08/31 18:29:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43073.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:37.602900Z","level":"error","event":"25/08/31 18:29:37 INFO NettyBlockTransferService: Server created on 6548a13336e4:43073","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:37.603046Z","level":"error","event":"25/08/31 18:29:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:37.613563Z","level":"error","event":"25/08/31 18:29:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 43073, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:37.620899Z","level":"error","event":"25/08/31 18:29:37 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:43073 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 43073, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:37.624970Z","level":"error","event":"25/08/31 18:29:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 43073, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:37.628948Z","level":"error","event":"25/08/31 18:29:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 43073, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.016461Z","level":"error","event":"25/08/31 18:29:38 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.016769Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.016917Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.017042Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.017155Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.017267Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.017413Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.017529Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.017637Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.017717Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.017789Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.017861Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.017938Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.018028Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.018107Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.018186Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.018268Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.018371Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.018458Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.018538Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.018634Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.018719Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.018809Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.018910Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.019006Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.019096Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.019198Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.019325Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.019435Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.019528Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:38.019614Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.281606Z","level":"error","event":"25/08/31 18:29:40 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.285474Z","level":"error","event":"25/08/31 18:29:40 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.293454Z","level":"error","event":"25/08/31 18:29:40 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.303273Z","level":"error","event":"25/08/31 18:29:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.316650Z","level":"error","event":"25/08/31 18:29:40 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.320851Z","level":"error","event":"25/08/31 18:29:40 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.320994Z","level":"error","event":"25/08/31 18:29:40 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.326405Z","level":"error","event":"25/08/31 18:29:40 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.331107Z","level":"error","event":"25/08/31 18:29:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.389035Z","level":"error","event":"25/08/31 18:29:40 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.394082Z","level":"error","event":"25/08/31 18:29:40 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.394275Z","level":"error","event":"25/08/31 18:29:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-54b3cd9c-08ba-4d56-8eaf-c651d48e45a1/pyspark-5a2f61ad-5fd6-48cd-b79c-a3c34052f533","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.398386Z","level":"error","event":"25/08/31 18:29:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-5bd5bb04-6476-4f1a-9892-8e74e2804b7c","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:29:40.402024Z","level":"error","event":"25/08/31 18:29:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-54b3cd9c-08ba-4d56-8eaf-c651d48e45a1","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:11.286714","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:30:12.084817Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:14.319355Z","level":"error","event":"25/08/31 18:30:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:14.645134Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:14.651684Z","level":"error","event":"25/08/31 18:30:14 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:14.658116Z","level":"error","event":"25/08/31 18:30:14 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:14.933496Z","level":"error","event":"25/08/31 18:30:14 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:14.939527Z","level":"error","event":"25/08/31 18:30:14 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:14.939744Z","level":"error","event":"25/08/31 18:30:14 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:14.973309Z","level":"error","event":"25/08/31 18:30:14 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:14.980236Z","level":"error","event":"25/08/31 18:30:14 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:14.980502Z","level":"error","event":"25/08/31 18:30:14 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:14.980634Z","level":"error","event":"25/08/31 18:30:14 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.009967Z","level":"error","event":"25/08/31 18:30:15 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.016651Z","level":"error","event":"25/08/31 18:30:15 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.016899Z","level":"error","event":"25/08/31 18:30:15 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.092559Z","level":"error","event":"25/08/31 18:30:15 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.100677Z","level":"error","event":"25/08/31 18:30:15 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.100906Z","level":"error","event":"25/08/31 18:30:15 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.101026Z","level":"error","event":"25/08/31 18:30:15 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.101124Z","level":"error","event":"25/08/31 18:30:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.469589Z","level":"error","event":"25/08/31 18:30:15 INFO Utils: Successfully started service 'sparkDriver' on port 44639.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.522464Z","level":"error","event":"25/08/31 18:30:15 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.541191Z","level":"error","event":"25/08/31 18:30:15 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.561746Z","level":"error","event":"25/08/31 18:30:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.566880Z","level":"error","event":"25/08/31 18:30:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.567040Z","level":"error","event":"25/08/31 18:30:15 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.601920Z","level":"error","event":"25/08/31 18:30:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1f6e69ad-b00b-40fc-aa93-d214ce160a3d","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.639348Z","level":"error","event":"25/08/31 18:30:15 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.845475Z","level":"error","event":"25/08/31 18:30:15 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.965245Z","level":"error","event":"25/08/31 18:30:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:15.980168Z","level":"error","event":"25/08/31 18:30:15 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.026382Z","level":"error","event":"25/08/31 18:30:16 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:44639/jars/hadoop-aws-3.3.6.jar with timestamp 1756665014927","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033114Z","level":"error","event":"25/08/31 18:30:16 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:44639/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665014927","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033285Z","level":"error","event":"25/08/31 18:30:16 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:44639/jars/ojdbc11.jar with timestamp 1756665014927","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033364Z","level":"error","event":"25/08/31 18:30:16 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033436Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033494Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033548Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033599Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033650Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033701Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033751Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033800Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033850Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033898Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033948Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.033998Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.034049Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.034107Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.034199Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.034288Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.034395Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.034489Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.034582Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.034673Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.034766Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.034859Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.034944Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035027Z","level":"error","event":"25/08/31 18:30:16 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035112Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035192Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035248Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035296Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035357Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035404Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035454Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035498Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035542Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035586Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035633Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035677Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035722Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035771Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035825Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035869Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035913Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.035957Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.036001Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.036052Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.036101Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.042977Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.043218Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.054191Z","level":"error","event":"25/08/31 18:30:16 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.058414Z","level":"error","event":"25/08/31 18:30:16 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.058565Z","level":"error","event":"25/08/31 18:30:16 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.058624Z","level":"error","event":"25/08/31 18:30:16 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.058678Z","level":"error","event":"25/08/31 18:30:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.175853Z","level":"error","event":"25/08/31 18:30:16 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.182393Z","level":"error","event":"25/08/31 18:30:16 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.182643Z","level":"error","event":"25/08/31 18:30:16 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.200731Z","level":"error","event":"25/08/31 18:30:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.200841Z","level":"error","event":"25/08/31 18:30:16 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@38d2738 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.214427Z","level":"error","event":"25/08/31 18:30:16 INFO Executor: Fetching spark://6548a13336e4:44639/jars/hadoop-aws-3.3.6.jar with timestamp 1756665014927","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.271038Z","level":"error","event":"25/08/31 18:30:16 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:44639 after 25 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.279978Z","level":"error","event":"25/08/31 18:30:16 INFO Utils: Fetching spark://6548a13336e4:44639/jars/hadoop-aws-3.3.6.jar to /tmp/spark-02a5afc4-23e3-45fe-bd04-8af05c9cb076/userFiles-06bf0c60-da24-4f4e-b1e0-9aaa1e68d521/fetchFileTemp9099182831543802161.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.311570Z","level":"error","event":"25/08/31 18:30:16 INFO Executor: Adding file:/tmp/spark-02a5afc4-23e3-45fe-bd04-8af05c9cb076/userFiles-06bf0c60-da24-4f4e-b1e0-9aaa1e68d521/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.318390Z","level":"error","event":"25/08/31 18:30:16 INFO Executor: Fetching spark://6548a13336e4:44639/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665014927","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:16.318621Z","level":"error","event":"25/08/31 18:30:16 INFO Utils: Fetching spark://6548a13336e4:44639/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-02a5afc4-23e3-45fe-bd04-8af05c9cb076/userFiles-06bf0c60-da24-4f4e-b1e0-9aaa1e68d521/fetchFileTemp11515580752257147043.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.139652Z","level":"error","event":"25/08/31 18:30:17 INFO Executor: Adding file:/tmp/spark-02a5afc4-23e3-45fe-bd04-8af05c9cb076/userFiles-06bf0c60-da24-4f4e-b1e0-9aaa1e68d521/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.152222Z","level":"error","event":"25/08/31 18:30:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37611.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.160004Z","level":"error","event":"25/08/31 18:30:17 INFO NettyBlockTransferService: Server created on 6548a13336e4:37611","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.160261Z","level":"error","event":"25/08/31 18:30:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.172949Z","level":"error","event":"25/08/31 18:30:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 37611, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.181018Z","level":"error","event":"25/08/31 18:30:17 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:37611 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 37611, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.188342Z","level":"error","event":"25/08/31 18:30:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 37611, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.188618Z","level":"error","event":"25/08/31 18:30:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 37611, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.624328Z","level":"error","event":"25/08/31 18:30:17 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.624655Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.624793Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.624899Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.624988Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.625082Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.625183Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.625274Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.625384Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.625471Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.625543Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.625611Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.625690Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.625766Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.625854Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.625934Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.626019Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.626106Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.626194Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.626276Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.626365Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.626439Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.626524Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.626627Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.626731Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.626824Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.626921Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.627031Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.627129Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.627226Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:17.627359Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:19.942898Z","level":"error","event":"25/08/31 18:30:19 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:19.945913Z","level":"error","event":"25/08/31 18:30:19 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:19.998561Z","level":"error","event":"25/08/31 18:30:19 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:19.999026Z","level":"error","event":"25/08/31 18:30:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:19.999101Z","level":"error","event":"25/08/31 18:30:19 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:19.999151Z","level":"error","event":"25/08/31 18:30:19 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:19.999196Z","level":"error","event":"25/08/31 18:30:19 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:19.999239Z","level":"error","event":"25/08/31 18:30:19 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:19.999288Z","level":"error","event":"25/08/31 18:30:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:20.044121Z","level":"error","event":"25/08/31 18:30:20 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:20.044261Z","level":"error","event":"25/08/31 18:30:20 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:20.044345Z","level":"error","event":"25/08/31 18:30:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-02a5afc4-23e3-45fe-bd04-8af05c9cb076","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:20.048153Z","level":"error","event":"25/08/31 18:30:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-407a67d8-171f-42f2-a47f-e7400c91983d","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:20.051126Z","level":"error","event":"25/08/31 18:30:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-02a5afc4-23e3-45fe-bd04-8af05c9cb076/pyspark-ae6da5a0-d24d-4058-aaa2-b9c90239f610","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:50.637172","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:30:51.154779Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.226919Z","level":"error","event":"25/08/31 18:30:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.486946Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.492861Z","level":"error","event":"25/08/31 18:30:53 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.499283Z","level":"error","event":"25/08/31 18:30:53 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.748238Z","level":"error","event":"25/08/31 18:30:53 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.748535Z","level":"error","event":"25/08/31 18:30:53 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.748746Z","level":"error","event":"25/08/31 18:30:53 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.802365Z","level":"error","event":"25/08/31 18:30:53 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.810984Z","level":"error","event":"25/08/31 18:30:53 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.811249Z","level":"error","event":"25/08/31 18:30:53 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.811397Z","level":"error","event":"25/08/31 18:30:53 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.861035Z","level":"error","event":"25/08/31 18:30:53 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.870058Z","level":"error","event":"25/08/31 18:30:53 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.870569Z","level":"error","event":"25/08/31 18:30:53 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.957506Z","level":"error","event":"25/08/31 18:30:53 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.963180Z","level":"error","event":"25/08/31 18:30:53 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.963384Z","level":"error","event":"25/08/31 18:30:53 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.963454Z","level":"error","event":"25/08/31 18:30:53 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:53.968193Z","level":"error","event":"25/08/31 18:30:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.294085Z","level":"error","event":"25/08/31 18:30:54 INFO Utils: Successfully started service 'sparkDriver' on port 37899.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.336368Z","level":"error","event":"25/08/31 18:30:54 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.355716Z","level":"error","event":"25/08/31 18:30:54 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.376238Z","level":"error","event":"25/08/31 18:30:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.376500Z","level":"error","event":"25/08/31 18:30:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.384048Z","level":"error","event":"25/08/31 18:30:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.419956Z","level":"error","event":"25/08/31 18:30:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-786e9d84-43e8-44da-ba7d-980d4080e566","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.448419Z","level":"error","event":"25/08/31 18:30:54 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.594945Z","level":"error","event":"25/08/31 18:30:54 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.702489Z","level":"error","event":"25/08/31 18:30:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.761191Z","level":"error","event":"25/08/31 18:30:54 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:37899/jars/hadoop-aws-3.3.6.jar with timestamp 1756665053721","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.766665Z","level":"error","event":"25/08/31 18:30:54 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:37899/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665053721","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.766880Z","level":"error","event":"25/08/31 18:30:54 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:37899/jars/ojdbc11.jar with timestamp 1756665053721","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.766957Z","level":"error","event":"25/08/31 18:30:54 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767017Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767077Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767136Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767188Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767237Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767290Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767359Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767415Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767464Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767515Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767564Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767627Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767681Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767734Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767785Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767834Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767882Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767931Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.767982Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768033Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768083Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768133Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768184Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768236Z","level":"error","event":"25/08/31 18:30:54 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768286Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768351Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768402Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768453Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768502Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768550Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768600Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768649Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768698Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768753Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768804Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768850Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768896Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768943Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.768989Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.769038Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.769084Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.769130Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.769176Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.769221Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.769267Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.774739Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.774909Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.801514Z","level":"error","event":"25/08/31 18:30:54 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.807472Z","level":"error","event":"25/08/31 18:30:54 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.807659Z","level":"error","event":"25/08/31 18:30:54 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.807728Z","level":"error","event":"25/08/31 18:30:54 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.807788Z","level":"error","event":"25/08/31 18:30:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:54.998690Z","level":"error","event":"25/08/31 18:30:54 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:55.003124Z","level":"error","event":"25/08/31 18:30:54 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:55.003294Z","level":"error","event":"25/08/31 18:30:54 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:55.021783Z","level":"error","event":"25/08/31 18:30:55 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:55.028532Z","level":"error","event":"25/08/31 18:30:55 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5f8d356e for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:55.043099Z","level":"error","event":"25/08/31 18:30:55 INFO Executor: Fetching spark://6548a13336e4:37899/jars/hadoop-aws-3.3.6.jar with timestamp 1756665053721","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:55.135286Z","level":"error","event":"25/08/31 18:30:55 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:37899 after 43 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:55.146370Z","level":"error","event":"25/08/31 18:30:55 INFO Utils: Fetching spark://6548a13336e4:37899/jars/hadoop-aws-3.3.6.jar to /tmp/spark-7208a6b4-470a-4acc-873c-8861d77a99f1/userFiles-6822bfdb-103a-4d79-b340-ec6dd7fb60c2/fetchFileTemp9485129858882506983.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:55.198635Z","level":"error","event":"25/08/31 18:30:55 INFO Executor: Adding file:/tmp/spark-7208a6b4-470a-4acc-873c-8861d77a99f1/userFiles-6822bfdb-103a-4d79-b340-ec6dd7fb60c2/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:55.208556Z","level":"error","event":"25/08/31 18:30:55 INFO Executor: Fetching spark://6548a13336e4:37899/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665053721","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:55.208843Z","level":"error","event":"25/08/31 18:30:55 INFO Utils: Fetching spark://6548a13336e4:37899/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-7208a6b4-470a-4acc-873c-8861d77a99f1/userFiles-6822bfdb-103a-4d79-b340-ec6dd7fb60c2/fetchFileTemp10496904273182015007.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.291051Z","level":"error","event":"25/08/31 18:30:56 INFO Executor: Adding file:/tmp/spark-7208a6b4-470a-4acc-873c-8861d77a99f1/userFiles-6822bfdb-103a-4d79-b340-ec6dd7fb60c2/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.304672Z","level":"error","event":"25/08/31 18:30:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35743.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.312365Z","level":"error","event":"25/08/31 18:30:56 INFO NettyBlockTransferService: Server created on 6548a13336e4:35743","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.312662Z","level":"error","event":"25/08/31 18:30:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.337392Z","level":"error","event":"25/08/31 18:30:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 35743, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.345700Z","level":"error","event":"25/08/31 18:30:56 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:35743 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 35743, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.353689Z","level":"error","event":"25/08/31 18:30:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 35743, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.353964Z","level":"error","event":"25/08/31 18:30:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 35743, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799116Z","level":"error","event":"25/08/31 18:30:56 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799344Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799422Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799481Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799535Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799587Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799645Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799697Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799749Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799800Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799850Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799900Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.799951Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800003Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800053Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800102Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800153Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800203Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800254Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800316Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800372Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800436Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800488Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800544Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800593Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800642Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800692Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800742Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800791Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800841Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:56.800890Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.493558Z","level":"error","event":"25/08/31 18:30:59 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.493670Z","level":"error","event":"25/08/31 18:30:59 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.502324Z","level":"error","event":"25/08/31 18:30:59 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.513401Z","level":"error","event":"25/08/31 18:30:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.530415Z","level":"error","event":"25/08/31 18:30:59 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.534885Z","level":"error","event":"25/08/31 18:30:59 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.535053Z","level":"error","event":"25/08/31 18:30:59 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.539046Z","level":"error","event":"25/08/31 18:30:59 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.545049Z","level":"error","event":"25/08/31 18:30:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.601637Z","level":"error","event":"25/08/31 18:30:59 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.609601Z","level":"error","event":"25/08/31 18:30:59 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.609738Z","level":"error","event":"25/08/31 18:30:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-7208a6b4-470a-4acc-873c-8861d77a99f1/pyspark-b1fe504c-a723-4a1c-bfb7-7cf83a5e6181","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.609807Z","level":"error","event":"25/08/31 18:30:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-0e6ead85-0a40-463f-a9ff-9334c558094f","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:30:59.613269Z","level":"error","event":"25/08/31 18:30:59 INFO ShutdownHookManager: Deleting directory /tmp/spark-7208a6b4-470a-4acc-873c-8861d77a99f1","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:30.379355","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:31:30.828897Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:32.623985Z","level":"error","event":"25/08/31 18:31:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:32.867428Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:32.873807Z","level":"error","event":"25/08/31 18:31:32 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:32.878035Z","level":"error","event":"25/08/31 18:31:32 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.109876Z","level":"error","event":"25/08/31 18:31:33 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.115977Z","level":"error","event":"25/08/31 18:31:33 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.116147Z","level":"error","event":"25/08/31 18:31:33 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.141940Z","level":"error","event":"25/08/31 18:31:33 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.149127Z","level":"error","event":"25/08/31 18:31:33 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.149373Z","level":"error","event":"25/08/31 18:31:33 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.149505Z","level":"error","event":"25/08/31 18:31:33 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.176983Z","level":"error","event":"25/08/31 18:31:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.184008Z","level":"error","event":"25/08/31 18:31:33 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.184266Z","level":"error","event":"25/08/31 18:31:33 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.237340Z","level":"error","event":"25/08/31 18:31:33 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.244848Z","level":"error","event":"25/08/31 18:31:33 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.245108Z","level":"error","event":"25/08/31 18:31:33 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.245243Z","level":"error","event":"25/08/31 18:31:33 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.245358Z","level":"error","event":"25/08/31 18:31:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.564600Z","level":"error","event":"25/08/31 18:31:33 INFO Utils: Successfully started service 'sparkDriver' on port 37763.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.596939Z","level":"error","event":"25/08/31 18:31:33 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.613024Z","level":"error","event":"25/08/31 18:31:33 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.634199Z","level":"error","event":"25/08/31 18:31:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.641221Z","level":"error","event":"25/08/31 18:31:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.641440Z","level":"error","event":"25/08/31 18:31:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.664026Z","level":"error","event":"25/08/31 18:31:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dce166e9-86d2-49f1-805d-36a1dc466816","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.692952Z","level":"error","event":"25/08/31 18:31:33 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.855264Z","level":"error","event":"25/08/31 18:31:33 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:33.934209Z","level":"error","event":"25/08/31 18:31:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.002671Z","level":"error","event":"25/08/31 18:31:34 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:37763/jars/hadoop-aws-3.3.6.jar with timestamp 1756665093104","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.008876Z","level":"error","event":"25/08/31 18:31:34 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:37763/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665093104","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009051Z","level":"error","event":"25/08/31 18:31:34 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:37763/jars/ojdbc11.jar with timestamp 1756665093104","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009119Z","level":"error","event":"25/08/31 18:31:34 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009184Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009264Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009353Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009418Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009476Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009532Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009587Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009641Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009703Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009755Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009808Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009864Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009918Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.009974Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.010028Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.010078Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.010134Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.010194Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.010246Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.010306Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.010366Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.010415Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.010464Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.015512Z","level":"error","event":"25/08/31 18:31:34 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.015708Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.015783Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.015843Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.015899Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.015953Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016006Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016059Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016110Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016158Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016205Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016254Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016310Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016379Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016428Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016478Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016526Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016573Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016619Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016667Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016719Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016768Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016830Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.016882Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.040974Z","level":"error","event":"25/08/31 18:31:34 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.046807Z","level":"error","event":"25/08/31 18:31:34 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.047039Z","level":"error","event":"25/08/31 18:31:34 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.047165Z","level":"error","event":"25/08/31 18:31:34 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.047278Z","level":"error","event":"25/08/31 18:31:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.195428Z","level":"error","event":"25/08/31 18:31:34 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.201494Z","level":"error","event":"25/08/31 18:31:34 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.201666Z","level":"error","event":"25/08/31 18:31:34 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.215749Z","level":"error","event":"25/08/31 18:31:34 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.222805Z","level":"error","event":"25/08/31 18:31:34 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1923a79b for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.231083Z","level":"error","event":"25/08/31 18:31:34 INFO Executor: Fetching spark://6548a13336e4:37763/jars/hadoop-aws-3.3.6.jar with timestamp 1756665093104","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.294528Z","level":"error","event":"25/08/31 18:31:34 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:37763 after 30 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.308759Z","level":"error","event":"25/08/31 18:31:34 INFO Utils: Fetching spark://6548a13336e4:37763/jars/hadoop-aws-3.3.6.jar to /tmp/spark-bc770bc7-78c0-4df6-970b-04534e66ce47/userFiles-dbbda99f-eed6-40c3-b298-d0f4a2253fbf/fetchFileTemp9383264037630696545.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.340587Z","level":"error","event":"25/08/31 18:31:34 INFO Executor: Adding file:/tmp/spark-bc770bc7-78c0-4df6-970b-04534e66ce47/userFiles-dbbda99f-eed6-40c3-b298-d0f4a2253fbf/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.347161Z","level":"error","event":"25/08/31 18:31:34 INFO Executor: Fetching spark://6548a13336e4:37763/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665093104","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:34.347346Z","level":"error","event":"25/08/31 18:31:34 INFO Utils: Fetching spark://6548a13336e4:37763/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-bc770bc7-78c0-4df6-970b-04534e66ce47/userFiles-dbbda99f-eed6-40c3-b298-d0f4a2253fbf/fetchFileTemp11817534819786241549.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.182023Z","level":"error","event":"25/08/31 18:31:35 INFO Executor: Adding file:/tmp/spark-bc770bc7-78c0-4df6-970b-04534e66ce47/userFiles-dbbda99f-eed6-40c3-b298-d0f4a2253fbf/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.199590Z","level":"error","event":"25/08/31 18:31:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46185.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.205283Z","level":"error","event":"25/08/31 18:31:35 INFO NettyBlockTransferService: Server created on 6548a13336e4:46185","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.205556Z","level":"error","event":"25/08/31 18:31:35 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.226130Z","level":"error","event":"25/08/31 18:31:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 46185, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.233908Z","level":"error","event":"25/08/31 18:31:35 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:46185 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 46185, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.240024Z","level":"error","event":"25/08/31 18:31:35 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 46185, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.240259Z","level":"error","event":"25/08/31 18:31:35 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 46185, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.686896Z","level":"error","event":"25/08/31 18:31:35 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.687176Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.687338Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.687466Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.687588Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.687704Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.687805Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.687900Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.687979Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688052Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688125Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688229Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688325Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688410Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688491Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688583Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688671Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688757Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688833Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688909Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.688995Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.689087Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.689176Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.689264Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.689380Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.689474Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.689579Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.689675Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.689776Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.689858Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:35.689944Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.040843Z","level":"error","event":"25/08/31 18:31:38 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.048570Z","level":"error","event":"25/08/31 18:31:38 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.059750Z","level":"error","event":"25/08/31 18:31:38 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.076756Z","level":"error","event":"25/08/31 18:31:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.105170Z","level":"error","event":"25/08/31 18:31:38 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.113683Z","level":"error","event":"25/08/31 18:31:38 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.114037Z","level":"error","event":"25/08/31 18:31:38 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.121660Z","level":"error","event":"25/08/31 18:31:38 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.130494Z","level":"error","event":"25/08/31 18:31:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.222936Z","level":"error","event":"25/08/31 18:31:38 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.230293Z","level":"error","event":"25/08/31 18:31:38 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.230504Z","level":"error","event":"25/08/31 18:31:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc770bc7-78c0-4df6-970b-04534e66ce47/pyspark-44369368-da91-4aec-aff8-b1b296644d02","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.234972Z","level":"error","event":"25/08/31 18:31:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-bc770bc7-78c0-4df6-970b-04534e66ce47","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:31:38.240060Z","level":"error","event":"25/08/31 18:31:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-78a65729-a7dd-47cf-b613-2e04dc9656ca","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:09.072994","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:32:09.526353Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:11.475862Z","level":"error","event":"25/08/31 18:32:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:11.709554Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:11.716609Z","level":"error","event":"25/08/31 18:32:11 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:11.716859Z","level":"error","event":"25/08/31 18:32:11 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:11.989389Z","level":"error","event":"25/08/31 18:32:11 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:11.995945Z","level":"error","event":"25/08/31 18:32:11 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:11.996192Z","level":"error","event":"25/08/31 18:32:11 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.044059Z","level":"error","event":"25/08/31 18:32:12 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.044334Z","level":"error","event":"25/08/31 18:32:12 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.044469Z","level":"error","event":"25/08/31 18:32:12 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.044558Z","level":"error","event":"25/08/31 18:32:12 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.093022Z","level":"error","event":"25/08/31 18:32:12 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.104063Z","level":"error","event":"25/08/31 18:32:12 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.104367Z","level":"error","event":"25/08/31 18:32:12 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.183467Z","level":"error","event":"25/08/31 18:32:12 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.192890Z","level":"error","event":"25/08/31 18:32:12 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.193144Z","level":"error","event":"25/08/31 18:32:12 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.193252Z","level":"error","event":"25/08/31 18:32:12 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.193368Z","level":"error","event":"25/08/31 18:32:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.607128Z","level":"error","event":"25/08/31 18:32:12 INFO Utils: Successfully started service 'sparkDriver' on port 43241.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.648868Z","level":"error","event":"25/08/31 18:32:12 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.672105Z","level":"error","event":"25/08/31 18:32:12 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.699746Z","level":"error","event":"25/08/31 18:32:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.706321Z","level":"error","event":"25/08/31 18:32:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.713768Z","level":"error","event":"25/08/31 18:32:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.747772Z","level":"error","event":"25/08/31 18:32:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a045acd7-11a6-4aea-8aea-dc7450d97d33","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:12.789171Z","level":"error","event":"25/08/31 18:32:12 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.025282Z","level":"error","event":"25/08/31 18:32:13 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.159948Z","level":"error","event":"25/08/31 18:32:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.171399Z","level":"error","event":"25/08/31 18:32:13 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.237915Z","level":"error","event":"25/08/31 18:32:13 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:43241/jars/hadoop-aws-3.3.6.jar with timestamp 1756665131980","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.246901Z","level":"error","event":"25/08/31 18:32:13 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:43241/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665131980","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.247160Z","level":"error","event":"25/08/31 18:32:13 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:43241/jars/ojdbc11.jar with timestamp 1756665131980","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.247287Z","level":"error","event":"25/08/31 18:32:13 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.247504Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.247801Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.247926Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.248033Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.248138Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.248242Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.248359Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.248478Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.248583Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.248691Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.248801Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.248908Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.249044Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.249146Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.249252Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.249371Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.249466Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.249560Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.249656Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.249765Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.249866Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.249968Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.250071Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.250176Z","level":"error","event":"25/08/31 18:32:13 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.250274Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.250404Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.250505Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.250609Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.250711Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.250813Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.250916Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.251017Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.251114Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.251218Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.251363Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.251475Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.251582Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.251688Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.251783Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.251870Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.251966Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.252072Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.252174Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.252271Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.252394Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.262043Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.262371Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.281660Z","level":"error","event":"25/08/31 18:32:13 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.289539Z","level":"error","event":"25/08/31 18:32:13 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.289882Z","level":"error","event":"25/08/31 18:32:13 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.290013Z","level":"error","event":"25/08/31 18:32:13 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.290113Z","level":"error","event":"25/08/31 18:32:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.511257Z","level":"error","event":"25/08/31 18:32:13 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.520768Z","level":"error","event":"25/08/31 18:32:13 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.520970Z","level":"error","event":"25/08/31 18:32:13 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.537409Z","level":"error","event":"25/08/31 18:32:13 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.545509Z","level":"error","event":"25/08/31 18:32:13 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@38d2738 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.557016Z","level":"error","event":"25/08/31 18:32:13 INFO Executor: Fetching spark://6548a13336e4:43241/jars/hadoop-aws-3.3.6.jar with timestamp 1756665131980","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.647081Z","level":"error","event":"25/08/31 18:32:13 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:43241 after 53 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.656402Z","level":"error","event":"25/08/31 18:32:13 INFO Utils: Fetching spark://6548a13336e4:43241/jars/hadoop-aws-3.3.6.jar to /tmp/spark-03e7184e-e5bb-495a-8fdc-5806d1071196/userFiles-43b231b8-3377-431b-bb5a-94a78022f113/fetchFileTemp9769604838700505625.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.697184Z","level":"error","event":"25/08/31 18:32:13 INFO Executor: Adding file:/tmp/spark-03e7184e-e5bb-495a-8fdc-5806d1071196/userFiles-43b231b8-3377-431b-bb5a-94a78022f113/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.705186Z","level":"error","event":"25/08/31 18:32:13 INFO Executor: Fetching spark://6548a13336e4:43241/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665131980","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:13.705489Z","level":"error","event":"25/08/31 18:32:13 INFO Utils: Fetching spark://6548a13336e4:43241/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-03e7184e-e5bb-495a-8fdc-5806d1071196/userFiles-43b231b8-3377-431b-bb5a-94a78022f113/fetchFileTemp16512004592772434846.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:14.494156Z","level":"error","event":"25/08/31 18:32:14 INFO Executor: Adding file:/tmp/spark-03e7184e-e5bb-495a-8fdc-5806d1071196/userFiles-43b231b8-3377-431b-bb5a-94a78022f113/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:14.506586Z","level":"error","event":"25/08/31 18:32:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39561.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:14.512714Z","level":"error","event":"25/08/31 18:32:14 INFO NettyBlockTransferService: Server created on 6548a13336e4:39561","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:14.512980Z","level":"error","event":"25/08/31 18:32:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:14.529364Z","level":"error","event":"25/08/31 18:32:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 39561, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:14.538051Z","level":"error","event":"25/08/31 18:32:14 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:39561 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 39561, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:14.544166Z","level":"error","event":"25/08/31 18:32:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 39561, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:14.551062Z","level":"error","event":"25/08/31 18:32:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 39561, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.021859Z","level":"error","event":"25/08/31 18:32:15 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.022125Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.022225Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.022388Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.022487Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.022572Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.022660Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.022745Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.022830Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.022912Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.022995Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023080Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023167Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023240Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023322Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023438Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023586Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023666Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023714Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023769Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023819Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023907Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.023956Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.024002Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.024046Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.024090Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.024137Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.024182Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.024226Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.024270Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:15.024329Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.366591Z","level":"error","event":"25/08/31 18:32:17 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.370550Z","level":"error","event":"25/08/31 18:32:17 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.378683Z","level":"error","event":"25/08/31 18:32:17 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.389895Z","level":"error","event":"25/08/31 18:32:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.407385Z","level":"error","event":"25/08/31 18:32:17 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.413150Z","level":"error","event":"25/08/31 18:32:17 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.413320Z","level":"error","event":"25/08/31 18:32:17 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.417679Z","level":"error","event":"25/08/31 18:32:17 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.423059Z","level":"error","event":"25/08/31 18:32:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.484698Z","level":"error","event":"25/08/31 18:32:17 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.488694Z","level":"error","event":"25/08/31 18:32:17 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.488843Z","level":"error","event":"25/08/31 18:32:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-e17fc201-9b18-4b96-8321-0b2530285b2d","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.492857Z","level":"error","event":"25/08/31 18:32:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-03e7184e-e5bb-495a-8fdc-5806d1071196/pyspark-3d193dc3-4ad2-4ff9-acf0-918397a993e1","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:17.497845Z","level":"error","event":"25/08/31 18:32:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-03e7184e-e5bb-495a-8fdc-5806d1071196","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:48.114893","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:32:48.552186Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.329344Z","level":"error","event":"25/08/31 18:32:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.561354Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.566346Z","level":"error","event":"25/08/31 18:32:50 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.571426Z","level":"error","event":"25/08/31 18:32:50 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.744124Z","level":"error","event":"25/08/31 18:32:50 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.748994Z","level":"error","event":"25/08/31 18:32:50 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.749195Z","level":"error","event":"25/08/31 18:32:50 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.776806Z","level":"error","event":"25/08/31 18:32:50 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.781797Z","level":"error","event":"25/08/31 18:32:50 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.781957Z","level":"error","event":"25/08/31 18:32:50 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.782028Z","level":"error","event":"25/08/31 18:32:50 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.804441Z","level":"error","event":"25/08/31 18:32:50 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.809942Z","level":"error","event":"25/08/31 18:32:50 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.810108Z","level":"error","event":"25/08/31 18:32:50 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.859647Z","level":"error","event":"25/08/31 18:32:50 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.866804Z","level":"error","event":"25/08/31 18:32:50 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.867057Z","level":"error","event":"25/08/31 18:32:50 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.867179Z","level":"error","event":"25/08/31 18:32:50 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:50.867280Z","level":"error","event":"25/08/31 18:32:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.135012Z","level":"error","event":"25/08/31 18:32:51 INFO Utils: Successfully started service 'sparkDriver' on port 35631.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.162771Z","level":"error","event":"25/08/31 18:32:51 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.176716Z","level":"error","event":"25/08/31 18:32:51 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.194762Z","level":"error","event":"25/08/31 18:32:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.201801Z","level":"error","event":"25/08/31 18:32:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.202035Z","level":"error","event":"25/08/31 18:32:51 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.225161Z","level":"error","event":"25/08/31 18:32:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-06191dd6-678e-4600-97d1-afbba79968c0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.253895Z","level":"error","event":"25/08/31 18:32:51 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.410872Z","level":"error","event":"25/08/31 18:32:51 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.493240Z","level":"error","event":"25/08/31 18:32:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.542761Z","level":"error","event":"25/08/31 18:32:51 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:35631/jars/hadoop-aws-3.3.6.jar with timestamp 1756665170738","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.548527Z","level":"error","event":"25/08/31 18:32:51 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:35631/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665170738","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.548702Z","level":"error","event":"25/08/31 18:32:51 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:35631/jars/ojdbc11.jar with timestamp 1756665170738","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.548767Z","level":"error","event":"25/08/31 18:32:51 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.548827Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.548898Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.548953Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549007Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549060Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549113Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549163Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549215Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549266Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549332Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549386Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549440Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549491Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549543Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549593Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549645Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549696Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549748Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549810Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549868Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549923Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.549975Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550028Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550085Z","level":"error","event":"25/08/31 18:32:51 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550149Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550206Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550261Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550336Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550389Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550442Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550492Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550544Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550594Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550643Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550701Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550750Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550797Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550845Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550893Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550944Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.550991Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.551038Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.551086Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.551133Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.551183Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.557259Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.557446Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.583504Z","level":"error","event":"25/08/31 18:32:51 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.592430Z","level":"error","event":"25/08/31 18:32:51 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.592678Z","level":"error","event":"25/08/31 18:32:51 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.592803Z","level":"error","event":"25/08/31 18:32:51 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.592907Z","level":"error","event":"25/08/31 18:32:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.745677Z","level":"error","event":"25/08/31 18:32:51 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.745793Z","level":"error","event":"25/08/31 18:32:51 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.745898Z","level":"error","event":"25/08/31 18:32:51 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.765002Z","level":"error","event":"25/08/31 18:32:51 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.765181Z","level":"error","event":"25/08/31 18:32:51 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1f21d715 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.777880Z","level":"error","event":"25/08/31 18:32:51 INFO Executor: Fetching spark://6548a13336e4:35631/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665170738","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.835600Z","level":"error","event":"25/08/31 18:32:51 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:35631 after 27 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:51.844018Z","level":"error","event":"25/08/31 18:32:51 INFO Utils: Fetching spark://6548a13336e4:35631/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-05eb32d5-76e4-46fd-8a7d-f86010557983/userFiles-08877580-57d0-43c6-94a1-6a94cb22d04c/fetchFileTemp1137071102340258871.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:52.578168Z","level":"error","event":"25/08/31 18:32:52 INFO Executor: Adding file:/tmp/spark-05eb32d5-76e4-46fd-8a7d-f86010557983/userFiles-08877580-57d0-43c6-94a1-6a94cb22d04c/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:52.585290Z","level":"error","event":"25/08/31 18:32:52 INFO Executor: Fetching spark://6548a13336e4:35631/jars/hadoop-aws-3.3.6.jar with timestamp 1756665170738","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:52.585528Z","level":"error","event":"25/08/31 18:32:52 INFO Utils: Fetching spark://6548a13336e4:35631/jars/hadoop-aws-3.3.6.jar to /tmp/spark-05eb32d5-76e4-46fd-8a7d-f86010557983/userFiles-08877580-57d0-43c6-94a1-6a94cb22d04c/fetchFileTemp14850867496020276595.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:52.592118Z","level":"error","event":"25/08/31 18:32:52 INFO Executor: Adding file:/tmp/spark-05eb32d5-76e4-46fd-8a7d-f86010557983/userFiles-08877580-57d0-43c6-94a1-6a94cb22d04c/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:52.603797Z","level":"error","event":"25/08/31 18:32:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32899.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:52.610722Z","level":"error","event":"25/08/31 18:32:52 INFO NettyBlockTransferService: Server created on 6548a13336e4:32899","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:52.610986Z","level":"error","event":"25/08/31 18:32:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:52.629693Z","level":"error","event":"25/08/31 18:32:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 32899, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:52.638063Z","level":"error","event":"25/08/31 18:32:52 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:32899 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 32899, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:52.643398Z","level":"error","event":"25/08/31 18:32:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 32899, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:52.649445Z","level":"error","event":"25/08/31 18:32:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 32899, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008186Z","level":"error","event":"25/08/31 18:32:53 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008416Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008500Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008557Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008610Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008664Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008715Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008765Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008816Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008867Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008916Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.008978Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009031Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009081Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009129Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009175Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009224Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009272Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009336Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009393Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009442Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009492Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009541Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009592Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009640Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009687Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009735Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009784Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009831Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009879Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:53.009926Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.367385Z","level":"error","event":"25/08/31 18:32:55 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.367563Z","level":"error","event":"25/08/31 18:32:55 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.380900Z","level":"error","event":"25/08/31 18:32:55 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4040","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.393172Z","level":"error","event":"25/08/31 18:32:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.410158Z","level":"error","event":"25/08/31 18:32:55 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.414484Z","level":"error","event":"25/08/31 18:32:55 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.414663Z","level":"error","event":"25/08/31 18:32:55 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.418602Z","level":"error","event":"25/08/31 18:32:55 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.424034Z","level":"error","event":"25/08/31 18:32:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.489382Z","level":"error","event":"25/08/31 18:32:55 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.489600Z","level":"error","event":"25/08/31 18:32:55 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.489706Z","level":"error","event":"25/08/31 18:32:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-05eb32d5-76e4-46fd-8a7d-f86010557983","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.493881Z","level":"error","event":"25/08/31 18:32:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-83290048-693d-490f-9f1e-2b1d9aeb320a","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:32:55.497604Z","level":"error","event":"25/08/31 18:32:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-05eb32d5-76e4-46fd-8a7d-f86010557983/pyspark-ce465694-3cf2-40b2-82da-6c9f6a307938","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:26.031035","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:33:26.483408Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.221157Z","level":"error","event":"25/08/31 18:33:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.517678Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.527387Z","level":"error","event":"25/08/31 18:33:28 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.535883Z","level":"error","event":"25/08/31 18:33:28 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.825117Z","level":"error","event":"25/08/31 18:33:28 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.825326Z","level":"error","event":"25/08/31 18:33:28 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.825428Z","level":"error","event":"25/08/31 18:33:28 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.874118Z","level":"error","event":"25/08/31 18:33:28 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.874305Z","level":"error","event":"25/08/31 18:33:28 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.874380Z","level":"error","event":"25/08/31 18:33:28 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.874438Z","level":"error","event":"25/08/31 18:33:28 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.905577Z","level":"error","event":"25/08/31 18:33:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.911537Z","level":"error","event":"25/08/31 18:33:28 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.911712Z","level":"error","event":"25/08/31 18:33:28 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.981526Z","level":"error","event":"25/08/31 18:33:28 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.981642Z","level":"error","event":"25/08/31 18:33:28 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.981748Z","level":"error","event":"25/08/31 18:33:28 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.981844Z","level":"error","event":"25/08/31 18:33:28 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:28.981932Z","level":"error","event":"25/08/31 18:33:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.260655Z","level":"error","event":"25/08/31 18:33:29 INFO Utils: Successfully started service 'sparkDriver' on port 38135.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.304712Z","level":"error","event":"25/08/31 18:33:29 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.321193Z","level":"error","event":"25/08/31 18:33:29 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.348368Z","level":"error","event":"25/08/31 18:33:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.354021Z","level":"error","event":"25/08/31 18:33:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.354202Z","level":"error","event":"25/08/31 18:33:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.380132Z","level":"error","event":"25/08/31 18:33:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e22713cd-3187-4410-be64-683e7c01f422","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.405862Z","level":"error","event":"25/08/31 18:33:29 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.553251Z","level":"error","event":"25/08/31 18:33:29 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.638638Z","level":"error","event":"25/08/31 18:33:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.649698Z","level":"error","event":"25/08/31 18:33:29 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.720397Z","level":"error","event":"25/08/31 18:33:29 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://6548a13336e4:38135/jars/hadoop-aws-3.3.6.jar with timestamp 1756665208813","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.726491Z","level":"error","event":"25/08/31 18:33:29 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://6548a13336e4:38135/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665208813","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.726720Z","level":"error","event":"25/08/31 18:33:29 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://6548a13336e4:38135/jars/ojdbc11.jar with timestamp 1756665208813","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.726794Z","level":"error","event":"25/08/31 18:33:29 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.726853Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.726919Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.726979Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727171Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727237Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727330Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727419Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727477Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727533Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727589Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727644Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727700Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727776Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727834Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727892Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.727949Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728002Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728051Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728112Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728165Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728217Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728268Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728338Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728397Z","level":"error","event":"25/08/31 18:33:29 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728449Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728500Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728551Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728606Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728656Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728708Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728757Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728808Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728856Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728906Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.728965Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.729019Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.729075Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.729121Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.729167Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.729214Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.729260Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.729316Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.729365Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.729410Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.729455Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.735642Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.735875Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.757314Z","level":"error","event":"25/08/31 18:33:29 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.763772Z","level":"error","event":"25/08/31 18:33:29 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.764006Z","level":"error","event":"25/08/31 18:33:29 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.764128Z","level":"error","event":"25/08/31 18:33:29 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.764238Z","level":"error","event":"25/08/31 18:33:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.927323Z","level":"error","event":"25/08/31 18:33:29 INFO Executor: Starting executor ID driver on host 6548a13336e4","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.934345Z","level":"error","event":"25/08/31 18:33:29 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.934548Z","level":"error","event":"25/08/31 18:33:29 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.949315Z","level":"error","event":"25/08/31 18:33:29 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.957393Z","level":"error","event":"25/08/31 18:33:29 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@65dec114 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:29.973283Z","level":"error","event":"25/08/31 18:33:29 INFO Executor: Fetching spark://6548a13336e4:38135/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665208813","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:30.055278Z","level":"error","event":"25/08/31 18:33:30 INFO TransportClientFactory: Successfully created connection to 6548a13336e4/172.18.0.11:38135 after 33 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:30.066014Z","level":"error","event":"25/08/31 18:33:30 INFO Utils: Fetching spark://6548a13336e4:38135/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-7aebb24b-768f-4b2a-9ae7-c124f0a88138/userFiles-2bf296ee-41a6-4304-9764-b3130b874b51/fetchFileTemp1302888578146525175.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.026149Z","level":"error","event":"25/08/31 18:33:31 INFO Executor: Adding file:/tmp/spark-7aebb24b-768f-4b2a-9ae7-c124f0a88138/userFiles-2bf296ee-41a6-4304-9764-b3130b874b51/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.026430Z","level":"error","event":"25/08/31 18:33:31 INFO Executor: Fetching spark://6548a13336e4:38135/jars/hadoop-aws-3.3.6.jar with timestamp 1756665208813","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.026581Z","level":"error","event":"25/08/31 18:33:31 INFO Utils: Fetching spark://6548a13336e4:38135/jars/hadoop-aws-3.3.6.jar to /tmp/spark-7aebb24b-768f-4b2a-9ae7-c124f0a88138/userFiles-2bf296ee-41a6-4304-9764-b3130b874b51/fetchFileTemp13499753300035575860.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.033875Z","level":"error","event":"25/08/31 18:33:31 INFO Executor: Adding file:/tmp/spark-7aebb24b-768f-4b2a-9ae7-c124f0a88138/userFiles-2bf296ee-41a6-4304-9764-b3130b874b51/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.053194Z","level":"error","event":"25/08/31 18:33:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40187.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.053523Z","level":"error","event":"25/08/31 18:33:31 INFO NettyBlockTransferService: Server created on 6548a13336e4:40187","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.062367Z","level":"error","event":"25/08/31 18:33:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.083421Z","level":"error","event":"25/08/31 18:33:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 6548a13336e4, 40187, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.094045Z","level":"error","event":"25/08/31 18:33:31 INFO BlockManagerMasterEndpoint: Registering block manager 6548a13336e4:40187 with 434.4 MiB RAM, BlockManagerId(driver, 6548a13336e4, 40187, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.102723Z","level":"error","event":"25/08/31 18:33:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 6548a13336e4, 40187, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.103009Z","level":"error","event":"25/08/31 18:33:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 6548a13336e4, 40187, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.655316Z","level":"error","event":"25/08/31 18:33:31 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.655590Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.655706Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.655802Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.655889Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.655984Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.656078Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.656162Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.656242Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.656340Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.656429Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.656511Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.656593Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.656678Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.656758Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.656841Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.656924Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657023Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657112Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657196Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657281Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657397Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657457Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657511Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657601Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657692Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657792Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657888Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.657981Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.658083Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:31.658165Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631309Z","level":"error","event":"25/08/31 18:33:33 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631366Z","level":"error","event":"25/08/31 18:33:33 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631416Z","level":"error","event":"25/08/31 18:33:33 INFO SparkUI: Stopped Spark web UI at http://6548a13336e4:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631464Z","level":"error","event":"25/08/31 18:33:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631510Z","level":"error","event":"25/08/31 18:33:33 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631557Z","level":"error","event":"25/08/31 18:33:33 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631603Z","level":"error","event":"25/08/31 18:33:33 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631649Z","level":"error","event":"25/08/31 18:33:33 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631695Z","level":"error","event":"25/08/31 18:33:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631740Z","level":"error","event":"25/08/31 18:33:33 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631786Z","level":"error","event":"25/08/31 18:33:33 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631832Z","level":"error","event":"25/08/31 18:33:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-7aebb24b-768f-4b2a-9ae7-c124f0a88138","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631889Z","level":"error","event":"25/08/31 18:33:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-da7cb5c9-844e-44da-a180-bf490c022d39","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:33:33.631937Z","level":"error","event":"25/08/31 18:33:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-7aebb24b-768f-4b2a-9ae7-c124f0a88138/pyspark-f7640415-c201-42bc-9595-5eac918e6f83","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:41.440218","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:35:45.919893Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:46.559514Z","level":"error","event":"25/08/31 18:35:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.018891Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.037960Z","level":"error","event":"25/08/31 18:35:47 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.046654Z","level":"error","event":"25/08/31 18:35:47 WARN DependencyUtils: Local jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar does not exist, skipping.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.678165Z","level":"error","event":"25/08/31 18:35:47 INFO SparkContext: Running Spark version 4.0.0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.686438Z","level":"error","event":"25/08/31 18:35:47 INFO SparkContext: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.686705Z","level":"error","event":"25/08/31 18:35:47 INFO SparkContext: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.734501Z","level":"error","event":"25/08/31 18:35:47 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.742492Z","level":"error","event":"25/08/31 18:35:47 INFO ResourceUtils: No custom resources configured for spark.driver.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.742765Z","level":"error","event":"25/08/31 18:35:47 INFO ResourceUtils: ==============================================================","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.742887Z","level":"error","event":"25/08/31 18:35:47 INFO SparkContext: Submitted application: BAITEST","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.792999Z","level":"error","event":"25/08/31 18:35:47 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.806219Z","level":"error","event":"25/08/31 18:35:47 INFO ResourceProfile: Limiting resource is cpu","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.806652Z","level":"error","event":"25/08/31 18:35:47 INFO ResourceProfileManager: Added ResourceProfile id: 0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.892429Z","level":"error","event":"25/08/31 18:35:47 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.908564Z","level":"error","event":"25/08/31 18:35:47 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.908853Z","level":"error","event":"25/08/31 18:35:47 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.908984Z","level":"error","event":"25/08/31 18:35:47 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:47.909085Z","level":"error","event":"25/08/31 18:35:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:48.476629Z","level":"error","event":"25/08/31 18:35:48 INFO Utils: Successfully started service 'sparkDriver' on port 42533.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:48.520474Z","level":"error","event":"25/08/31 18:35:48 INFO SparkEnv: Registering MapOutputTracker","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:48.543105Z","level":"error","event":"25/08/31 18:35:48 INFO SparkEnv: Registering BlockManagerMaster","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:48.571998Z","level":"error","event":"25/08/31 18:35:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:48.578878Z","level":"error","event":"25/08/31 18:35:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:48.585196Z","level":"error","event":"25/08/31 18:35:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:48.617422Z","level":"error","event":"25/08/31 18:35:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b0c05d85-8599-4fad-b248-80f7db8df9e0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:48.653860Z","level":"error","event":"25/08/31 18:35:48 INFO SparkEnv: Registering OutputCommitCoordinator","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:48.850423Z","level":"error","event":"25/08/31 18:35:48 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:48.974547Z","level":"error","event":"25/08/31 18:35:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:48.988348Z","level":"error","event":"25/08/31 18:35:48 INFO Utils: Successfully started service 'SparkUI' on port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.127959Z","level":"error","event":"25/08/31 18:35:49 INFO SparkContext: Added JAR /opt/spark/jars/hadoop-aws-3.3.6.jar at spark://102c1303304a:42533/jars/hadoop-aws-3.3.6.jar with timestamp 1756665347669","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.128212Z","level":"error","event":"25/08/31 18:35:49 INFO SparkContext: Added JAR /opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar at spark://102c1303304a:42533/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665347669","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.128329Z","level":"error","event":"25/08/31 18:35:49 INFO SparkContext: Added JAR /opt/spark/jars/ojdbc11.jar at spark://102c1303304a:42533/jars/ojdbc11.jar with timestamp 1756665347669","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.134996Z","level":"error","event":"25/08/31 18:35:49 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.135236Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.135553Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.135825Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.135924Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.136011Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.136109Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.136226Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.136332Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.136425Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.136526Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.136705Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.136789Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.136869Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.136953Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.137071Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.137176Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.137283Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.137414Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.137526Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.137644Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.137748Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.137830Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.137917Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.138054Z","level":"error","event":"25/08/31 18:35:49 ERROR SparkContext: Failed to add /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar to Spark environment","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.138167Z","level":"error","event":"java.io.FileNotFoundException: Jar /opt/spark/jars/iceberg-aws-bundle-1.9.2.jar not found","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.138271Z","level":"error","event":"\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:2174)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.138386Z","level":"error","event":"\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2230)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.138479Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.138570Z","level":"error","event":"\tat org.apache.spark.SparkContext.$anonfun$new$15$adapted(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.138680Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.138764Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.138837Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.138918Z","level":"error","event":"\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:538)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.139007Z","level":"error","event":"\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:59)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.139099Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.139193Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.139473Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.139641Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.139748Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.139862Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.140065Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.140164Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.140251Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.140379Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.140476Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.140607Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.140708Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.175182Z","level":"error","event":"25/08/31 18:35:49 INFO SecurityManager: Changing view acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.181426Z","level":"error","event":"25/08/31 18:35:49 INFO SecurityManager: Changing modify acls to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.181672Z","level":"error","event":"25/08/31 18:35:49 INFO SecurityManager: Changing view acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.181801Z","level":"error","event":"25/08/31 18:35:49 INFO SecurityManager: Changing modify acls groups to: airflow","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.181904Z","level":"error","event":"25/08/31 18:35:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY; RPC SSL disabled","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.381644Z","level":"error","event":"25/08/31 18:35:49 INFO Executor: Starting executor ID driver on host 102c1303304a","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.387653Z","level":"error","event":"25/08/31 18:35:49 INFO Executor: OS info Linux, 6.8.0-79-generic, amd64","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.387830Z","level":"error","event":"25/08/31 18:35:49 INFO Executor: Java version 17.0.16","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.403062Z","level":"error","event":"25/08/31 18:35:49 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/opt/spark/jars/ojdbc11.jar,file:/opt/airflow/ojdbc11.jar'","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.409107Z","level":"error","event":"25/08/31 18:35:49 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@6df5fdf4 for default.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.428550Z","level":"error","event":"25/08/31 18:35:49 INFO Executor: Fetching spark://102c1303304a:42533/jars/aws-java-sdk-bundle-1.12.787.jar with timestamp 1756665347669","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.507368Z","level":"error","event":"25/08/31 18:35:49 INFO TransportClientFactory: Successfully created connection to 102c1303304a/172.18.0.9:42533 after 36 ms (0 ms spent in bootstraps)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:49.519189Z","level":"error","event":"25/08/31 18:35:49 INFO Utils: Fetching spark://102c1303304a:42533/jars/aws-java-sdk-bundle-1.12.787.jar to /tmp/spark-5184a8c4-c634-44cf-8583-8a9febebecd0/userFiles-c51c9119-c835-4b6d-9c7f-0f5780149e67/fetchFileTemp1695931268089535727.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:50.875740Z","level":"error","event":"25/08/31 18:35:50 INFO Executor: Adding file:/tmp/spark-5184a8c4-c634-44cf-8583-8a9febebecd0/userFiles-c51c9119-c835-4b6d-9c7f-0f5780149e67/aws-java-sdk-bundle-1.12.787.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:50.882851Z","level":"error","event":"25/08/31 18:35:50 INFO Executor: Fetching spark://102c1303304a:42533/jars/hadoop-aws-3.3.6.jar with timestamp 1756665347669","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:50.883154Z","level":"error","event":"25/08/31 18:35:50 INFO Utils: Fetching spark://102c1303304a:42533/jars/hadoop-aws-3.3.6.jar to /tmp/spark-5184a8c4-c634-44cf-8583-8a9febebecd0/userFiles-c51c9119-c835-4b6d-9c7f-0f5780149e67/fetchFileTemp4650184615374868735.tmp","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:50.897074Z","level":"error","event":"25/08/31 18:35:50 INFO Executor: Adding file:/tmp/spark-5184a8c4-c634-44cf-8583-8a9febebecd0/userFiles-c51c9119-c835-4b6d-9c7f-0f5780149e67/hadoop-aws-3.3.6.jar to class loader default","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:50.906935Z","level":"error","event":"25/08/31 18:35:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38961.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:50.919520Z","level":"error","event":"25/08/31 18:35:50 INFO NettyBlockTransferService: Server created on 102c1303304a:38961","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:50.919773Z","level":"error","event":"25/08/31 18:35:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:50.943509Z","level":"error","event":"25/08/31 18:35:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 102c1303304a, 38961, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:50.949817Z","level":"error","event":"25/08/31 18:35:50 INFO BlockManagerMasterEndpoint: Registering block manager 102c1303304a:38961 with 434.4 MiB RAM, BlockManagerId(driver, 102c1303304a, 38961, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:50.956078Z","level":"error","event":"25/08/31 18:35:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 102c1303304a, 38961, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:50.962100Z","level":"error","event":"25/08/31 18:35:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 102c1303304a, 38961, None)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.563178Z","level":"error","event":"25/08/31 18:35:51 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.563450Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.563584Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.563697Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.563808Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.563919Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.564031Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.564138Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.564247Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.564368Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.564478Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.564608Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.564718Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.564825Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.564928Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.565029Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.565136Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.565240Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.565353Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.565459Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.565566Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.565678Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.565788Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.565894Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.566000Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.566110Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.566217Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.566345Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.566454Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.566560Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:51.566664Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.252638Z","level":"error","event":"25/08/31 18:35:54 INFO SparkContext: Invoking stop() from shutdown hook","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.259732Z","level":"error","event":"25/08/31 18:35:54 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:539.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.266716Z","level":"error","event":"25/08/31 18:35:54 INFO SparkUI: Stopped Spark web UI at http://102c1303304a:4041","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.278690Z","level":"error","event":"25/08/31 18:35:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.298502Z","level":"error","event":"25/08/31 18:35:54 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.303072Z","level":"error","event":"25/08/31 18:35:54 INFO MemoryStore: MemoryStore cleared","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.303224Z","level":"error","event":"25/08/31 18:35:54 INFO BlockManager: BlockManager stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.308680Z","level":"error","event":"25/08/31 18:35:54 INFO BlockManagerMaster: BlockManagerMaster stopped","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.314951Z","level":"error","event":"25/08/31 18:35:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.368412Z","level":"error","event":"25/08/31 18:35:54 INFO SparkContext: Successfully stopped SparkContext","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.374269Z","level":"error","event":"25/08/31 18:35:54 INFO ShutdownHookManager: Shutdown hook called","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.376625Z","level":"error","event":"25/08/31 18:35:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-3cf028e5-0049-4587-92fd-9f62af2436cd","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.376833Z","level":"error","event":"25/08/31 18:35:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-5184a8c4-c634-44cf-8583-8a9febebecd0/pyspark-4a99e705-9436-4c69-9ca3-14a43d39f4f2","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:35:54.384260Z","level":"error","event":"25/08/31 18:35:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-5184a8c4-c634-44cf-8583-8a9febebecd0","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:00.045464","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:50:03.780987Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:04.756812Z","level":"error","event":"25/08/31 18:50:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:05.234407Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:05.244832Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:05.245116Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.849906Z","level":"error","event":"25/08/31 18:50:09 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.850601Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.851787Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.852017Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.852128Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.852227Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.852346Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.852443Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.852536Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.852629Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.852717Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.852806Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.852900Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.853001Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.853101Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.853200Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.853317Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.853426Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.853522Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.853613Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.853702Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.853793Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.853884Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.854006Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.854100Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.856548Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.856718Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.856823Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.856922Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.857022Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:09.857125Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:43.183607","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:50:43.711152Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:45.873601Z","level":"error","event":"25/08/31 18:50:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:46.552891Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:46.582890Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:46.583170Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.984388Z","level":"error","event":"25/08/31 18:50:52 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.984829Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.985008Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.985120Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.985217Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.985323Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.985421Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.985539Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.985656Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.985830Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.985967Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.986096Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.986228Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.986378Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.986493Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.986598Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.986696Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.986793Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.986875Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.987098Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.988279Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.989607Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.989767Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.989882Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.989980Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.990082Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.990180Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.990270Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.990397Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.993396Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:50:52.993924Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:29.376459","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:51:30.129545Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:32.755444Z","level":"error","event":"25/08/31 18:51:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:33.097772Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:33.106878Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:33.107132Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:35.105624Z","level":"error","event":"25/08/31 18:51:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.060051Z","level":"error","event":"25/08/31 18:51:39 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.060370Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.060489Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.060582Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.060670Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.060754Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.060833Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.060901Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.060953Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061022Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061088Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061142Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061195Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061249Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061332Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061390Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061445Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061497Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061549Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061600Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061652Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061703Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061754Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061806Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061857Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061908Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.061960Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.062010Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.062057Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.062105Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:51:39.062152Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:12.728129","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:52:13.201003Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:15.239437Z","level":"error","event":"25/08/31 18:52:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:15.591409Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:15.599312Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:15.599597Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.414612Z","level":"error","event":"25/08/31 18:52:19 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.414979Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.415127Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.415270Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.415405Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.415510Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.415576Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.415664Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.415729Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.415789Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.415867Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.415932Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.415991Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416059Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416118Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416177Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416233Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416291Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416366Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416423Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416498Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416557Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416612Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416668Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416725Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416780Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416833Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416884Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416936Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.416989Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:19.417042Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:53.167123","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T18:52:53.821786Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:55.600491Z","level":"error","event":"25/08/31 18:52:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:55.898734Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:55.906552Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:55.906781Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.196486Z","level":"error","event":"25/08/31 18:52:59 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.196814Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.196934Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197045Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197132Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197217Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197286Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197388Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197457Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197525Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197589Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197655Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197723Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197788Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197845Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197898Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.197954Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198009Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198067Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198120Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198177Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198231Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198284Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198350Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198405Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198457Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198525Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198584Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198639Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198696Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T18:52:59.198751Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:21.234085","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:00:25.867556Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:26.337738Z","level":"error","event":"25/08/31 19:00:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:26.749335Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:26.755609Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:26.755852Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:28.467743Z","level":"error","event":"25/08/31 19:00:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.220480Z","level":"error","event":"25/08/31 19:00:31 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.220746Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.220863Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.220975Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.221081Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.221186Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.221292Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.221410Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.221517Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.221632Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.221756Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.221860Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.221960Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.222055Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.222158Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.222256Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.222387Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.222492Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.222592Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.222688Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.222788Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.222888Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.222989Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.223093Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.223194Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.223305Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.223413Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.223518Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.223622Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.223718Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:00:31.223802Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:05.120690","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:01:05.740578Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:09.213748Z","level":"error","event":"25/08/31 19:01:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:09.621323Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:09.631154Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:09.631424Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:11.559116Z","level":"error","event":"25/08/31 19:01:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.191785Z","level":"error","event":"25/08/31 19:01:15 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.192143Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.192570Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.192711Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.192824Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.192946Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.193040Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.193127Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.193210Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.193290Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.193386Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.193480Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.193564Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.193655Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.193760Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.193877Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.193982Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.194098Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.194209Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.194347Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.194452Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.194546Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.194648Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.194755Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.194847Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.194946Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.195046Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.195139Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.195234Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.195368Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:15.195469Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:50.836165","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:01:51.495389Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:54.180617Z","level":"error","event":"25/08/31 19:01:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:54.569947Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:54.579411Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:54.579669Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.181554Z","level":"error","event":"25/08/31 19:01:59 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.181864Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.181974Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.182075Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.182175Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.182268Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.182378Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.182469Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.182559Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.182647Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.182766Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.182869Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.182973Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.183076Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.183182Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.183286Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.183405Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.183510Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.183613Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.183824Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.184090Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.184231Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.184341Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.184457Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.184564Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.184668Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.184781Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.184885Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.184988Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.185088Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:01:59.185192Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:34.993606","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:02:35.746393Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:38.172468Z","level":"error","event":"25/08/31 19:02:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:38.580660Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:38.590335Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:38.590555Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:39.916199Z","level":"error","event":"25/08/31 19:02:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.042708Z","level":"error","event":"25/08/31 19:02:42 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043015Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043220Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043389Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043507Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043574Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043628Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043679Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043731Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043783Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043836Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043888Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043934Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.043980Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044026Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044073Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044123Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044190Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044238Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044283Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044339Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044387Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044433Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044479Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044525Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044570Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044623Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044672Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044718Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044764Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:02:42.044809Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:14.772199","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:03:15.290255Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:17.351420Z","level":"error","event":"25/08/31 19:03:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:17.684860Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:17.690117Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:17.690334Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:18.840908Z","level":"error","event":"25/08/31 19:03:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.005350Z","level":"error","event":"25/08/31 19:03:21 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.005643Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.005757Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.005855Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.005923Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.005999Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006054Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006106Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006158Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006211Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006289Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006376Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006431Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006483Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006535Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006586Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006636Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006685Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006735Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006786Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006835Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006885Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006934Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.006985Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.007037Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.007090Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.007145Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.007197Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.007247Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.007311Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:21.007381Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:55.472154","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:03:56.274483Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:58.399696Z","level":"error","event":"25/08/31 19:03:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:58.721538Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:58.728603Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:03:58.728851Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:00.093156Z","level":"error","event":"25/08/31 19:04:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.505777Z","level":"error","event":"25/08/31 19:04:02 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.506140Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.506311Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.506439Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.506564Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.506672Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.506781Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.506871Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.506943Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.507017Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.507099Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.507197Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.507286Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.507394Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.507491Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.507582Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.507694Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.507773Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.507846Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.508104Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.508356Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.508466Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.508576Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.508680Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.508796Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.508913Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.509028Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.509137Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.509224Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.509329Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:02.509452Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:36.461450","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:04:37.283027Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:39.854074Z","level":"error","event":"25/08/31 19:04:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:40.145810Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:40.153203Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:40.153456Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.421292Z","level":"error","event":"25/08/31 19:04:43 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.422193Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.422377Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.422481Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.422582Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.422675Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.422759Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.422859Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.422966Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.423059Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.423147Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.423233Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.423334Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.423437Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.423548Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.423640Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.423739Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.423860Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.423977Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.424075Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.424174Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.424288Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.424418Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.424592Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.424853Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.424965Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.425241Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.425423Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.425552Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.425666Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:04:43.425760Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:16.800359","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:05:17.504866Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:19.667936Z","level":"error","event":"25/08/31 19:05:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:19.956214Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:19.962266Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:19.962422Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:21.225596Z","level":"error","event":"25/08/31 19:05:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.358636Z","level":"error","event":"25/08/31 19:05:23 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.358921Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359073Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359162Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359249Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359335Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359392Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359443Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359492Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359543Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359592Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359642Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359693Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359752Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359801Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359850Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359903Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.359955Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360005Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360056Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360106Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360158Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360209Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360261Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360326Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360380Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360436Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360501Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360556Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360607Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:23.360660Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:56.907420","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:05:57.655871Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:59.592543Z","level":"error","event":"25/08/31 19:05:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:59.908406Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:59.917435Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:05:59.917862Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.033861Z","level":"error","event":"25/08/31 19:06:03 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.034344Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.034622Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.034810Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.034932Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.034983Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035061Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035127Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035178Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035227Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035392Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035543Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035693Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035752Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035810Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035867Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035926Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.035987Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036044Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036100Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036156Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036212Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036292Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036385Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036451Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036509Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036579Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036632Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036684Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036737Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:03.036791Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:36.414535","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:06:36.933399Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:39.227490Z","level":"error","event":"25/08/31 19:06:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:39.539339Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:39.544583Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:39.544768Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:40.835818Z","level":"error","event":"25/08/31 19:06:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927009Z","level":"error","event":"25/08/31 19:06:42 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927274Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927373Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927446Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927507Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927564Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927631Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927685Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927740Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927796Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927853Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927906Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.927961Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928017Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928071Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928127Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928183Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928251Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928316Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928371Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928424Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928473Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928519Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928568Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928616Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928664Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928711Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928759Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928806Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928859Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:06:42.928906Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:16.360992","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:07:16.958880Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:19.527228Z","level":"error","event":"25/08/31 19:07:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:19.914652Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:19.914882Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:19.915015Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:21.262597Z","level":"error","event":"25/08/31 19:07:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.086420Z","level":"error","event":"25/08/31 19:07:25 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.086774Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.086913Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.087028Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.087132Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.087254Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.087384Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.087496Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.088332Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.088480Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.088578Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.088689Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.088814Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.089135Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.089275Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.089400Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.089512Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.089619Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.089720Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.089819Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.089919Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.090041Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.090139Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.090237Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.090349Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.090411Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.090737Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.090814Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.090869Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.090937Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:25.091079Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:07:59.399447","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:07:59.929005Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:01.976975Z","level":"error","event":"25/08/31 19:08:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:02.250804Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:02.256933Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:02.257220Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:03.560871Z","level":"error","event":"25/08/31 19:08:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.024171Z","level":"error","event":"25/08/31 19:08:06 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.024487Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.024619Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.024735Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.024833Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.024944Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.025053Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.025153Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.025254Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.025372Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.025463Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.025559Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.025658Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.025758Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.025862Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.025963Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.026063Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.026158Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.026254Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.026363Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.026473Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.026570Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.026663Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.026754Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.026843Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.026936Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.027028Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.027137Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.027242Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.027339Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:06.027432Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:40.439398","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:08:40.928554Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:43.291472Z","level":"error","event":"25/08/31 19:08:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:43.608395Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:43.614936Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:43.615178Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.072054Z","level":"error","event":"25/08/31 19:08:47 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.072425Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.072552Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.072618Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.072677Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.072735Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.072793Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.072850Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.072917Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.072976Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073031Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073084Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073156Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073213Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073269Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073338Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073394Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073446Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073500Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073557Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073617Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073674Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073729Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073783Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073843Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073903Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.073960Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.074015Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.074066Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.074117Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:08:47.074172Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:16.656281","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:23:21.493899Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:21.494043Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:21.972280Z","level":"error","event":"25/08/31 19:23:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:22.350458Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:22.350733Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:22.350859Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.874366Z","level":"error","event":"25/08/31 19:23:26 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.874633Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.874754Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.874864Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.874967Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.875069Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.875169Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.875269Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.875383Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.875483Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.875580Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.875679Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.875788Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.875897Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.876004Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.876110Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.876214Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.876353Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.876463Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.876565Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.876664Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.876760Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.876856Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.876947Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.877044Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.877145Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.877245Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.877357Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.877454Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.877551Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:26.877649Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682236Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682420Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682489Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682547Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682599Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682649Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682699Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682747Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682805Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682855Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682904Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682952Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.683000Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.683048Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.683096Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.683142Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.683189Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.683235Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.683282Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.683344Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:23:29.682977","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:24:00.696008","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:24:01.344426Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:02.377076Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:03.656410Z","level":"error","event":"25/08/31 19:24:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:03.891181Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:03.899463Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:03.899719Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:05.331635Z","level":"error","event":"25/08/31 19:24:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.695007Z","level":"error","event":"25/08/31 19:24:07 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.695340Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.695455Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.695552Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.695627Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.695683Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.695773Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.695871Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.695967Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696066Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696162Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696260Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696339Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696396Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696449Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696499Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696552Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696603Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696661Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696747Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696836Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.696932Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.697035Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.697133Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.697230Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.697341Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.697435Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.697524Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.697613Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.697703Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:07.697788Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.243671Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.243891Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244007Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244086Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244176Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244272Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244392Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244461Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244515Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244566Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244616Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244667Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244717Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244767Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244818Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244867Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244917Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.244967Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.245017Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.245068Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:10.243845","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:24:40.999404","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:24:41.472495Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:42.419870Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:43.486079Z","level":"error","event":"25/08/31 19:24:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:43.784320Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:43.784595Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:43.784699Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:45.143147Z","level":"error","event":"25/08/31 19:24:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.036045Z","level":"error","event":"25/08/31 19:24:47 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.036292Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.036527Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.036797Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.036914Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037000Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037089Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037166Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037258Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037356Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037440Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037521Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037611Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037702Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037792Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037893Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.037982Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.038065Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.038151Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.038236Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.038339Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.038431Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.038515Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.038602Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.038785Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.039036Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.039165Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.039248Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.039363Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.039445Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:47.039528Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.143555Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144053Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144158Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144246Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144317Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144390Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144443Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144526Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144617Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144705Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144796Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144881Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144970Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.145061Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.145148Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.145235Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.145335Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.145435Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.145533Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.145629Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:24:49.144046","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:25:19.788163","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:25:20.249630Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:21.188254Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:22.203780Z","level":"error","event":"25/08/31 19:25:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:22.490241Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:22.495836Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:22.496087Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.044364Z","level":"error","event":"25/08/31 19:25:25 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.044573Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.044652Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.044723Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.044787Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.044847Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.044909Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.044991Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.045104Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.045202Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.045322Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.045428Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.045532Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.045631Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.045731Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.045834Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.045941Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046030Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046089Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046150Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046210Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046259Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046318Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046368Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046420Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046469Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046519Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046567Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046613Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046660Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:25.046719Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.937668Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.937999Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.938102Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.938205Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.938457Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.938675Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.938758Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.938817Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.938875Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.938930Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.939006Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.939154Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.939273Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.939365Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.939431Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.939491Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.939552Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.939614Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.939709Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.939825Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:25:26.937796","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:25:58.436980","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:25:58.843733Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:25:59.629873Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:00.484595Z","level":"error","event":"25/08/31 19:26:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:00.750243Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:00.759428Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:00.759700Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.101019Z","level":"error","event":"25/08/31 19:26:04 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.102556Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.102811Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.102939Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.103047Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.103123Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.103184Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.103260Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.103381Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.103497Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.103605Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.103707Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.103815Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.103918Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.103994Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.104065Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.104156Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.104220Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.104280Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.104356Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.104453Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.104561Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.104666Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.104779Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.104882Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.104986Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.105081Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.105190Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.105280Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.105401Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:04.105467Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156084Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156259Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156350Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156409Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156460Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156508Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156566Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156613Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156660Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156707Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156753Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156799Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156845Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156891Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156938Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156985Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.157031Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.157094Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.157143Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.157190Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:06.156183","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:26:37.306093","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:26:37.872950Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:38.798686Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:39.812728Z","level":"error","event":"25/08/31 19:26:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:40.062159Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:40.069323Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:40.069593Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.840566Z","level":"error","event":"25/08/31 19:26:43 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.840889Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.841011Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.841110Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.841207Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.841314Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.841420Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.841513Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.841609Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.841714Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.841806Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.841915Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.842025Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.842129Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.842221Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.842338Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.842431Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.842529Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.842638Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.842735Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.842826Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.842911Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.842996Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.843203Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.843290Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.843447Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.843538Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.843634Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.844967Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.845181Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:43.845289Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.514149Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.514451Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.514564Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.514661Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.514748Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.514827Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.514906Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.514986Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.515066Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.515140Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.515214Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.515314Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.515433Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.515534Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.515626Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.515721Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.515822Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.515927Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.516024Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.516130Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:26:46.514327","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:27:17.520412","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:27:18.159948Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:18.956357Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:20.351437Z","level":"error","event":"25/08/31 19:27:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:20.657374Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:20.666941Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:20.667287Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.898027Z","level":"error","event":"25/08/31 19:27:23 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.898320Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.898438Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.898537Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.898629Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.898741Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.898843Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.898936Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.899029Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.899118Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.899219Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.899356Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.899464Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.899575Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.899668Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.899762Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.899853Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.899940Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.900024Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.900118Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.900209Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.900308Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.900402Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.900490Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.900585Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.900674Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.900763Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.900869Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.900960Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.901049Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:23.901138Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118144Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118347Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118415Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118471Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118520Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118569Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118618Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118666Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118713Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118761Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118808Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118857Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118905Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118952Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118999Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.119045Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.119102Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.119163Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.119223Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.119285Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:26.118365","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:27:56.796760","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:27:57.441630Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:58.402686Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:27:59.557787Z","level":"error","event":"25/08/31 19:27:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:59.831402Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:59.840741Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:27:59.841054Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:00.904898Z","level":"error","event":"25/08/31 19:28:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.702668Z","level":"error","event":"25/08/31 19:28:02 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.703118Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.703279Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.703403Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.703505Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.703602Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.703701Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.703795Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.703891Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.703984Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.704077Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.704169Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.704264Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.704372Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.704464Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.704552Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.704643Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.704733Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.704821Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.704908Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.705008Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.705093Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.705181Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.705269Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.705377Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.705473Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.705567Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.705652Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.705735Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.705816Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:02.705898Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.845866Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.846137Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.846239Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.846369Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.846488Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.846600Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.846709Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.846809Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.846893Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.846985Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.847083Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.847266Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.847386Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.847460Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.847521Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.847581Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.847643Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.847699Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.847755Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.847813Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:04.846159","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:28:35.618805","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:28:36.153805Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:37.188272Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:38.848532Z","level":"error","event":"25/08/31 19:28:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:39.094323Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:39.101716Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:39.101952Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:40.440919Z","level":"error","event":"25/08/31 19:28:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.792573Z","level":"error","event":"25/08/31 19:28:42 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.792819Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.792909Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.792993Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793075Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793146Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793224Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793288Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793359Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793423Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793475Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793539Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793608Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793685Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793774Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793853Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793920Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.793987Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794037Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794087Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794135Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794184Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794233Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794282Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794377Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794439Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794494Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794549Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794620Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794693Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:42.794768Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.182416Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.182596Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.182671Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.182721Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.182769Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.182830Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.182878Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.182926Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.182996Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.183046Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.183092Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.183242Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.183294Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.183357Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.183406Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.183458Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.183506Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.183554Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.183599Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.183645Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:28:45.182555","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:29:16.212019","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:29:16.797139Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:17.683004Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:18.692191Z","level":"error","event":"25/08/31 19:29:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:18.918994Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:18.927008Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:18.927201Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:20.048507Z","level":"error","event":"25/08/31 19:29:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.982790Z","level":"error","event":"25/08/31 19:29:21 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983030Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983130Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983216Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983308Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983399Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983453Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983501Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983561Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983609Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983657Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983705Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983753Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983799Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983846Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983892Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983937Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.983983Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984029Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984075Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984121Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984167Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984212Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984258Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984315Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984387Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984441Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984487Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984537Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984596Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:21.984644Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.354054Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.354550Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.354692Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.354801Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.354909Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.355012Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.355116Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.355225Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.355336Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.355613Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.355787Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.355896Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.355997Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.356092Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.356189Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.356284Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.356397Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.356493Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.356589Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.356682Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:24.354287","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:29:55.324851","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:29:55.766438Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:56.559383Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:29:57.500493Z","level":"error","event":"25/08/31 19:29:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:57.679780Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:57.686821Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:57.687047Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:29:58.929654Z","level":"error","event":"25/08/31 19:29:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.921860Z","level":"error","event":"25/08/31 19:30:00 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.922196Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.922348Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.922457Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.922574Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.922679Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.922781Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.922878Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.922983Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.923073Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.923161Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.923249Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.923346Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.923441Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.923538Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.923635Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.923733Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.923828Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.923913Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.923992Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.924075Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.924168Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.924262Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.924389Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.924486Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.924578Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.924672Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.924762Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.924852Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.924945Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:00.925035Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.420421Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.420647Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.420741Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.420806Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.420855Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.420903Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.420959Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421007Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421055Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421100Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421146Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421191Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421238Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421286Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421356Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421404Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421449Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421494Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421538Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.421584Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:03.420611","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:30:34.269851","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:30:34.731999Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:35.492553Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:36.458356Z","level":"error","event":"25/08/31 19:30:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:36.692244Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:36.699453Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:36.699692Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.765816Z","level":"error","event":"25/08/31 19:30:39 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.766711Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.766916Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.766992Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.767072Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.767154Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.767236Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.767340Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.767424Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.767504Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.767584Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.767665Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.767746Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.767837Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.767927Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768021Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768100Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768182Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768255Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768324Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768376Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768438Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768502Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768569Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768642Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768698Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768749Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768809Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768874Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768923Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:39.768971Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.835254Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.835515Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.835650Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.835734Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.835820Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.835930Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836021Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836112Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836202Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836273Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836340Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836389Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836435Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836540Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836688Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836739Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836791Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836840Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836886Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.836937Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:30:41.835500","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:31:13.339414","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:31:13.820945Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:14.851005Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:15.947240Z","level":"error","event":"25/08/31 19:31:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:16.200585Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:16.211355Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:16.211664Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:17.400752Z","level":"error","event":"25/08/31 19:31:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.461452Z","level":"error","event":"25/08/31 19:31:19 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.461865Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.462012Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.462128Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.462236Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.462363Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.462460Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.462553Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.462655Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.462754Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.462917Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.463222Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.463406Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.463511Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.463613Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.463705Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.463797Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.463896Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.463994Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.464099Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.464194Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.464290Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.464414Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.464516Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.464610Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.464697Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.464787Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.464885Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.464980Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.465130Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:19.465449Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.996340Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.996573Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.996660Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.996719Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.996772Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.996824Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.996874Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.996925Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.996975Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.997024Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.997073Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.997123Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.997173Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.997222Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.997273Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.997336Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.997386Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.997436Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.997485Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.997536Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:21.996548","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:31:52.712502","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:31:53.183731Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:54.078518Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:31:54.985807Z","level":"error","event":"25/08/31 19:31:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:55.214023Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:55.219709Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:55.219872Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.253586Z","level":"error","event":"25/08/31 19:31:58 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.253813Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.253913Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.253987Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254038Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254091Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254143Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254204Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254255Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254316Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254374Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254423Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254471Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254520Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254567Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254615Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254664Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254712Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254761Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254811Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254856Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254899Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254943Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.254995Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.255046Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.255090Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.255135Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.255178Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.255227Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.255271Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:31:58.255324Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.120952Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121141Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121205Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121261Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121330Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121387Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121439Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121491Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121549Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121596Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121643Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121687Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121732Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121777Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121822Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121867Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121911Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121956Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.122001Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.122047Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:00.121078","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:32:30.699314","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:32:31.231222Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:32.090753Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:32.980474Z","level":"error","event":"25/08/31 19:32:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:33.186105Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:33.192680Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:33.192911Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.087723Z","level":"error","event":"25/08/31 19:32:36 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088020Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088124Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088208Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088287Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088383Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088461Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088539Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088617Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088676Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088722Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088770Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088816Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088872Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088920Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.088968Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089016Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089074Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089160Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089251Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089335Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089395Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089463Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089517Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089567Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089613Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089661Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089704Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089746Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089790Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:36.089833Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.551733Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.551996Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.552124Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.552232Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.552357Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.552463Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.552558Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.552646Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.552736Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.552826Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.552912Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.552997Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.553079Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.553168Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.553273Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.553383Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.553480Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.553570Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.553658Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.553758Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:32:38.551962","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:33:09.818251","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:33:10.416530Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:11.169765Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:12.491574Z","level":"error","event":"25/08/31 19:33:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:12.899041Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:12.918462Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:12.918722Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.237032Z","level":"error","event":"25/08/31 19:33:16 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.237279Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.237428Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.237541Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.237650Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.237745Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.237848Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.237946Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.238052Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.238154Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.238261Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.238387Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.238492Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.238599Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.238700Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.238801Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.238904Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.239009Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.239136Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.239249Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.239366Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.239471Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.239595Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.239701Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.239825Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.239928Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.240032Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.240136Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.240239Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.240363Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:16.240471Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.505366Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.505668Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.505798Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.505919Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.506026Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.506134Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.506233Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.506340Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.506467Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.506572Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.506680Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.506790Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.506882Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.506979Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.507073Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.507163Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.507258Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.507364Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.507459Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.507563Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:18.505497","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:33:49.707504","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:33:50.195294Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:51.263275Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:52.396401Z","level":"error","event":"25/08/31 19:33:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:52.647201Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:52.652082Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:52.652250Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:53.730994Z","level":"error","event":"25/08/31 19:33:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.963391Z","level":"error","event":"25/08/31 19:33:55 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.963772Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.963851Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.963920Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.963993Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964068Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964128Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964198Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964253Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964323Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964378Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964433Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964505Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964561Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964614Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964666Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964738Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964807Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964899Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.964969Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.965046Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.965117Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.965178Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.965231Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.965285Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.965349Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.965404Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.965457Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.965513Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.965568Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:55.965636Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147028Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147227Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147320Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147376Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147426Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147474Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147523Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147570Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147619Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147666Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147711Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147756Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147802Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147849Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147895Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147943Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147990Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.148315Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.148379Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.148429Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:33:58.147213","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:34:29.535143","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:34:30.134793Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:31.216750Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:32.388717Z","level":"error","event":"25/08/31 19:34:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:32.650279Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:32.656362Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:32.656617Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:33.879767Z","level":"error","event":"25/08/31 19:34:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.077009Z","level":"error","event":"25/08/31 19:34:36 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.077561Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.077731Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.077852Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.077949Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.078061Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.078872Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.079057Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.079178Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.079282Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.079426Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.079535Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.079637Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.079798Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.080072Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.080227Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.080365Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.080468Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.080568Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.080662Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.080757Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.080846Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.080945Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.081050Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.081155Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.081256Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.081398Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.081524Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.081623Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.081723Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:36.081823Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.663950Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.664170Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.664264Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.664365Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.664459Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.664552Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.664643Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.664734Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.664822Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.664909Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.665003Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.665092Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.665175Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.665233Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.665342Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.665423Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.665474Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.665523Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.665583Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.665634Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:34:38.664119","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:35:09.974476","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:35:10.529460Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:11.413245Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:12.516188Z","level":"error","event":"25/08/31 19:35:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:12.730311Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:12.737457Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:12.737642Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:13.887636Z","level":"error","event":"25/08/31 19:35:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.077496Z","level":"error","event":"25/08/31 19:35:16 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.077874Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.077961Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078036Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078097Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078152Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078206Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078259Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078335Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078395Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078449Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078507Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078605Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078693Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078779Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078836Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078890Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078943Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.078997Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079050Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079120Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079173Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079224Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079275Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079347Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079401Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079455Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079511Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079564Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079616Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:16.079667Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.400645Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.400824Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.400886Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.400934Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.400986Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401031Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401078Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401121Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401163Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401207Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401249Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401318Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401370Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401415Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401459Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401502Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401544Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401587Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401629Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.401672Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:18.400809","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:35:49.314064","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:35:49.816515Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:50.681869Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:51.505785Z","level":"error","event":"25/08/31 19:35:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:51.721446Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:51.721729Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:51.721846Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:52.831548Z","level":"error","event":"25/08/31 19:35:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.500552Z","level":"error","event":"25/08/31 19:35:54 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.501640Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.501832Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.501948Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.502054Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.502147Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.502238Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.502350Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.502439Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.502523Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.502612Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.502704Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.502787Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.502869Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.502970Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503051Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503131Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503214Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503319Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503403Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503490Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503571Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503651Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503735Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503815Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503894Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.503976Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.504059Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.504140Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.504223Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:54.504322Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.304961Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.305364Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.305435Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.305634Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.305697Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.305759Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.305814Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.305861Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.305908Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.305956Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.306007Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.306055Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.306104Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.306159Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.306204Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.306252Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.306304Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.306356Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.306401Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.306449Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:35:56.277025","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:36:27.339272","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:36:27.932939Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:28.850365Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:29.760760Z","level":"error","event":"25/08/31 19:36:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:29.976311Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:29.986026Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:29.986283Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:31.398105Z","level":"error","event":"25/08/31 19:36:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.183481Z","level":"error","event":"25/08/31 19:36:33 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.183797Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.183923Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184012Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184093Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184175Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184255Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184355Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184469Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184557Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184644Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184722Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184797Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184876Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.184952Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.185028Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.185104Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.185182Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.185261Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.185363Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.185444Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.185522Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.185605Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.185684Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.185759Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.185834Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.186042Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.186279Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.186394Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.186509Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:33.186597Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.149851Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150083Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150145Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150194Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150241Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150285Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150342Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150387Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150432Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150475Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150518Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150559Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150601Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150642Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150686Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150728Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150782Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150825Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150868Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.150911Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:36:35.149881","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
{"timestamp":"2025-08-31T19:37:05.973548","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-31T19:37:06.550381Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:07.432719Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:08.477338Z","level":"error","event":"25/08/31 19:37:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:08.672838Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:08.680987Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:08.681237Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.557636Z","level":"error","event":"25/08/31 19:37:11 WARN SparkSession: Cannot use org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions to configure session extensions.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.557828Z","level":"error","event":"java.lang.ClassNotFoundException: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.557892Z","level":"error","event":"\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.557977Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558031Z","level":"error","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558080Z","level":"error","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558134Z","level":"error","event":"\tat java.base/java.lang.Class.forName(Class.java:467)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558183Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName(SparkClassUtils.scala:41)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558230Z","level":"error","event":"\tat org.apache.spark.util.SparkClassUtils.classForName$(SparkClassUtils.scala:36)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558278Z","level":"error","event":"\tat org.apache.spark.util.Utils$.classForName(Utils.scala:99)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558336Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2(SparkSession.scala:1056)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558386Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.$anonfun$applyExtensions$2$adapted(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558437Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558484Z","level":"error","event":"\tat scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558534Z","level":"error","event":"\tat scala.collection.AbstractIterable.foreach(Iterable.scala:935)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558589Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.org$apache$spark$sql$classic$SparkSession$$applyExtensions(SparkSession.scala:1054)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558640Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession$.applyAndLoadExtensions(SparkSession.scala:1038)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558692Z","level":"error","event":"\tat org.apache.spark.sql.classic.SparkSession.<init>(SparkSession.scala:116)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558744Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558794Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558844Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558894Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558944Z","level":"error","event":"\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.558991Z","level":"error","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.559047Z","level":"error","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.559100Z","level":"error","event":"\tat py4j.Gateway.invoke(Gateway.java:238)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.559151Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.559201Z","level":"error","event":"\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.559248Z","level":"error","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.559305Z","level":"error","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:11.559356Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stderr","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.122864Z","level":"info","event":"Khng tm thy Iceberg SparkCatalog: An error occurred while calling z:java.lang.Class.forName.","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.123123Z","level":"info","event":": java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.123245Z","level":"info","event":"\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.123374Z","level":"info","event":"\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.123478Z","level":"info","event":"\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.123583Z","level":"info","event":"\tat java.base/java.lang.Class.forName0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.123672Z","level":"info","event":"\tat java.base/java.lang.Class.forName(Class.java:375)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.123762Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.123854Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.123950Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.124050Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.124154Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.124241Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.124340Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.124435Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.124526Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.124631Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.124731Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.124825Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.124917Z","level":"info","event":"","chan":"stdout","logger":"processor"}
{"timestamp":"2025-08-31T19:37:14.123087","level":"error","event":"Failed to import: /opt/airflow/dags/etl_data_weather.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling z:java.lang.Class.forName.\n: java.lang.ClassNotFoundException: org.apache.iceberg.spark.SparkCatalog\n\tat java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n\tat java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)\n\tat java.base/java.lang.Class.forName0(Native Method)\n\tat java.base/java.lang.Class.forName(Class.java:375)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":72,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1362,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":282,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":327,"name":"get_return_value"}]}]}
