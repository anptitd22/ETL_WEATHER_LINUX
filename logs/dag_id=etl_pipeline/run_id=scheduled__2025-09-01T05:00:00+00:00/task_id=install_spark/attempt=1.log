{"timestamp":"2025-09-01T05:05:03.870508","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-01T05:05:03.870967","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:05:04.507953Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:05.232034Z","level":"error","event":"25/09/01 05:05:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-01T05:05:05.367811Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-01T05:05:05.367991Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-01T05:05:07.511693Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.092377Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.092501Z","level":"info","event":" Previous state of the Task instance: queued","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.092547Z","level":"info","event":"Current task name:install_spark","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.092580Z","level":"info","event":"Dag name:etl_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.571752Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.572071Z","level":"info","event":"Spark session started.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606391Z","level":"info","event":"spark.hadoop.fs.s3a.vectored.read.min.seek.size = 131072","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606568Z","level":"info","event":"spark.hadoop.fs.s3a.access.key = admin","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606609Z","level":"info","event":"spark.app.submitTime = 1756703105354","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606644Z","level":"info","event":"spark.hadoop.fs.s3a.threads.max = 10","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606679Z","level":"info","event":"spark.hadoop.fs.s3a.secret.key = admin12345","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606711Z","level":"info","event":"spark.hadoop.fs.s3a.connection.ssl.enabled = false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606744Z","level":"info","event":"spark.hadoop.fs.s3a.path.style.access = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606774Z","level":"info","event":"spark.app.id = local-1756703106160","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606808Z","level":"info","event":"spark.jars = /opt/spark/jars/hadoop-aws-3.3.6.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar,/opt/spark/jars/ojdbc11.jar,/opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar,/opt/spark/jars/iceberg-aws-bundle-1.9.2.jar","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606841Z","level":"info","event":"spark.hadoop.fs.s3a.connection.part.upload.timeout = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606885Z","level":"info","event":"spark.hadoop.fs.s3a.aws.credentials.provider = org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606919Z","level":"info","event":"spark.hadoop.fs.s3a.attempts.maximum = 3","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606950Z","level":"info","event":"spark.app.name = BAITEST","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.606999Z","level":"info","event":"spark.app.startTime = 1756703105534","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607139Z","level":"info","event":"spark.sql.adaptive.coalescePartitions.enabled = false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607182Z","level":"info","event":"spark.sql.catalog.local.type = hadoop","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607216Z","level":"info","event":"spark.hadoop.fs.s3a.connection.idle.time = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607248Z","level":"info","event":"spark.hadoop.fs.s3a.vectored.read.max.merged.size = 2097152","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607277Z","level":"info","event":"spark.hadoop.fs.s3a.connection.establish.timeout = 5000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607307Z","level":"info","event":"spark.serializer.objectStreamReset = 100","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607340Z","level":"info","event":"spark.repl.local.jars = file:///opt/spark/jars/hadoop-aws-3.3.6.jar,file:///opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar,file:///opt/spark/jars/ojdbc11.jar,file:///opt/spark/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar,file:///opt/spark/jars/iceberg-aws-bundle-1.9.2.jar","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607375Z","level":"info","event":"spark.master = local[*]","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607406Z","level":"info","event":"spark.sql.catalog.local.warehouse = s3a://warehouse/","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607436Z","level":"info","event":"spark.submit.deployMode = client","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607467Z","level":"info","event":"spark.sql.warehouse.dir = file:/opt/airflow/spark-warehouse","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607499Z","level":"info","event":"spark.sql.adaptive.enabled = false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607529Z","level":"info","event":"spark.hadoop.fs.s3a.retry.limit = 5","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607569Z","level":"info","event":"spark.hadoop.fs.s3a.multipart.size = 104857600","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607622Z","level":"info","event":"spark.driver.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607662Z","level":"info","event":"spark.driver.port = 33785","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607705Z","level":"info","event":"spark.hadoop.fs.s3a.connection.maximum = 15","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607755Z","level":"info","event":"spark.executor.extraClassPath = /opt/spark/jars/*","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607816Z","level":"info","event":"spark.hadoop.fs.s3a.socket.send.buffer = 65536","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607894Z","level":"info","event":"spark.executor.id = driver","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.607969Z","level":"info","event":"spark.hadoop.fs.s3a.connection.timeout = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608026Z","level":"info","event":"spark.app.initial.jar.urls = spark://4b16fab01bfb:33785/jars/iceberg-spark-runtime-4.0_2.13-1.9.2.jar,spark://4b16fab01bfb:33785/jars/hadoop-aws-3.3.6.jar,spark://4b16fab01bfb:33785/jars/ojdbc11.jar,spark://4b16fab01bfb:33785/jars/aws-java-sdk-bundle-1.12.787.jar,spark://4b16fab01bfb:33785/jars/iceberg-aws-bundle-1.9.2.jar","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608084Z","level":"info","event":"spark.hadoop.fs.s3a.retry.interval = 500","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608137Z","level":"info","event":"spark.driver.host = 4b16fab01bfb","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608192Z","level":"info","event":"spark.driver.extraClassPath = /opt/spark/jars/*","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608239Z","level":"info","event":"spark.sql.extensions = org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608293Z","level":"info","event":"spark.hadoop.fs.s3a.socket.recv.buffer = 65536","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608371Z","level":"info","event":"spark.hadoop.fs.s3a.impl = org.apache.hadoop.fs.s3a.S3AFileSystem","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608458Z","level":"info","event":"spark.sql.catalog.local = org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608521Z","level":"info","event":"spark.rdd.compress = True","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608572Z","level":"info","event":"spark.hadoop.fs.s3a.threads.keepalivetime = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608631Z","level":"info","event":"spark.executor.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608692Z","level":"info","event":"spark.hadoop.fs.s3a.multipart.purge.age = 86400","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608748Z","level":"info","event":"spark.submit.pyFiles =","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608803Z","level":"info","event":"spark.hadoop.fs.s3a.endpoint = http://minio:9000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608872Z","level":"info","event":"spark.ui.showConsoleProgress = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.608940Z","level":"info","event":"spark.hadoop.fs.s3a.fast.upload = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.609009Z","level":"info","event":"spark.hadoop.fs.s3a.impl.disable.cache = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.609065Z","level":"info","event":"spark.hadoop.fs.s3a.connection.request.timeout = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.609122Z","level":"info","event":"Spark session finished.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.850948","level":"info","event":"Done. Returned value was: None","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-09-01T05:05:08.870904Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.871018Z","level":"info","event":" Previous state of the Task instance: running","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:05:08.871054Z","level":"info","event":"Task operator:<Task(PythonOperator): install_spark>","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:25.649416","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-01T05:16:25.649781","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:16:26.320697Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:27.118183Z","level":"error","event":"25/09/01 05:16:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-01T05:16:27.347080Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-01T05:16:27.347380Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-01T05:16:28.479204Z","level":"error","event":"25/09/01 05:16:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-01T05:16:31.103039Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:31.646494Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:31.646760Z","level":"info","event":" Previous state of the Task instance: queued","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:31.646889Z","level":"info","event":"Current task name:install_spark","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:31.647013Z","level":"info","event":"Dag name:etl_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.318419Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.318727Z","level":"info","event":"Spark session started.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.362800Z","level":"info","event":"spark.hadoop.fs.s3a.vectored.read.min.seek.size = 131072","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363142Z","level":"info","event":"spark.hadoop.fs.s3a.access.key = admin","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363264Z","level":"info","event":"spark.hadoop.fs.s3a.threads.max = 10","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363323Z","level":"info","event":"spark.hadoop.fs.s3a.secret.key = admin12345","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363379Z","level":"info","event":"spark.hadoop.fs.s3a.connection.ssl.enabled = false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363434Z","level":"info","event":"spark.driver.port = 40403","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363493Z","level":"info","event":"spark.hadoop.fs.s3a.path.style.access = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363553Z","level":"info","event":"spark.hadoop.fs.s3a.connection.part.upload.timeout = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363616Z","level":"info","event":"spark.hadoop.fs.s3a.aws.credentials.provider = org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363720Z","level":"info","event":"spark.hadoop.fs.s3a.attempts.maximum = 3","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363783Z","level":"info","event":"spark.app.name = BAITEST","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363843Z","level":"info","event":"spark.app.id = local-1756703788553","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.363941Z","level":"info","event":"spark.sql.adaptive.coalescePartitions.enabled = false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.364002Z","level":"info","event":"spark.app.submitTime = 1756703787316","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.364058Z","level":"info","event":"spark.sql.catalog.local.type = hadoop","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.364118Z","level":"info","event":"spark.hadoop.fs.s3a.connection.idle.time = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.364187Z","level":"info","event":"spark.hadoop.fs.s3a.vectored.read.max.merged.size = 2097152","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.364253Z","level":"info","event":"spark.hadoop.fs.s3a.connection.establish.timeout = 5000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.364316Z","level":"info","event":"spark.driver.host = b019023520fc","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.364378Z","level":"info","event":"spark.serializer.objectStreamReset = 100","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.364450Z","level":"info","event":"spark.master = local[*]","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.364511Z","level":"info","event":"spark.sql.catalog.local.warehouse = s3a://warehouse/","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.364569Z","level":"info","event":"spark.submit.deployMode = client","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.365358Z","level":"info","event":"spark.sql.warehouse.dir = file:/opt/airflow/spark-warehouse","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.365472Z","level":"info","event":"spark.sql.adaptive.enabled = false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.365530Z","level":"info","event":"spark.repl.local.jars = file:///opt/spark/jars/hadoop-aws-3.3.6.jar,file:///opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar,file:///opt/spark/jars/ojdbc11.jar,file:///opt/spark/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar,file:///opt/spark/jars/iceberg-aws-bundle-1.9.2.jar","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.365625Z","level":"info","event":"spark.hadoop.fs.s3a.retry.limit = 5","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.365683Z","level":"info","event":"spark.hadoop.fs.s3a.multipart.size = 104857600","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.365754Z","level":"info","event":"spark.driver.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.365815Z","level":"info","event":"spark.hadoop.fs.s3a.connection.maximum = 15","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.365907Z","level":"info","event":"spark.executor.extraClassPath = /opt/spark/jars/*","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.365962Z","level":"info","event":"spark.hadoop.fs.s3a.socket.send.buffer = 65536","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366013Z","level":"info","event":"spark.executor.id = driver","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366064Z","level":"info","event":"spark.hadoop.fs.s3a.connection.timeout = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366117Z","level":"info","event":"spark.hadoop.fs.s3a.retry.interval = 500","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366174Z","level":"info","event":"spark.sql.extensions = org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366227Z","level":"info","event":"spark.driver.extraClassPath = /opt/spark/jars/*","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366287Z","level":"info","event":"spark.hadoop.fs.s3a.socket.recv.buffer = 65536","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366343Z","level":"info","event":"spark.hadoop.fs.s3a.impl = org.apache.hadoop.fs.s3a.S3AFileSystem","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366404Z","level":"info","event":"spark.sql.catalog.local = org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366462Z","level":"info","event":"spark.rdd.compress = True","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366520Z","level":"info","event":"spark.hadoop.fs.s3a.threads.keepalivetime = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366576Z","level":"info","event":"spark.executor.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366796Z","level":"info","event":"spark.jars = /opt/spark/jars/hadoop-aws-3.3.6.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar,/opt/spark/jars/ojdbc11.jar,/opt/spark/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar,/opt/spark/jars/iceberg-aws-bundle-1.9.2.jar","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.366959Z","level":"info","event":"spark.hadoop.fs.s3a.multipart.purge.age = 86400","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.367032Z","level":"info","event":"spark.app.startTime = 1756703787542","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.367094Z","level":"info","event":"spark.submit.pyFiles =","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.367151Z","level":"info","event":"spark.app.initial.jar.urls = spark://b019023520fc:40403/jars/aws-java-sdk-bundle-1.12.787.jar,spark://b019023520fc:40403/jars/iceberg-aws-bundle-1.9.2.jar,spark://b019023520fc:40403/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar,spark://b019023520fc:40403/jars/ojdbc11.jar,spark://b019023520fc:40403/jars/hadoop-aws-3.3.6.jar","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.367222Z","level":"info","event":"spark.hadoop.fs.s3a.endpoint = http://minio:9000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.367283Z","level":"info","event":"spark.ui.showConsoleProgress = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.367338Z","level":"info","event":"spark.hadoop.fs.s3a.fast.upload = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.367395Z","level":"info","event":"spark.hadoop.fs.s3a.impl.disable.cache = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.367448Z","level":"info","event":"spark.hadoop.fs.s3a.connection.request.timeout = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.367500Z","level":"info","event":"Spark session finished.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.709429","level":"info","event":"Done. Returned value was: None","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-09-01T05:16:33.744796Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.745152Z","level":"info","event":" Previous state of the Task instance: running","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:16:33.745254Z","level":"info","event":"Task operator:<Task(PythonOperator): install_spark>","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:04.406269","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-09-01T05:30:04.406784","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-09-01T05:30:05.167082Z","level":"info","event":"WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:06.137367Z","level":"error","event":"25/09/01 05:30:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-01T05:30:06.395709Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-01T05:30:06.395999Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-01T05:30:07.558267Z","level":"error","event":"25/09/01 05:30:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"task"}
{"timestamp":"2025-09-01T05:30:10.321293Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:10.885376Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:10.885582Z","level":"info","event":" Previous state of the Task instance: queued","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:10.885642Z","level":"info","event":"Current task name:install_spark","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:10.885696Z","level":"info","event":"Dag name:etl_pipeline","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.589632Z","level":"info","event":"Iceberg SparkCatalog OK.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.590091Z","level":"info","event":"Spark session started.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.777027Z","level":"info","event":"spark.hadoop.fs.s3a.connection.request.timeout = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.777253Z","level":"info","event":"spark.hadoop.fs.s3a.vectored.read.min.seek.size = 131072","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.777332Z","level":"info","event":"spark.hadoop.fs.s3a.access.key = admin","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.777416Z","level":"info","event":"spark.hadoop.fs.s3a.threads.max = 10","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.777496Z","level":"info","event":"spark.hadoop.fs.s3a.secret.key = admin12345","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.777898Z","level":"info","event":"spark.hadoop.fs.s3a.connection.ssl.enabled = false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.777981Z","level":"info","event":"spark.hadoop.fs.s3a.path.style.access = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778045Z","level":"info","event":"spark.hadoop.fs.s3a.connection.part.upload.timeout = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778105Z","level":"info","event":"spark.app.initial.jar.urls = spark://5eaf9358cc0f:35207/jars/aws-java-sdk-bundle-1.12.787.jar,spark://5eaf9358cc0f:35207/jars/ojdbc11.jar,spark://5eaf9358cc0f:35207/jars/hadoop-aws-3.3.4.jar,spark://5eaf9358cc0f:35207/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar,spark://5eaf9358cc0f:35207/jars/iceberg-aws-bundle-1.9.2.jar","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778170Z","level":"info","event":"spark.hadoop.fs.s3a.aws.credentials.provider = org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778232Z","level":"info","event":"spark.hadoop.fs.s3a.attempts.maximum = 3","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778296Z","level":"info","event":"spark.app.name = BAITEST","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778355Z","level":"info","event":"spark.jars = /opt/spark/jars/hadoop-aws-3.3.4.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar,/opt/spark/jars/ojdbc11.jar,/opt/spark/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar,/opt/spark/jars/iceberg-aws-bundle-1.9.2.jar","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778552Z","level":"info","event":"spark.sql.adaptive.coalescePartitions.enabled = false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778646Z","level":"info","event":"spark.sql.catalog.local.type = hadoop","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778707Z","level":"info","event":"spark.hadoop.fs.s3a.connection.idle.time = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778764Z","level":"info","event":"spark.hadoop.fs.s3a.vectored.read.max.merged.size = 2097152","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778815Z","level":"info","event":"spark.hadoop.fs.s3a.connection.establish.timeout = 5000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778889Z","level":"info","event":"spark.serializer.objectStreamReset = 100","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.778946Z","level":"info","event":"spark.master = local[*]","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779008Z","level":"info","event":"spark.sql.catalog.local.warehouse = s3a://warehouse/","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779071Z","level":"info","event":"spark.submit.deployMode = client","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779141Z","level":"info","event":"spark.sql.warehouse.dir = file:/opt/airflow/spark-warehouse","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779200Z","level":"info","event":"spark.sql.adaptive.enabled = false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779256Z","level":"info","event":"spark.hadoop.fs.s3a.retry.limit = 5","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779307Z","level":"info","event":"spark.app.submitTime = 1756704606373","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779360Z","level":"info","event":"spark.hadoop.fs.s3a.multipart.size = 104857600","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779423Z","level":"info","event":"spark.repl.local.jars = file:///opt/spark/jars/hadoop-aws-3.3.4.jar,file:///opt/spark/jars/aws-java-sdk-bundle-1.12.787.jar,file:///opt/spark/jars/ojdbc11.jar,file:///opt/spark/jars/iceberg-spark-runtime-3.5_2.13-1.9.2.jar,file:///opt/spark/jars/iceberg-aws-bundle-1.9.2.jar","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779517Z","level":"info","event":"spark.driver.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779580Z","level":"info","event":"spark.hadoop.fs.s3a.connection.maximum = 15","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779630Z","level":"info","event":"spark.executor.extraClassPath = /opt/spark/jars/*","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779680Z","level":"info","event":"spark.hadoop.fs.s3a.socket.send.buffer = 65536","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779729Z","level":"info","event":"spark.executor.id = driver","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779775Z","level":"info","event":"spark.hadoop.fs.s3a.connection.timeout = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779826Z","level":"info","event":"spark.hadoop.fs.s3a.retry.interval = 500","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779896Z","level":"info","event":"spark.app.id = local-1756704607678","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779942Z","level":"info","event":"spark.driver.extraClassPath = /opt/spark/jars/*","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.779987Z","level":"info","event":"spark.app.startTime = 1756704606614","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780036Z","level":"info","event":"spark.sql.extensions = org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780089Z","level":"info","event":"spark.hadoop.fs.s3a.socket.recv.buffer = 65536","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780138Z","level":"info","event":"spark.hadoop.fs.s3a.impl = org.apache.hadoop.fs.s3a.S3AFileSystem","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780195Z","level":"info","event":"spark.sql.catalog.local = org.apache.iceberg.spark.SparkCatalog","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780246Z","level":"info","event":"spark.rdd.compress = True","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780301Z","level":"info","event":"spark.hadoop.fs.s3a.threads.keepalivetime = 60000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780359Z","level":"info","event":"spark.executor.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780447Z","level":"info","event":"spark.hadoop.fs.s3a.multipart.purge.age = 86400","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780511Z","level":"info","event":"spark.submit.pyFiles =","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780568Z","level":"info","event":"spark.driver.port = 35207","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780619Z","level":"info","event":"spark.hadoop.fs.s3a.endpoint = http://minio:9000","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780670Z","level":"info","event":"spark.ui.showConsoleProgress = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780720Z","level":"info","event":"spark.hadoop.fs.s3a.fast.upload = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780772Z","level":"info","event":"spark.hadoop.fs.s3a.impl.disable.cache = true","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780818Z","level":"info","event":"spark.driver.host = 5eaf9358cc0f","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:11.780885Z","level":"info","event":"Spark session finished.","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:12.162788","level":"info","event":"Done. Returned value was: None","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-09-01T05:30:12.201264Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:12.201673Z","level":"info","event":" Previous state of the Task instance: running","chan":"stdout","logger":"task"}
{"timestamp":"2025-09-01T05:30:12.201798Z","level":"info","event":"Task operator:<Task(PythonOperator): install_spark>","chan":"stdout","logger":"task"}
